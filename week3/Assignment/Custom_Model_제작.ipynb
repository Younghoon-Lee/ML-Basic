{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": " Custom Model ì œì‘.ipynbì˜ ì‚¬ë³¸",
      "provenance": [],
      "collapsed_sections": [
        "nzf_SMkwQIcp",
        "A9pZE3mpaIdG",
        "Oknx2fv3Ncvn",
        "VodIGNr0gI8U",
        "95QrHvgqadqg",
        "VfkQ0jmGbSmX",
        "JQsWM-vgqV17",
        "33PuuiWGZhz5",
        "M1EGwkfCxDr7",
        "D9JlxC5WyO7X",
        "qXkF-1SC1Q0q",
        "oJ0ZuWycwsff",
        "5qM693v7A31v",
        "zfJJRMVx4uZU",
        "f3MnmB0zE-TK",
        "dgoOCMtbJHEL",
        "W-eAr6c7GEHl",
        "m7w_YfK6HXQ9",
        "LZ0zV31lX6zN",
        "TwdiREr_YLEa",
        "SHpq-zKFdQ8j",
        "VfmnV6cRuYf5",
        "Ybvq8tz4769-",
        "5d8rq3BlRjmH",
        "jpXu3zuOcjzO",
        "yBmtQly_nqR7",
        "jPvOek5YxfRg",
        "VBC_HD024zT7",
        "zLFA5jeb7dcB",
        "IJNyfmll_h_o",
        "qrEsHFT2FRDj",
        "8r1QkKGGJobo",
        "GGZDh_Tw4tpS",
        "HXUIf4hw8R_A",
        "b7RtvqiWNGen",
        "aowwiHAz3I2c",
        "q2IFscSgPqj0",
        "C5EzHAPj3LW8",
        "rSyB0wutN_Oi",
        "pSIGoFyWRoJ2",
        "u7iF0gyR3dZa",
        "Ixzc0txuqmDb"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7tFl6DHSdUHf"
      },
      "source": [
        "<img src=\"https://i.imgur.com/uDGD221.png\" width=100%>\n",
        "\n",
        "```\n",
        "ğŸ’¡ Colab Dark ëª¨ë“œ ì‚¬ìš©ì„ ê¶Œì¥í•©ë‹ˆë‹¤\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dYStbm6ZsH9a"
      },
      "source": [
        "# Custom Model ì œì‘\n",
        "> PyTorchì˜ ì²« ë²ˆì§¸ í•„ìˆ˜ ê³¼ì œì— ì˜¤ì‹  ê²ƒì„ í™˜ì˜í•©ë‹ˆë‹¤! ì´ë²ˆ Colabì—ì„œëŠ” PyTorch ê°•ì˜ë¥¼ ìˆ˜ê°•í•˜ì‹œë©´ì„œ ë°°ìš´ ë‹¤ì–‘í•œ ì§€ì‹ë“¤ ë° ê·¸ ì™¸ ìœ ìš©í•œ ì§€ì‹ë“¤ì„ ì‹¤ìŠµì„ í†µí•´ì„œ í™œìš©í•´ë³¼ ì‹œê°„ì„ ê°€ì§ˆ ê²ƒì…ë‹ˆë‹¤!\n",
        "- ğŸŒ Custom ëª¨ë¸ ì œì‘ì„ ìœ„í•œ Documentation í™œìš©\n",
        "- â­ Custom ëª¨ë¸ ì œì‘ì„ ìœ„í•œ nn.Module í´ë˜ìŠ¤\n",
        "- ğŸš€ <font color='yellow'><b>[ Optional ]</b></font> Custom ëª¨ë¸ ì œì‘ì„ ìœ„í•œ Github ì°¸ì¡°í•´ë³´ê¸°\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ECqIkyC27Z5X"
      },
      "source": [
        "## ğŸ¦† ê³¼ì œì™€ í•¨ê»˜í•  ì¹œêµ¬ ë¶€ìŠ¤íŠ¸ìº í”„ ì˜¤ë¦¬ - ë¶€ë•ì´\n",
        "> ë¶€ë•ì´ëŠ” ì´ì œ ê°“ PyTorchë¥¼ ì‹œì‘í•´ì„œ ê¶ê¸ˆí•œê²Œ ë§¤ìš° ë§ê³  ì—´ì •ì´ ë„˜ì³ìš”! \n",
        "\n",
        "```python\n",
        "ğŸ¦†\n",
        "ë°˜ê°€ì›Œìš”! PyTorchë¥¼ í•¨ê»˜ ê³µë¶€í•˜ê²Œ ëœ ë¶€ë•ì´ë¼ê³  í•´ìš”!\n",
        "PyTorchê°€ ë¬´ì—‡ì¸ì§€ ëŠ˜ ê¶ê¸ˆí–ˆì—ˆëŠ”ë° ì´ë²ˆì— ê³µë¶€í•˜ê²Œ ë˜ì–´ ë„ˆë¬´ ê¸°ë»ìš”!\n",
        "```\n",
        "```pyton\n",
        "ğŸ˜Š\n",
        "ë¬¼ë¡ ì´ì£ ! í•¨ê»˜ ì—´ì‹¬íˆ ê³µë¶€í•´ë´ìš”!\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nzf_SMkwQIcp"
      },
      "source": [
        "## ğŸ˜‰ PyTorch ë¼ì´ì„¼ìŠ¤\n",
        "\n",
        "PyTorchëŠ” BSD ë¼ì´ì„¼ìŠ¤ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤! ììœ ë¡­ê²Œ ìˆ˜ì •í•˜ê³  ë°°í¬ê°€ ê°€ëŠ¥í•˜ë©° ì‹¬ì§€ì–´ ìƒì—…ì ìœ¼ë¡œ ì´ìš©ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤!\n",
        "\n",
        "![](https://github.com/IllgamhoDuck/PyTorch/blob/main/document_image/pytorch%20official%20-%20bsd%20license.png?raw=true)\n",
        "\n",
        "- [Adding a Contributor License Agreement for PyTorch - PyTorch](https://pytorch.org/blog/a-contributor-license-agreement-for-pytorch/#what-is-not-changing)\n",
        "- [BSD License - Wikipedia](https://en.wikipedia.org/wiki/BSD_licenses)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TE5_pyW7zvbT"
      },
      "source": [
        "## ğŸŒˆ ê³¼ì œ ì¢…ë¥˜\n",
        "> ì•ìœ¼ë¡œ ì—¬ëŸ¬ë¶„ë“¤ì´ ë§ˆì£¼í•˜ê²Œ ë  ê³¼ì œëŠ” ë‹¤ìŒê³¼ ê°™ì´ 4ê°œì˜ ì¢…ë¥˜ë¡œ êµ¬ì„±ë˜ì–´ ìˆìŠµë‹ˆë‹¤!\n",
        "- ğŸ” íƒìƒ‰ : ì •ë³´ë¥¼ ì°¾ì•„ ëª¨í—˜ì„ ë– ë‚˜ë³¼ê¹Œìš”?\n",
        "- ğŸ‘¨â€ğŸ’» ì½”ë”© : ìì‹ ì˜ ì†ìœ¼ë¡œ ì½”ë“œë¥¼ ì‘ì„±í•´ë³´ì„¸ìš”!\n",
        "- ğŸ“– ì½ê¸° : ìë£Œë¥¼ ëˆˆìœ¼ë¡œ ì°¬ì°¬íˆ í›‘ì–´ë³´ì„¸ìš”!\n",
        "- â“ í€´ì¦ˆ : ì •ë‹µì„ ë§í˜€ë³´ì„¸ìš”!\n",
        "\n",
        "**ê¸°íƒ€**\n",
        "- ğŸ íŒíŠ¸ : ê³¼ì œ í•´ê²°ì— ë„ì›€ì„ ì£¼ëŠ” ê¸€ì…ë‹ˆë‹¤\n",
        "- âœ¨ ìœ ìš©í•œ ìë£Œ : ì½ìœ¼ë©´ ì¢‹ì§€ë§Œ í•„ìˆ˜ëŠ” ì•„ë‹™ë‹ˆë‹¤\n",
        "- ğŸ”¥ í™œí™œ : ê³¼ì œ ë‚œì´ë„ê°€ ë†’ìŠµë‹ˆë‹¤\n",
        "- ğŸ”¥ğŸ”¥ğŸ”¥ í™œí™œí™œí™”ë¥´ë¥´ : ê³¼ì œ ë‚œì´ë„ê°€ ë§¤ìš° ë†’ìŠµë‹ˆë‹¤\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lh7DIeNXnfZN"
      },
      "source": [
        "## ğŸŒ Custom ëª¨ë¸ ì œì‘ì„ ìœ„í•œ Documentation í™œìš©\n",
        "\n",
        "```\n",
        "ğŸ’¡ PyTorch ë¼ì´ë¸ŒëŸ¬ë¦¬ì˜ Documentationì„ í•¨ê»˜ íƒì‚¬í•˜ë©° Custom ëª¨ë¸\n",
        "   ì œì‘ì„ ìœ„í•´ Documentationì„ í™œìš©í•˜ëŠ” ë°©ë²•ì„ ë°°ì›Œë³¼ ê²ƒì…ë‹ˆë‹¤!\n",
        "```\n",
        "\n",
        "Documentationì€ ê°œë°œìë“¤ì´ ìì‹ ë“¤ì˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ì— ëŒ€í•œ ì„¤ëª…ì„ ì¹œì ˆíˆ ë‹´ì•„ë†“ì€ ë¬¸ì„œì…ë‹ˆë‹¤. ìš°ë¦¬ê°€ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì‚¬ìš©í•˜ë©° ê²½í—˜í•˜ëŠ” ë§ì€ ë¬¸ì œë“¤ì˜ í•´ë²•ì€ Stack overflowë‚˜ googleì—ì„œ ì°¾ëŠ” mediumê³¼ ê°™ì€ ë¸”ë¡œê·¸ì— ëŒ€ë¶€ë¶„ ì˜ ì •ë¦¬ë˜ì–´ìˆì§€ë§Œ ì„¸ë¶€ì ì¸ ë‚´ìš©ì„ ì•Œì•„ì•¼ í•˜ëŠ” ìˆœê°„ì´ ìˆìŠµë‹ˆë‹¤. ìš°ë¦¬ê°€ ì°¾ëŠ” ë‚´ìš©ì´ documentationì„ ì œì™¸í•œ ê·¸ ì–´ëŠ ê³³ì—ë„ ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ê²½ìš°ë„ ìˆì§€ìš”.\n",
        "\n",
        "Documentationì€ ë¼ì´ë¸ŒëŸ¬ë¦¬ì˜ ëª¨ë“  ì„¸ë¶€ ì •ë³´ê°€ ë‹´ê²¨ìˆëŠ” ê³³ìœ¼ë¡œ ì—¬ê¸°ì— ë‚˜ì˜¤ëŠ” ë‹¤ì–‘í•œ ë‚´ìš©ë“¤ì„ ë§ì´ ì•Œìˆ˜ë¡ Custom ëª¨ë¸ì„ ë§Œë“¤ë•Œ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ë„êµ¬ì˜ ë²”ìœ„ê°€ ë„“ì–´ì§€ê²Œ ë©ë‹ˆë‹¤. ë” ë©‹ì§„ ì„¸ë ¨ëœ ìì‹ ë§Œì˜ Custom ëª¨ë¸ì„ ë§Œë“¤ê¸° ìœ„í•´ ê°€ì¥ ì¤‘ìš”í•œ ì´ˆì„ì´ë¼ê³  í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤!\n",
        "\n",
        "ê·¸ëŸ¼ ğŸ¦† ë¶€ë•ì´ì™€ í•¨ê»˜ ë– ë‚˜ë³¼ê¹Œìš”!\n",
        "\n",
        "\n",
        "- ğŸŒ“ Documentationê³¼ ì¹œí•´ì§€ê¸°\n",
        "- ğŸŒ“ Documentationì—ì„œ ì •ë³´ íƒìƒ‰í•˜ê¸°\n",
        "- ğŸŒ“ Documentationì—ì„œ ì°¾ì€ ê¸°ëŠ¥ ì´í•´ ë° í™œìš©í•˜ê¸°\n",
        "- ğŸŒ“ Documentation ì½ê¸°"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A9pZE3mpaIdG"
      },
      "source": [
        "###  ğŸŒ“ Documentationê³¼ ì¹œí•´ì§€ê¸°\n",
        "> ì²˜ìŒ ì ‘í•˜ëŠ” Documentationì„ ë³´ê²Œ ë˜ë©´ ê·¸ ë°©ëŒ€í•œ ì–‘ì— ê¸°ê°€ ì§ˆë¦¬ê²Œ ë§ˆë ¨ì…ë‹ˆë‹¤! íŠ¹íˆë‚˜ ìƒì†Œí•œ ë¶„ì•¼ì˜ Documentationì´ë¼ë©´ ê·¸ ì–´ìƒ‰í•¨ì€ ë”ë”ìš± ë§í•  ê²ƒë„ ì—†ê² ì£ ! ë‚´ìš©ì„ ì´í•´í•  í•„ìš”ëŠ” ì—†ìŠµë‹ˆë‹¤! ììœ ë¡­ê²Œ Documentationì„ ë³´ë©´ì„œ ì´ê²ƒì €ê²ƒ ëˆŒëŸ¬ë³´ê³  íƒí—˜í•´ë³´ì„¸ìš”! \n",
        "\n",
        "- ğŸ” <font color='orange'><b>[ íƒìƒ‰ ]</b></font> Documentation ë‘˜ëŸ¬ë³´ê¸°\n",
        "- â“ <font color='red'><b>[ í€´ì¦ˆ ]</b></font> PyTorch Release Status (ë°°í¬ ìƒíƒœ)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oknx2fv3Ncvn"
      },
      "source": [
        "#### ğŸ” <font color='orange'><b>[ íƒìƒ‰ ]</b></font> Documentation ë‘˜ëŸ¬ë³´ê¸°\n",
        "> ğŸ’¡ ì œì‹œë˜ëŠ” í•­ëª©ì„ ë”°ë¼ê°€ì£¼ì‹œë©´ ë©ë‹ˆë‹¤! í€´ì¦ˆê°€ ì•„ë‹™ë‹ˆë‹¤!\n",
        "\n",
        "``` python\n",
        "ğŸ¦†\n",
        "PyTorchë¥¼ ì•Œê¸° ìœ„í•´ì„œ ê³µì‹ documentionì„ ë“¤ì–´ê°€ë³´ì•˜ì–´ìš”!\n",
        "PyTorch ë‹µê²Œ ë¹¨ê°„ìƒ‰ìœ¼ë¡œ í¬ì¸íŠ¸ë¥¼ ì¤€ í™ˆí˜ì´ì§€ê°€ ë³´ì´ë„¤ìš”!\n",
        "ì €í¬ í•¨ê»˜ Documentationì„ ë‘˜ëŸ¬ë³´ì•„ìš”!\n",
        "```\n",
        "- [Documentation main - PyTorch ê³µì‹ ë¬¸ì„œ](https://pytorch.org/docs/stable/index.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VodIGNr0gI8U"
      },
      "source": [
        "##### âœ”ï¸ ë²„ì ¼ (Version)\n",
        "``` python\n",
        "ğŸ¦†\n",
        "ì €í¬ê°€ ë³´ëŠ” ì´ PyTorch Documentationì˜ ë²„ì ¼ì„ ì‚´í´ë³´ì•„ìš”!\n",
        "```\n",
        "\n",
        "- âœ… PyTorch ë²„ì ¼ í™•ì¸í•´ë³´ê¸°\n",
        "    - `1.9.0`\n",
        "- âœ… PyTorch ë²„ì ¼ í´ë¦­í•´ì„œ ë‹¤ë¥¸ ë²„ì ¼ ì‚´í´ë³´ê¸°\n",
        "    - ![](https://github.com/IllgamhoDuck/PyTorch/blob/main/document_image/pytorch%20version.png?raw=true)\n",
        "    - `v0.1.12`ì—ì„œ ì‹œì‘í•´ì„œ í˜„ì¬ `v1.9.0` ë²„ì ¼\n",
        "- âœ… master (unstable) ë²„ì ¼ Documentation ì—´ì–´ë³´ê¸°\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "95QrHvgqadqg"
      },
      "source": [
        "##### âœ”ï¸ ëª©ì°¨ (Index)\n",
        "``` python\n",
        "ğŸ¦†\n",
        "PyTorchì—ëŠ” ì •ë§ ë§ì€ ë‚´ìš©ì´ ë‹´ê²¨ì ¸ ìˆê¸° ë•Œë¬¸ì—\n",
        "ì‚¬ëŒì´ ì‰½ê²Œ ë‚´ìš©ì„ ì°¾ê¸° ìœ„í•´ì„œ ëª©ì°¨ë¡œ ì •ë¦¬ê°€ ì˜ ë˜ì–´ìˆì„ ê±°ì—ìš”!\n",
        "Documentationì˜ ì¢Œì¸¡ì— ëª©ì°¨ê°€ ìœ„ì¹˜í•˜ê³  ìˆëŠ” ê²ƒ ê°™ì•„ìš”! ê°™ì´ ì‚´í´ë´ìš”!\n",
        "```\n",
        "\n",
        "- âœ… `python API` ì˜†ì˜ `[ - ]` ëˆŒëŸ¬ë³´ê¸°\n",
        "    - ![](https://github.com/IllgamhoDuck/PyTorch/blob/main/document_image/+%20-%20button.png?raw=true)\n",
        "- âœ… ëª©ì°¨ ì‚´í´ë³´ê¸°\n",
        "    - Notes\n",
        "    - Language Bindings\n",
        "    - Python API\n",
        "    - Libraries\n",
        "    - Community\n",
        "- âœ… python APIì˜ í•˜ìœ„ ëª©ì°¨ í›‘ì–´ë³´ê¸°\n",
        "- âœ… python APIì˜ í•˜ìœ„ ëª©ì°¨ ì•„ë¬´ê±°ë‚˜ í•˜ë‚˜ ê°€ë³ê²Œ ì½ì–´ë³´ê¸°\n",
        "    - ex) `torch.nn`\n",
        "- âœ… python API - torch ë¬¸ì„œ ë‚´ë¶€ ëª©ì°¨ í›‘ì–´ë³´ê¸°\n",
        "    - [TORCH - PyTorch ê³µì‹ ë¬¸ì„œ](https://pytorch.org/docs/stable/torch.html)\n",
        "    - ![](https://github.com/IllgamhoDuck/PyTorch/blob/main/document_image/table%20of%20content%20-%20torch.png?raw=true)\n",
        "    \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tSwYkTH_lgsz"
      },
      "source": [
        "##### âœ”ï¸ ê²€ìƒ‰ (Search)\n",
        "``` python\n",
        "ğŸ¦†\n",
        "ëª©ì°¨ê°€ ìˆì–´ ì›í•˜ëŠ” ë‚´ìš©ì„ ì°¾ê¸°ê°€ ìˆ˜ì›”í•´ë³´ì´ì§€ë§Œ\n",
        "ìµìˆ™í•œ ì‚¬ëŒì´ ì•„ë‹ˆë¼ë©´ ì›í•˜ëŠ” ë‚´ìš©ì„ ì°¾ê¸° ìœ„í•´ í•œì°¸ì„ í—¤ë§¬ ê²ƒ ê°™ì•„ìš”!\n",
        "ìš°ë¦¬ê°€ ì›í•˜ëŠ” ë‚´ìš©ì„ ë°”ë¡œ ì°¾ê¸° ìœ„í•´ search barë¥¼ ì‚¬ìš©í•˜ë©´ ë  ê²ƒ ê°™ì•„ìš”!\n",
        "```\n",
        "\n",
        "- âœ… search bar ìœ„ì¹˜ í™•ì¸í•´ë³´ê¸°\n",
        "    - ![](https://github.com/IllgamhoDuck/PyTorch/blob/main/document_image/pytorch%20search%20bar.png?raw=true)\n",
        "- âœ… ì›í•˜ëŠ” í‚¤ì›Œë“œ ì•„ë¬´ê²ƒì´ë‚˜ ê²€ìƒ‰í•´ë³´ê¸°\n",
        "    - ex) duck\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VfkQ0jmGbSmX"
      },
      "source": [
        "#### â“ <font color='red'><b>[ í€´ì¦ˆ ]</b></font> PyTorch Release Status (ë°°í¬ ìƒíƒœ)\n",
        "``` python\n",
        "ğŸ¦†\n",
        "PyTorchì— ì •ë§ ë‚´ìš©ì´ ë§ë„¤ìš”! ë‘˜ëŸ¬ë³´ëŠ” ê²ƒì„ ë©ˆì¶”ê³ \n",
        "ë©”ì¸ í˜ì´ì§€ë¡œ ëŒì•„ì™”ëŠ”ë° release statusì— ëŒ€í•œ ì„¤ëª…ì´ ì“°ì—¬ìˆë„¤ìš”!\n",
        "Stable, Beta, Prototype 3ê°€ì§€ê°€ ì í˜€ì ¸ ìˆëŠ”ë° Betaê°€ ë¬´ì—‡ì¸ì§€ ì•Œë ¤ì£¼ì„¸ìš”!\n",
        "```\n",
        "- [Documentation main - PyTorch ê³µì‹ ë¬¸ì„œ](https://pytorch.org/docs/stable/index.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5X_RYE6szDXr"
      },
      "source": [
        "```python\n",
        "ğŸ˜®\n",
        "# TODO : ë§ê³  í‹€ë¦¬ê³ ê°€ ì—†ëŠ” ë¬¸ì œì…ë‹ˆë‹¤. ë¬¸ì„œë¥¼ ì½ê³  ë‹µì„ ììœ ë¡œì´ ì ì–´ì£¼ì„¸ìš”\n",
        "\n",
        "\n",
        "Betaë€ ì•„ì§ ì˜¨ì „í•˜ê²Œ ì™„ì„±ëœ ë²„ì „ì´ ì•„ë‹ˆë©°, ì¶”ê°€ì ìœ¼ë¡œ ì‚¬ìš©ìì˜ í”¼ë“œë°±ìœ¼ë¡œ ë²„ì ¼ì´ ë°”ë€” ê°€ëŠ¥ì„±ì´ ì¡´ì¬í•œë‹¤. beta ë²„ì ¼ì€ ìƒˆë¡œìš´ featureê°€ ì•ˆì •ë˜ê²Œ ì‘ë™ë˜ëŠ” ê²ƒì„ ëª©í‘œë¡œ í•˜ë©´ í•˜ìœ„ í˜¸ì™„ë˜ëŠ” ê²ƒì„ ì§€ì–‘í•œë‹¤. \n",
        "\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JQsWM-vgqV17"
      },
      "source": [
        "### ğŸŒ“ Documentationì—ì„œ ì •ë³´ íƒìƒ‰í•˜ê¸°\n",
        "> ëŒ€ë¶€ë¶„ì˜ í•´ë²•ì€ êµ¬ê¸€ë§ì„ í†µí•´ì„œ ë°”ë¡œ ì •ë‹µì„ ì°¾ì„ ìˆ˜ ìˆê³  ì§€ê¸ˆ ì´ ê¸€ì„ ì½ëŠ” ëª¨ë“  ë¶„ë“¤ì€ ì´ë¯¸ ì˜ í™œìš©í•˜ì‹¤ ê²ë‹ˆë‹¤. í•˜ì§€ë§Œ Documentationì˜ ëª¨ë“  ì •ë³´ê°€ í•­ìƒ êµ¬ê¸€ë§ì„ í†µí•´ ë‚˜ì˜¤ëŠ” ê²ƒì€ ì•„ë‹ˆê¸° ë•Œë¬¸ì— êµ¬ê¸€ë§ ì—†ì´ Documentationë§Œì„ ê°€ì§€ê³  ì •ë³´ë¥¼ ì°¾ëŠ” ë°©ë²•ì„ ì‹¤ìŠµí•´ë³¼ ê²ƒì…ë‹ˆë‹¤!\n",
        "\n",
        "- â“ <font color='red'><b>[ í€´ì¦ˆ ]</b></font> Documentationì´ ì œê³µí•˜ëŠ” search ê¸°ëŠ¥ í™œìš©\n",
        "- ğŸ” <font color='orange'><b>[ íƒìƒ‰ ]</b></font> ëª©ì°¨ë¥¼ ë³´ê³  ì›í•˜ëŠ” ì •ë³´ë¥¼ ì°¾ê¸° "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "33PuuiWGZhz5"
      },
      "source": [
        "#### â“ <font color='red'><b>[ í€´ì¦ˆ ]</b></font> Documentationì´ ì œê³µí•˜ëŠ” search ê¸°ëŠ¥ í™œìš©\n",
        "\n",
        "``` python\n",
        "ğŸ¦†\n",
        "PyTorchê°€ ì œê³µí•´ì£¼ëŠ” ê²€ìƒ‰ ê¸°ëŠ¥ì„ ì´ìš©í•˜ì—¬ì„œ ê¶ê¸ˆí•œ ê²ƒì„ ì°¾ì•„ë³´ê³  ì‹¶ì–´ìš”!\n",
        "```\n",
        "- [Documentation main - PyTorch ê³µì‹ ë¬¸ì„œ](https://pytorch.org/docs/stable/index.html)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M1EGwkfCxDr7"
      },
      "source": [
        "##### ğŸ’¯ PyTorchì˜ Linear Algebra ê¸°ëŠ¥ ì—¬ë¶€\n",
        "\n",
        "``` python\n",
        "ğŸ¦†\n",
        "PyTorchëŠ” NumPyì²˜ëŸ¼ ì„ í˜•ëŒ€ìˆ˜í•™(Linear Algebra) ê´€ë ¨ ê¸°ëŠ¥ì´ ìˆë‚˜ìš”?\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CmxHQsDxZUoK"
      },
      "source": [
        "```python\n",
        "ğŸ˜‰\n",
        "# TODO : ìˆëŠ”ì§€ ì—†ëŠ”ì§€ ììœ ë¡­ê²Œ ë‹µí•´ì£¼ì„¸ìš”!\n",
        "ìˆë‹¤ !\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D9JlxC5WyO7X"
      },
      "source": [
        "##### ğŸ’¯ Matrix Multiplication\n",
        "\n",
        "``` python\n",
        "ğŸ¦†\n",
        "pytorchì—ì„œ Matrix Multiplicationì„ í•˜ê³  ì‹¶ì„ ë•Œ ì‚¬ìš©í•˜ëŠ” í•¨ìˆ˜ëŠ” ë¬´ì—‡ì¼ê¹Œìš”?\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rHpU8WUZyO7f"
      },
      "source": [
        "```python\n",
        "ğŸ˜‰\n",
        "# TODO : ì •í•´ì§„ í˜•ì‹ì´ ì—†ìŠµë‹ˆë‹¤! ììœ ë¡­ê²Œ ë‹µí•´ì£¼ì„¸ìš”!\n",
        "torch.matmul, torch.mm ë“±ì´ ìˆë‹¤.\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qXkF-1SC1Q0q"
      },
      "source": [
        "##### ğŸ’¯ Norm\n",
        "> ì—¬ê¸°ì„œ ë§í•˜ëŠ” normì€ normalizationì´ ì•„ë‹ˆë¼ ë²¡í„°ë‚˜ í–‰ë ¬ì˜ í¬ê¸°ì˜ ê°œë…ì¸ normì„ì— ì£¼ì˜í•´ì£¼ì„¸ìš”!\n",
        "\n",
        "``` python\n",
        "ğŸ¦†\n",
        "ì €ëŠ” ëª¨ë¸ì„ ë§Œë“¤ ë•Œ ë²¡í„°ë‚˜ í–‰ë ¬ì˜ normì„ ë§ì´ ì´ìš©í•  ê²ƒ ê°™ì•„ìš”! \n",
        "ì´ëŸ´ë•Œ ì–´ë–¤ í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ë©´ ì¢‹ì„ê¹Œìš”?\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "orfjxQuq1Q0u"
      },
      "source": [
        "```python\n",
        "ğŸ˜ƒ\n",
        "# TODO : ì •í•´ì§„ í˜•ì‹ì´ ì—†ìŠµë‹ˆë‹¤! ììœ ë¡­ê²Œ ë‹µí•´ì£¼ì„¸ìš”!\n",
        "torch.linalg.nomr í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ë©´ ëœë‹¤\n",
        "\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oJ0ZuWycwsff"
      },
      "source": [
        "#### ğŸ” <font color='orange'><b>[ íƒìƒ‰ ]</b></font> ëª©ì°¨ë¥¼ ë³´ê³  ì›í•˜ëŠ” ì •ë³´ë¥¼ ì°¾ê¸°\n",
        "> ğŸ’¡ ì œì‹œë˜ëŠ” í•­ëª©ì„ ë”°ë¼ê°€ì£¼ì‹œë©´ ë©ë‹ˆë‹¤! í€´ì¦ˆê°€ ì•„ë‹™ë‹ˆë‹¤!\n",
        "\n",
        "``` python\n",
        "ğŸ¦†\n",
        "ë‚˜ì¤‘ì— PyTorchì— ìµìˆ™í•´ì§€ë©´ ì €ë„ ë¼ì´ë¸ŒëŸ¬ë¦¬ì— ì œ ì½”ë“œë¥¼ ê¸°ì—¬í•˜ê³  ì‹¶ì–´ìš”!\n",
        "ëŒ€ë¶€ë¶„ì˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ê·¸ë ‡ë“¯ PyTorchë„ ë¶„ëª…íˆ ê¸°ì—¬ í”„ë¡œì„¸ìŠ¤ì— ëŒ€í•´\n",
        "ì‘ì„±í•´ë†“ì€ ë¬¸ì„œê°€ ìˆì„ê±°ì˜ˆìš”! \n",
        "```\n",
        "- [Documentation main - PyTorch ê³µì‹ ë¬¸ì„œ](https://pytorch.org/docs/stable/index.html)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fUmgABsu8dSn"
      },
      "source": [
        "``` python\n",
        "ğŸ¦†\n",
        "ì—­ì‹œ ëª©ì°¨ì— ì»¤ë®¤ë‹ˆí‹° (Community)ê°€ ìˆë„¤ìš”!\n",
        "ì—¬ê¸°ì— ì½”ë“œì— ê¸°ì—¬í•˜ê³  ì‹¶ì€ ì‚¬ëŒë“¤ì„ ìœ„í•œ ê°€ì´ë“œ ë¬¸ì„œê°€ ìˆì–´ìš”! \n",
        "```\n",
        "\n",
        "- âœ… Community í•˜ìœ„ ëª©ì°¨ ì‚´í´ë³´ê¸°\n",
        "- âœ… PyTorch Contribution Guide ë¬¸ì„œ ì—´ì–´ì„œ í›‘ì–´ë³´ê¸°\n",
        "    - [PyTorch Contribution Guide - PyTorch ê³µì‹ ë¬¸ì„œ](https://pytorch.org/docs/stable/community/contribution_guide.html)\n",
        "- âœ… PyTorch Contribution Guide ë¬¸ì„œ ë‚´ë¶€ ëª©ì°¨ í™•ì¸\n",
        "    - ![](https://github.com/IllgamhoDuck/PyTorch/blob/main/document_image/table%20of%20content%20-%20contribution.png?raw=true)\n",
        "- âœ… ë‚´ë¶€ ëª©ì°¨ - Common Mistakes to Avoid ê°€ë³ê²Œ ì½ì–´ë³´ê¸°\n",
        "    - [PyTorch Contribution Guide - Common Mistakes To Avoid - PyTorch ê³µì‹ ë¬¸ì„œ](https://pytorch.org/docs/stable/community/contribution_guide.html#common-mistakes-to-avoid)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5qM693v7A31v"
      },
      "source": [
        "### ğŸŒ“ Documentationì—ì„œ ì°¾ì€ ê¸°ëŠ¥ ì´í•´ ë° í™œìš©í•˜ê¸°\n",
        "> ì´ì œ PyTorch documentationì—ì„œ ì›í•˜ëŠ” ì •ë³´ë¥¼ ì°¾ëŠ” ë°©ë²•ì„ ì•Œê²Œ ë˜ì—ˆìŠµë‹ˆë‹¤! í•˜ì§€ë§Œ ë‹¨ì§€ ì°¾ê¸°ë§Œ í•˜ë©´ ì†Œìš©ì´ ì—†ê² ì£ ! Documentationì— ì íŒ ê¸°ëŠ¥ì˜ ì„¤ëª…ì„ ì½ê³  ì§ì ‘ í™œìš©í•  ì¤„ ì•Œì•„ì•¼ ì§„ì§œ ì˜ë¯¸ê°€ ìˆìŠµë‹ˆë‹¤. ìš°ë¦¬ëŠ” ê°„ë‹¨í•œ ì˜ˆì œë¥¼ í†µí•´ PyTorchë¥¼ ì§ì ‘ ì‚¬ìš©í•´ë³¼ ê²ƒì…ë‹ˆë‹¤!\n",
        "\n",
        "- â“ <font color='red'><b>[ í€´ì¦ˆ ]</b></font> PyTorchì˜ ê¸°ë³¸ êµ¬ì„± ìš”ì†Œ Tensor\n",
        "- ğŸ‘¨â€ğŸ’» <font color='green'><b>[ ì½”ë”© ]</b></font> ì‚¬ì¹™ì—°ì‚° ê³„ì‚°í•˜ê¸°\n",
        "- ğŸ‘¨â€ğŸ’» <font color='green'><b>[ ì½”ë”© ]</b></font> ì¸ë±ì‹± (Indexing)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zfJJRMVx4uZU"
      },
      "source": [
        "#### â“ <font color='red'><b>[ í€´ì¦ˆ ]</b></font> PyTorchì˜ ê¸°ë³¸ êµ¬ì„± ìš”ì†Œ Tensor\n",
        "``` python\n",
        "ğŸ¦†\n",
        "PyTorchëŠ” tensorê°€ ëª¨ë“  ê²ƒì˜ ê¸°ë³¸ êµ¬ì„± ìš”ì†Œë¼ê³  í•´ì„œ\n",
        "ì‚¬ìš©í•˜ë ¤ê³  ì°¾ì•„ë³´ì•˜ëŠ”ë° \"torch.tensor\"ì™€ \"torch.Tensor\"\n",
        "2ê°€ì§€ê°€ ìˆë”ë¼êµ¬ìš”! ë¬´ìŠ¨ ì°¨ì´ê°€ ìˆëŠ” ê±°ì£ ?\n",
        "```\n",
        "- [Documentation main - PyTorch ê³µì‹ ë¬¸ì„œ](https://pytorch.org/docs/stable/index.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JXqdRH8h4uZc"
      },
      "source": [
        "```python\n",
        "ğŸ™ƒ\n",
        "# TODO : ë§ê³  í‹€ë¦¬ê³ ê°€ ì—†ëŠ” ë¬¸ì œì…ë‹ˆë‹¤. ë¬¸ì„œë¥¼ ì½ê³  ë‹µì„ ììœ ë¡œì´ ì ì–´ì£¼ì„¸ìš”\n",
        "ê·¼ë³¸ì ìœ¼ë¡œ torch.TensorëŠ”*classì´ê³  torch.tensorì€ í•¨ìˆ˜ì´ë‹¤.\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f3MnmB0zE-TK"
      },
      "source": [
        "#### ğŸ‘¨â€ğŸ’» <font color='green'><b>[ ì½”ë”© ]</b></font> ì‚¬ì¹™ì—°ì‚° ê³„ì‚°í•˜ê¸°\n",
        "\n",
        "``` python\n",
        "ğŸ¦†\n",
        "ì €í¬ë„ ì´ì œ ë“œë””ì–´ PyTorchë¥¼ ì´ìš©í•´ ì½”ë”©ì„ ì‹œì‘í•˜ë„¤ìš”!\n",
        "ê°„ë‹¨í•œ ì‚¬ì¹™ì—°ì‚°ìœ¼ë¡œ ê°™ì´ ì‹œì‘í•´ë´ìš”!\n",
        "```\n",
        "- [Documentation main - PyTorch ê³µì‹ ë¬¸ì„œ](https://pytorch.org/docs/stable/index.html)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dgoOCMtbJHEL"
      },
      "source": [
        "##### ğŸ’¡ ë”í•˜ê¸° (add)\n",
        "> ğŸ¦† ë¶€ë•ì´ê°€ ì½”ë“œë¥¼ ì‘ì„±í•´ì£¼ì—ˆì–´ìš”!\n",
        "\n",
        "```python\n",
        "ğŸ¦†\n",
        "5 + 7 ê³„ì‚°ì„ ë¨¼ì € ì œê°€ í•´ë³¼ê²Œìš”!\n",
        "```\n",
        "\n",
        "- [torch.add - PyTorch ê³µì‹ ë¬¸ì„œ](https://pytorch.org/docs/stable/generated/torch.add.html?highlight=add#torch.add)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K5-9T-fjE3a_",
        "outputId": "5f9cdbbe-8078-4aba-b57a-7ecb62589009"
      },
      "source": [
        "import torch\n",
        "\n",
        "A = torch.Tensor([5])\n",
        "B = torch.Tensor([7])\n",
        "\n",
        "torch.add(A, B)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([12.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9U9Wd_2oCLVR",
        "outputId": "64dc6dc4-770b-49ad-fea6-4bace9d7c722"
      },
      "source": [
        "# ğŸ¦† torch.addë¥¼ + ì—°ì‚°ìë¥¼ í†µí•´ì„œ ì‚¬ìš© ê°€ëŠ¥í•´ìš”!\n",
        "A + B"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([12.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kq9h3ucECtoe",
        "outputId": "b49419e7-3310-42be-f3e6-cd51a74172da"
      },
      "source": [
        "# ğŸ¦† ê³„ì‚°í• ë•Œ í”¼ì—°ì‚°ì(operand)ì¤‘ í•˜ë‚˜ë¼ë„ tensorê°€ ì…ë ¥ë˜ë©´ ê²°ê³¼ëŠ” tensorë¡œ ë‚˜ì™€ìš”!\n",
        "A + 7"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([12.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W-eAr6c7GEHl"
      },
      "source": [
        "##### ğŸ’¡ ë³µì¡í•œ ì‚¬ì¹™ì—°ì‚° ê³„ì‚°\n",
        "```python\n",
        "ğŸ¦†\n",
        "(3 + 7) * 2 - 5 / 10 ì€ ë¬´ì—‡ì¼ê¹Œìš”?\n",
        "ì—°ì‚°ì(+, -, *, /) ì—†ì´ í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•´ ê³„ì‚°í•´ì£¼ì„¸ìš”!\n",
        "```\n",
        "\n",
        "ê° ì‚¬ì¹™ì—°ì‚°ì€ torchì—ì„œ ì–´ë–¤ ì´ë¦„ì„ ì‚¬ìš©í• ê¹Œìš”?\n",
        "- `+` : [torch.add](https://pytorch.org/docs/stable/generated/torch.add.html?highlight=add#torch.add)\n",
        "- `-` : torch.sub\n",
        "- `*` : torch.mul\n",
        "- `/` : torch.div"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a-1cyVz1CiCK",
        "outputId": "e26d2497-74ea-4d6b-b4b6-edf4979f0b51"
      },
      "source": [
        "import torch\n",
        "\n",
        "A = torch.Tensor([3])\n",
        "B = torch.Tensor([7])\n",
        "C = torch.Tensor([2])\n",
        "D = torch.Tensor([5])\n",
        "E = torch.Tensor([10])\n",
        "\n",
        "# TODO : torch í•¨ìˆ˜ë¥¼ ì´ìš©í•´ì„œ (3 + 7) * 2 - 5 / 10 ë¥¼ ê³„ì‚°í•´ë³´ì„¸ìš”!\n",
        "\n",
        "# ì •ë‹µ 19.5ê°€ ë‚˜ì™€ì•¼ í•©ë‹ˆë‹¤!\n",
        "\n",
        "output = torch.add(A, B) # 1ì¤„ì— torch í•¨ìˆ˜ í•˜ë‚˜ì”©ë§Œ ì‚¬ìš©í•˜ì„¸ìš”!\n",
        "output = torch.sub(torch.mul(output, C), torch.div(D,E))\n",
        "\n",
        "# ì•„ë˜ ì½”ë“œëŠ” ìˆ˜ì •í•˜ì‹¤ í•„ìš”ê°€ ì—†ìŠµë‹ˆë‹¤!\n",
        "if output == 19.5:\n",
        "    print(\"ğŸ‰ğŸ‰ğŸ‰ ì„±ê³µ!!! ğŸ‰ğŸ‰ğŸ‰\")\n",
        "else:\n",
        "    print(\"ğŸ¦† ë‹¤ì‹œ ë„ì „í•´ë´ìš”!\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ğŸ‰ğŸ‰ğŸ‰ ì„±ê³µ!!! ğŸ‰ğŸ‰ğŸ‰\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m7w_YfK6HXQ9"
      },
      "source": [
        "#### ğŸ‘¨â€ğŸ’» <font color='green'><b>[ ì½”ë”© ]</b></font> ì¸ë±ì‹± (Indexing)\n",
        "> <font color='yellow'><b>[ Optional ]</b></font> ë¬¸ì œì˜ ê²½ìš° ğŸ”¥ ë§¤ìš° ì–´ë ¤ìš¸ ìˆ˜ ìˆìŠµë‹ˆë‹¤ ğŸ”¥ Documentationë§Œìœ¼ë¡œ ë„ì €íˆ ì´í•´ê°€ ì•ˆê°€ì‹ ë‹¤ë©´ êµ¬ê¸€ë§ì„ í—ˆìš©í•©ë‹ˆë‹¤. ë‚œì´ë„ê°€ ë†’ì•„ ì‹œê°„ì´ ë§ì´ ì†Œìš”ë  ìˆ˜ ìˆê¸° ë•Œë¬¸ì— ì—¬ìœ ê°€ ë˜ì‹œëŠ” ë¶„ì—ê²Œë§Œ ì¶”ì²œë“œë¦½ë‹ˆë‹¤.\n",
        "\n",
        "``` python\n",
        "ğŸ¦†\n",
        "tensorì—ì„œ ì›í•˜ëŠ” ê°’ë§Œ ê°€ì ¸ì˜¤ê³  ì‹¶ì€ë° ì–´ë–»ê²Œ í•´ì•¼ ì¢‹ì„ì§€ ëª¨ë¥´ê² ì–´ìš”!\n",
        "íŒŒì´ì¬ì—ì„œ listë¥¼ indexing(ì¸ë±ì‹±)í•˜ëŠ” ê²ƒê³¼ ë¹„ìŠ·í• ê¹Œìš”?\n",
        "```\n",
        "\n",
        "- [Documentation main - PyTorch ê³µì‹ ë¬¸ì„œ](https://pytorch.org/docs/stable/index.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZ0zV31lX6zN"
      },
      "source": [
        "##### ğŸ’¡ index_select\n",
        "\n",
        "\n",
        "``` python\n",
        "ğŸ¦†\n",
        "[[1  2]\n",
        " [3  4]] 2ì°¨ì› í…ì„œì—ì„œ [1  3]ì´ë¼ëŠ” ê°’ì„ ê°€ì ¸ì˜¤ê³  ì‹¶ì–´ìš”!\n",
        "```\n",
        "\n",
        "- [torch.index_select - PyTorch ê³µì‹ ë¬¸ì„œ](https://pytorch.org/docs/stable/generated/torch.index_select.html?highlight=index#torch.index_select)\n",
        "\n",
        "ğŸ **íŒíŠ¸** ğŸ\n",
        "- tensorë¥¼ ì›í•˜ëŠ” ëª¨ì–‘ìœ¼ë¡œ ë°”ê¾¸ê³  ì‹¶ì„ë•Œ [torch.Tensor.view](https://pytorch.org/docs/stable/generated/torch.Tensor.view.html?highlight=view#torch.Tensor.view)ë¼ëŠ” í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ë©´ ë©ë‹ˆë‹¤!\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wIDKrXzXZs07",
        "outputId": "be222af6-6404-41f7-c661-5a8fc885fa0d"
      },
      "source": [
        "import torch\n",
        "\n",
        "A = torch.Tensor([[1, 2],\n",
        "                  [3, 4]])\n",
        "\n",
        "# TODO : [1, 3]ì„ ë§Œë“œì„¸ìš”!\n",
        "A = (A[:,:1]).view(-1,2)\n",
        "# torch.index_select í•¨ìˆ˜ë¥¼ ì¨ì„œ í•´ë³´ì„¸ìš”!\n",
        "output = A\n",
        "\n",
        "# ì•„ë˜ ì½”ë“œëŠ” ìˆ˜ì •í•˜ì‹¤ í•„ìš”ê°€ ì—†ìŠµë‹ˆë‹¤!\n",
        "\n",
        "if torch.all(output == torch.Tensor([1, 3])):\n",
        "    print(\"ğŸ‰ğŸ‰ğŸ‰ ì„±ê³µ!!! ğŸ‰ğŸ‰ğŸ‰\")\n",
        "else:\n",
        "    print(\"ğŸ¦† ë‹¤ì‹œ ë„ì „í•´ë´ìš”!\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ğŸ‰ğŸ‰ğŸ‰ ì„±ê³µ!!! ğŸ‰ğŸ‰ğŸ‰\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Co8YFuVtaVZr",
        "outputId": "f51b5b1b-4395-40b9-8091-7ac1a857acff"
      },
      "source": [
        "# íŒŒì´ì¬ ë¦¬ìŠ¤íŠ¸ ì¸ë±ì‹±ê³¼ ë¹„ìŠ·í•œ ë°©ë²•ìœ¼ë¡œ í•´ë³´ì„¸ìš”!\n",
        "output = A\n",
        "\n",
        "# ì•„ë˜ ì½”ë“œëŠ” ìˆ˜ì •í•˜ì‹¤ í•„ìš”ê°€ ì—†ìŠµë‹ˆë‹¤!\n",
        "if torch.all(output == torch.Tensor([1, 3])):\n",
        "    print(\"ğŸ‰ğŸ‰ğŸ‰ ì„±ê³µ!!! ğŸ‰ğŸ‰ğŸ‰\")\n",
        "else:\n",
        "    print(\"ğŸ¦† ë‹¤ì‹œ ë„ì „í•´ë´ìš”!\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ğŸ‰ğŸ‰ğŸ‰ ì„±ê³µ!!! ğŸ‰ğŸ‰ğŸ‰\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TwdiREr_YLEa"
      },
      "source": [
        "##### ğŸ’¡ 2D tensorì—ì„œ ëŒ€ê°ì„  ìš”ì†Œ ê°€ì ¸ì˜¤ê¸° - 2D gather\n",
        "\n",
        "``` python\n",
        "ğŸ¦†\n",
        "[[1  2]\n",
        " [3  4]] 2ì°¨ì› í…ì„œì—ì„œ ëŒ€ê°ì„  ìš”ì†Œë§Œ ê°€ì ¸ì™€ì„œ [1  4] 1ì°¨ì› í…ì„œë¥¼ ë§Œë“¤ê³  ì‹¶ì–´ìš”!\n",
        "\n",
        "indexingì„ í†µí•´ í•´ë³´ë ¤ë‹ˆê¹Œ ì™ ì§€ ëª¨ë¥´ê²Œ ì•ˆë˜ë”ë¼êµ¬ìš”!\n",
        "ì¹œêµ¬ê°€ \"torch.gather\"ë¼ëŠ” í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ë¼ê³  ê·€ëœ¸í•´ì¤¬ì–´ìš”!\n",
        "```\n",
        "- [torch.gather - PyTorch ê³µì‹ ë¬¸ì„œ](https://pytorch.org/docs/stable/generated/torch.gather.html#torch.gather)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kwx3LEqKbU9M",
        "outputId": "69ac48d9-09ae-4226-fae7-6adc95575e6d"
      },
      "source": [
        "import torch\n",
        "\n",
        "A = torch.Tensor([[1, 2],\n",
        "                  [3, 4]])\n",
        "\n",
        "# torch.gather í•¨ìˆ˜ë¥¼ ì¨ì„œ í•´ë³´ì„¸ìš”!\n",
        "output = torch.gather(A,0,torch.tensor([[0,1]]))\n",
        "print(output)\n",
        "\n",
        "# ì•„ë˜ ì½”ë“œëŠ” ìˆ˜ì •í•˜ì‹¤ í•„ìš”ê°€ ì—†ìŠµë‹ˆë‹¤!\n",
        "if torch.all(output == torch.Tensor([1, 4])):\n",
        "    print(\"ğŸ‰ğŸ‰ğŸ‰ ì„±ê³µ!!! ğŸ‰ğŸ‰ğŸ‰\")\n",
        "else:\n",
        "    print(\"ğŸ¦† ë‹¤ì‹œ ë„ì „í•´ë´ìš”!\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1., 4.]])\n",
            "ğŸ‰ğŸ‰ğŸ‰ ì„±ê³µ!!! ğŸ‰ğŸ‰ğŸ‰\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SHpq-zKFdQ8j"
      },
      "source": [
        "##### ğŸ’¡ ğŸ”¥ <font color='yellow'><b>[ Optional ]</b></font> 3D tensorì—ì„œ ëŒ€ê°ì„  ìš”ì†Œ ê°€ì ¸ì˜¤ê¸° - 3D gather ğŸ”¥\n",
        "> PyTorch ìˆ™ë ¨ìì—ê²Œë„ ì•½ê°„ ë‚œì´ë„ê°€ ìˆëŠ” ë¬¸ì œì…ë‹ˆë‹¤. PyTorchì—ì„œ ë‹¤ë¤„ì§€ëŠ” ëŒ€ë¶€ë¶„ì˜ tensorëŠ” 3D ì´ìƒì¸ ë§Œí¼ ì‹œê°„ì´ ë  ë•Œ í•œë²ˆ ì¦ˆìŒ ì—°ìŠµí•´ë³´ëŠ” ê²ƒì„ ì¶”ì²œë“œë¦½ë‹ˆë‹¤.\n",
        "\n",
        "``` python\n",
        "ğŸ¦†\n",
        "2Dì—ì„œ ì„±ê³µì ìœ¼ë¡œ ëŒ€ê°ì„  ìš”ì†Œë¥¼ ëª¨ì•„ì„œ ë„ˆë¬´ ê¸°ë»ìš”!\n",
        "3Dì—ë„ ì ìš©ì‹œì¼œë³´ê³  ì‹¶ì€ë° ê°€ëŠ¥í• ê¹Œìš”?\n",
        "\n",
        "[[[1  2]\n",
        "  [3  4]]\n",
        " [[5  6]                                   [[1  4]\n",
        "  [7  8]]] 3ì°¨ì› í…ì„œì—ì„œ ëŒ€ê°ì„  ìš”ì†Œë§Œ ê°€ì ¸ì™€ì„œ [5  8]] ì´ë¼ëŠ” 2ì°¨ì› í…ì„œë¥¼ ë§Œë“¤ê³  ì‹¶ì–´ìš”!\n",
        "```\n",
        "- [torch.gather - PyTorch ê³µì‹ ë¬¸ì„œ](https://pytorch.org/docs/stable/generated/torch.gather.html#torch.gather)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N7_WCGcpdQ81",
        "outputId": "cfed1bbd-8281-4c94-bb48-986fcc689efc"
      },
      "source": [
        "import torch\n",
        "\n",
        "A = torch.Tensor([[[1, 2],\n",
        "                   [3, 4]],\n",
        "                  [[5, 6],\n",
        "                   [7, 8]]])\n",
        "\n",
        "# torch.gather í•¨ìˆ˜ë¥¼ ì¨ì„œ í•´ë³´ì„¸ìš”!\n",
        "output = torch.gather(A,3)\n",
        "\n",
        "\n",
        "# ì•„ë˜ ì½”ë“œëŠ” ìˆ˜ì •í•˜ì‹¤ í•„ìš”ê°€ ì—†ìŠµë‹ˆë‹¤!\n",
        "if torch.all(output == torch.Tensor([[1, 4], [5, 8]])):\n",
        "    print(\"ğŸ‰ğŸ‰ğŸ‰ ì„±ê³µ!!! ğŸ‰ğŸ‰ğŸ‰\")\n",
        "else:\n",
        "    print(\"ğŸ¦† ë‹¤ì‹œ ë„ì „í•´ë´ìš”!\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ğŸ¦† ë‹¤ì‹œ ë„ì „í•´ë´ìš”!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VfmnV6cRuYf5"
      },
      "source": [
        "##### ğŸ’¡ ğŸ”¥ğŸ”¥ğŸ”¥ <font color='yellow'><b>[ Optional ]</b></font> ì„ì˜ì˜ í¬ê¸°ì˜ 3D tensorì—ì„œ ëŒ€ê°ì„  ìš”ì†Œ ëª¨ìœ¼ê¸° - 3D gather ğŸ”¥ğŸ”¥ğŸ”¥\n",
        "> PyTorch ìˆ™ë ¨ìì—ê²Œë„ ì–´ë ¤ìš´ ë¬¸ì œì…ë‹ˆë‹¤. ë‹¤ì–‘í•œ í¬ê¸°ì˜ ì…ë ¥ê°’ì—ë„ ê°•ê±´í•˜ê²Œ ëŒ€ì‘í•  ìˆ˜ ìˆëŠ” ëª¨ë¸ì„ ë§Œë“œëŠ” ê³¼ì •ì—ì„œ ë¶€ë”ªíˆê²Œ ë˜ëŠ” ë¬¸ì œì´ê¸°ë„ í•©ë‹ˆë‹¤. gatherì˜ ë™ì‘ ì›ë¦¬ë¥¼ ì •í™•íˆ ìˆ™ì§€í•´ì•¼ í•˜ë©° í™•ì¥ì„± ìˆëŠ” ìœ ì—°í•œ ì½”ë“œë¥¼ ì‘ì„±í•´ì•¼ í•©ë‹ˆë‹¤.\n",
        "\n",
        "``` python\n",
        "ğŸ¦†\n",
        "ì €í¬ëŠ” ì§€ê¸ˆê¹Œì§€ ì •í•´ì§„ í¬ê¸°ì˜ ì…ë ¥ì—ì„œ ëŒ€ê°ì„  ìš”ì†Œë¥¼ ê°€ì ¸ì™”ëŠ”ë°\n",
        "ì„ì˜ì˜ í¬ê¸°ì˜ 3D í…ì„œì—ì„œë„ ë§ˆì°¬ê°€ì§€ë¡œ ëŒ€ê°ì„  ìš”ì†Œë¥¼ ê°€ì ¸ì™€ì„œ 2D í…ì„œë¥¼ ë§Œë“¤ ìˆ˜ ìˆì„ê¹Œìš”?\n",
        "```\n",
        "- [torch.gather - PyTorch ê³µì‹ ë¬¸ì„œ](https://pytorch.org/docs/stable/generated/torch.gather.html#torch.gather)\n",
        "\n",
        "ğŸ **íŒíŠ¸** ğŸ\n",
        "- ì›í•˜ëŠ” í¬ê¸°ì˜ tensorë¥¼ ë§Œë“¤ê¸° ìœ„í•´ [torch.Tensor.expand](https://pytorch.org/docs/stable/generated/torch.Tensor.expand.html?highlight=expand)ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yg_byIzJxoPC"
      },
      "source": [
        "import torch\n",
        "\n",
        "# TODO : ì„ì˜ì˜ í¬ê¸°ì˜ 3D tensorì—ì„œ ëŒ€ê°ì„  ìš”ì†Œ ê°€ì ¸ì™€ 2Dë¡œ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜ë¥¼ ë§Œë“œì„¸ìš”! \n",
        "def get_diag_element_3D(A):\n",
        "\n",
        "    output = A\n",
        "\n",
        "    return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7q9gz0d5rYiG",
        "outputId": "2c06d9c9-60fb-4ffc-9f4f-0a9edd6ab299"
      },
      "source": [
        "# TODO : ì›í•˜ëŠ” í¬ê¸°ì˜ 3D tensorë¥¼ ë§Œë“¤ì–´ë³´ë©´ì„œ ì œëŒ€ë¡œ ë™ì‘í•˜ëŠ”ì§€ í…ŒìŠ¤íŠ¸í•´ë³´ì„¸ìš”!\n",
        "C = 1\n",
        "H = 2\n",
        "W = 3\n",
        "\n",
        "# ì•„ë˜ ì½”ë“œëŠ” ìˆ˜ì •í•˜ì‹¤ í•„ìš”ê°€ ì—†ìŠµë‹ˆë‹¤!\n",
        "A = torch.tensor([i for i in range(1, C*H*W + 1)])\n",
        "A = A.view(C, H, W)\n",
        "\n",
        "print(f\"ì›ë³¸ 3D í–‰ë ¬\\n{A}\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "print(f\"ëŒ€ê°ì„  ìš”ì†Œë¥¼ ëª¨ì€ 2D í–‰ë ¬\")\n",
        "get_diag_element_3D(A)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ì›ë³¸ 3D í–‰ë ¬\n",
            "tensor([[[1, 2, 3],\n",
            "         [4, 5, 6]]])\n",
            "--------------------------------------------------\n",
            "ëŒ€ê°ì„  ìš”ì†Œë¥¼ ëª¨ì€ 2D í–‰ë ¬\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[1, 2, 3],\n",
              "         [4, 5, 6]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ORBb-HPcJnCg",
        "outputId": "bc0cf766-f4d9-4a1a-acda-4b866a912d6c"
      },
      "source": [
        "# ì•„ë˜ ì½”ë“œëŠ” ìˆ˜ì •í•˜ì‹¤ í•„ìš”ê°€ ì—†ìŠµë‹ˆë‹¤!\n",
        "A = torch.tensor([[[1]]])\n",
        "\n",
        "if torch.all(get_diag_element_3D(A) == torch.Tensor([[1]])):\n",
        "    print(\"ğŸ‰ğŸ‰ğŸ‰ ì„±ê³µ!!! ğŸ‰ğŸ‰ğŸ‰\")\n",
        "else:\n",
        "    print(\"ğŸ¦† ë‹¤ì‹œ ë„ì „í•´ë´ìš”!\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ğŸ‰ğŸ‰ğŸ‰ ì„±ê³µ!!! ğŸ‰ğŸ‰ğŸ‰\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pSbNIk3tyj8U",
        "outputId": "564db1e5-25e4-447d-f5e8-0b5e2ea65e67"
      },
      "source": [
        "# ì•„ë˜ ì½”ë“œëŠ” ìˆ˜ì •í•˜ì‹¤ í•„ìš”ê°€ ì—†ìŠµë‹ˆë‹¤!\n",
        "A = torch.Tensor([[[1, 2],\n",
        "                   [3, 4]],\n",
        "                  [[5, 6],\n",
        "                   [7, 8]]])\n",
        "\n",
        "if torch.all(get_diag_element_3D(A) == torch.Tensor([[1, 4],\n",
        "                                                     [5, 8]])):\n",
        "    print(\"ğŸ‰ğŸ‰ğŸ‰ ì„±ê³µ!!! ğŸ‰ğŸ‰ğŸ‰\")\n",
        "else:\n",
        "    print(\"ğŸ¦† ë‹¤ì‹œ ë„ì „í•´ë´ìš”!\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ğŸ¦† ë‹¤ì‹œ ë„ì „í•´ë´ìš”!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "id": "H3ewV_sBJ-nm",
        "outputId": "ff6f187c-74dc-4951-ca60-60958cb81a62"
      },
      "source": [
        "# ì•„ë˜ ì½”ë“œëŠ” ìˆ˜ì •í•˜ì‹¤ í•„ìš”ê°€ ì—†ìŠµë‹ˆë‹¤!\n",
        "A = torch.Tensor([[[1, 2, 3],\n",
        "                   [4, 5, 6]]])\n",
        "\n",
        "if torch.all(get_diag_element_3D(A) == torch.Tensor([[1, 5]])):\n",
        "    print(\"ğŸ‰ğŸ‰ğŸ‰ ì„±ê³µ!!! ğŸ‰ğŸ‰ğŸ‰\")\n",
        "else:\n",
        "    print(\"ğŸ¦† ë‹¤ì‹œ ë„ì „í•´ë´ìš”!\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-5690f10ee105>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m                    [4, 5, 6]]])\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_diag_element_3D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ğŸ‰ğŸ‰ğŸ‰ ì„±ê³µ!!! ğŸ‰ğŸ‰ğŸ‰\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (3) must match the size of tensor b (2) at non-singleton dimension 2"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fueU_tOgIzDC"
      },
      "source": [
        "# ì•„ë˜ ì½”ë“œëŠ” ìˆ˜ì •í•˜ì‹¤ í•„ìš”ê°€ ì—†ìŠµë‹ˆë‹¤!\n",
        "A = torch.tensor([[[ 1,  2,  3,  4,  5],\n",
        "                   [ 6,  7,  8,  9, 10],\n",
        "                   [11, 12, 13, 14, 15]],\n",
        "          \n",
        "                  [[16, 17, 18, 19, 20],\n",
        "                   [21, 22, 23, 24, 25],\n",
        "                   [26, 27, 28, 29, 30]]])\n",
        "\n",
        "if torch.all(get_diag_element_3D(A) == torch.Tensor([[ 1,  7, 13],\n",
        "                                                     [16, 22, 28]])):\n",
        "    print(\"ğŸ‰ğŸ‰ğŸ‰ ì„±ê³µ!!! ğŸ‰ğŸ‰ğŸ‰\")\n",
        "else:\n",
        "    print(\"ğŸ¦† ë‹¤ì‹œ ë„ì „í•´ë´ìš”!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1MKSgAWOJWvb"
      },
      "source": [
        "# ì•„ë˜ ì½”ë“œëŠ” ìˆ˜ì •í•˜ì‹¤ í•„ìš”ê°€ ì—†ìŠµë‹ˆë‹¤!\n",
        "A = torch.tensor([[[ 1,  2,  3],\n",
        "                   [ 4,  5,  6],\n",
        "                   [ 7,  8,  9],\n",
        "                   [10, 11, 12],\n",
        "                   [13, 14, 15]],\n",
        "        \n",
        "                  [[16, 17, 18],\n",
        "                   [19, 20, 21],\n",
        "                   [22, 23, 24],\n",
        "                   [25, 26, 27],\n",
        "                   [28, 29, 30]],\n",
        "        \n",
        "                  [[31, 32, 33],\n",
        "                   [34, 35, 36],\n",
        "                   [37, 38, 39],\n",
        "                   [40, 41, 42],\n",
        "                   [43, 44, 45]]])\n",
        "\n",
        "if torch.all(get_diag_element_3D(A) == torch.Tensor([[ 1,  5,  9],\n",
        "                                                     [16, 20, 24],\n",
        "                                                     [31, 35, 39]])):\n",
        "    print(\"ğŸ‰ğŸ‰ğŸ‰ ì„±ê³µ!!! ğŸ‰ğŸ‰ğŸ‰\")\n",
        "else:\n",
        "    print(\"ğŸ¦† ë‹¤ì‹œ ë„ì „í•´ë´ìš”!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6h_5Q9Xejktd"
      },
      "source": [
        "### ğŸŒ“ Documentation ì½ê¸°\n",
        "> PyTorch documentationì—ì„œ ì›í•˜ëŠ” ì •ë³´ë¥¼ ì°¾ëŠ” ê²ƒì€ ë¬¼ë¡  í™œìš©ë„ ë¬¸ì œì—†ì´ í•˜ê²Œ ë˜ì—ˆìŠµë‹ˆë‹¤! í•˜ì§€ë§Œ ì•„ì§ PyTorchê°€ ì œê³µí•˜ëŠ” ë‹¤ì–‘í•œ ê¸°ëŠ¥ì— ì–´ë–¤ ê²ƒë“¤ì´ ìˆëŠ”ì§€ ëª¨ë¦…ë‹ˆë‹¤. Custom ëª¨ë¸ì„ ì œì‘í•¨ì— ìˆì–´ PyTorchê°€ ì œê³µí•˜ëŠ” ê¸°ëŠ¥ì„ ë§ì´ ì•Œë©´ ë§ì´ ì•Œìˆ˜ë¡ ë” ë‹¤ì–‘í•˜ê³  ë©‹ì§„ ëª¨ë¸ì„ ë§Œë“¤ì–´ë‚¼ ìˆ˜ ìˆê²Œ ë©ë‹ˆë‹¤! ê·¸ë ‡ê¸°ì— ì´ë²ˆ ì„¹ì…˜ì—ì„œëŠ” Documentationì„ ì°¨ë¶„íˆ ì½ì–´ë³´ëŠ” ì‹œê°„ì„ ê°€ì§ˆ ê²ƒì…ë‹ˆë‹¤!\n",
        "\n",
        "- ğŸ“– <font color='gold' ><b>[ ì½ê¸° ]</b></font> torch ë¬¸ì„œ ì½ê¸°\n",
        "- ğŸ“– <font color='gold' ><b>[ ì½ê¸° ]</b></font> torch.linalg ë¬¸ì„œ ì½ê¸°\n",
        "- ğŸ“– <font color='gold' ><b>[ ì½ê¸° ]</b></font> torch.nn ë¬¸ì„œ ì½ê¸°\n",
        "- ğŸ‘¨â€ğŸ’» <font color='green'><b>[ ì½”ë”© ]</b></font> torch.nn `Linear Layers`\n",
        "- â“ <font color='red'><b>[ í€´ì¦ˆ ]</b></font> Linear vs LazyLinear"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ybvq8tz4769-"
      },
      "source": [
        "#### ğŸ“– <font color='gold' ><b>[ ì½ê¸° ]</b></font> torch ë¬¸ì„œ ì½ê¸°\n",
        "``` python\n",
        "ğŸ¦†\n",
        "Documentationì„ ì ê¹ ë‘˜ëŸ¬ë³´ì•˜ëŠ”ë° Python API ëª©ì°¨ì˜ torch ë¬¸ì„œì— \n",
        "ì¤‘ìš”í•˜ê³  ìœ ìš©í•œ ë‚´ìš©ë“¤ì´ ê°€ë“ ë‹´ê²¨ìˆëŠ” ê²ƒ ê°™ì•„ìš”!\n",
        "\n",
        "ê°œë°œìë“¤ì´ ì •ì„±ë“¤ì—¬ ë§Œë“¤ì–´ë†“ì€ ë‹¤ì–‘í•œ ê¸°ëŠ¥ë“¤ì´ ìˆëŠ”ë°\n",
        "ëª°ë¼ì„œ í™œìš©ë˜ì§€ ì•ŠëŠ”ë‹¤ë©´ ì •ë§ ì•„ì‰¬ìš¸ ê²ƒ ê°™ì•„ìš”!\n",
        "\n",
        "ìš°ë¦¬ ê°™ì´ ì½ì–´ë´ìš”!\n",
        "```\n",
        "\n",
        "- [torch ë¬¸ì„œ - PyTorch ê³µì‹ ë¬¸ì„œ](https://pytorch.org/docs/stable/torch.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5d8rq3BlRjmH"
      },
      "source": [
        "##### ğŸ’Œ Tensors\n",
        "> ğŸ¦† ë¶€ë•ì´ê°€ Tensorë¶€ë¶„ì„ ì •ë¦¬ í•´ì£¼ì—ˆì–´ìš”!\n",
        "\n",
        "``` python\n",
        "ğŸ¦†\n",
        "Tensors ë¶€ë¶„ì„ ì œê°€ ë¨¼ì € ì½ì–´ì„œ ì •ë¦¬ë¥¼ í•´ë‘ì—ˆì–´ìš”!\n",
        "ì œê°€ ì–´ë–»ê²Œ í•´ë‹¹ ë¶€ë¶„ì„ ì½ì–´ë‚˜ê°”ëŠ”ì§€ ê³µìœ í•´ë“œë¦´ê²Œìš”!\n",
        "```\n",
        "\n",
        "- [Tensors - PyTorch ê³µì‹ ë¬¸ì„œ](https://pytorch.org/docs/stable/torch.html#tensors)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XOvQP1sYUfci"
      },
      "source": [
        "``` python\n",
        "ğŸ¦†\n",
        "\"Tensors\"ë¼ëŠ” ì´ë¦„ì„ ë³´ë©° ì¶”ì¸¡í•´ë³´ì•˜ëŠ”ë° tensor ìë£Œêµ¬ì¡°ë¥¼ ìƒì„±í•˜ê±°ë‚˜\n",
        "ê´€ë ¨ëœ íŠ¹ì„±ì„ ì¶”ì¶œí•  ìˆ˜ ìˆëŠ” í•¨ìˆ˜ë“¤ì´ ëª¨ì—¬ìˆì„ ê²ƒ ê°™ì•„ìš”!\n",
        "\n",
        "ë¨¼ì € Tensors ë¶€ë¶„ì„ ì½ì–´ë‚˜ê°€ë©´ì„œ ì–´ë–¤ í•¨ìˆ˜ë“¤ì´ ìˆëŠ”ì§€ ë³´ì•˜ì–´ìš”!\n",
        "\"is_tensor\"ë‚˜ \"is_storage\"ì™€ ê°™ì€ í•¨ìˆ˜ëª…ì„ ë³´ì•„ì„œ ìë£Œêµ¬ì¡°ë¥¼\n",
        "ì²´í¬í•˜ëŠ” í•¨ìˆ˜ì¸ ê²ƒ ê°™ì•„ìš”!\n",
        "```\n",
        "\n",
        "![](https://github.com/IllgamhoDuck/PyTorch/blob/main/document_image/torch%20-%20tensors.png?raw=true)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_EYZfH4CX7tT"
      },
      "source": [
        "``` python\n",
        "ğŸ¦†\n",
        "\"is_tensor\"ë¼ëŠ” í•¨ìˆ˜ë¥¼ ë” ì•Œê³  ì‹¶ì–´ì„œ ë§í¬ë¥¼ íƒ€ê³  ë“¤ì–´ê°”ì–´ìš”!\n",
        "íŒŒë€ ë°•ìŠ¤ ë¶€ë¶„ì— ì„¤ëª…ì„ ì½ê³  ë‚˜ë‹ˆê¹Œ ì œê°€ ìƒê°í–ˆë˜ ëŒ€ë¡œ\n",
        "tensor ìë£Œêµ¬ì¡°ì¸ì§€ ì²´í¬í•˜ëŠ” ê²ƒì´ ë§ë„¤ìš”!\n",
        "\n",
        "ì•„ë˜ ë¹¨ê°„ ë°•ìŠ¤ ë¶€ë¶„ì— ì˜ˆì œê°€ ë‚˜ì™€ìˆë”ë¼êµ¬ìš”!\n",
        "ì½”ë“œë¥¼ ì§ì ‘ ì³ë³´ë©´ ë” ì´í•´ê°€ ì˜ë  ê²ƒ ê°™ì•„ì„œ\n",
        "ë‚ ê°œë¡œ ì§ì ‘ ì˜ˆì œë¥¼ êµ¬í˜„í•´ë³´ì•˜ì–´ìš”!\n",
        "```\n",
        "- [torch.is_tensor - PyTorch ê³µì‹ ë¬¸ì„œ](https://pytorch.org/docs/stable/generated/torch.is_tensor.html#torch.is_tensor)\n",
        "![](https://github.com/IllgamhoDuck/PyTorch/blob/main/document_image/torch%20is%20tensor.png?raw=true)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-up9L8HlYzmm",
        "outputId": "31c05015-036e-43ef-c831-578e6a35457e"
      },
      "source": [
        "import torch\n",
        "\n",
        "x = torch.tensor([1,2,3])\n",
        "y = [1, 2, 3]\n",
        "\n",
        "# ğŸ¦† ë©‹ì§€ê²Œ ë™ì‘í•˜ë„¤ìš”! ì˜ˆìƒí–ˆë˜ ëŒ€ë¡œì—ìš”!\n",
        "torch.is_tensor(x), torch.is_tensor(y) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(True, False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L-pYoFx5bYcj",
        "outputId": "8a7bbfb2-140c-48c5-e4d1-616bd83e0207"
      },
      "source": [
        "# ğŸ¦† numelì´ë¼ëŠ” í•¨ìˆ˜ë„ í•œ ë²ˆ ì¨ë³´ì•˜ì–´ìš”! ì˜ ë™ì‘í•˜ë„¤ìš”!\n",
        "torch.numel(x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6wP5qfTMUYxq"
      },
      "source": [
        "``` python\n",
        "ğŸ¦†\n",
        "ìŠ¤í¬ë¡¤ì„ ë‚´ë¦¬ë‹¤ë³´ë‹ˆê¹Œ Tensorì˜ ì†í•˜ëŠ” í•¨ìˆ˜ë“¤ì¸ë°\n",
        "ë‹¤ìŒì˜ ì„¸ë¶€ í•­ëª©ìœ¼ë¡œ ë¶„ë¥˜í–ˆë”ë¼êµ¬ìš”!\n",
        "- \"Creation Ops\"\n",
        "- \"Indexing, Slicing, Joining, Mutating Ops\"\n",
        "\n",
        "ê·¸ë˜ì„œ ì—¬ê¸°ì— ê°™ì´ ì •ë¦¬í•˜ì§€ ì•Šê³  ìƒˆë¡œìš´ ì„¹ì…˜ì„ ë§Œë“¤ì–´ì„œ ì •ë¦¬í•˜ë ¤ê³  í•´ìš”!\n",
        "```\n",
        "\n",
        "![](https://github.com/IllgamhoDuck/PyTorch/blob/main/document_image/torch%20-%20tensors%20-%20ops.png?raw=true)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jpXu3zuOcjzO"
      },
      "source": [
        "##### ğŸ’Œ Tensors - Creation Ops\n",
        "> ğŸ¦† ë¶€ë•ì´ê°€ ì •ë¦¬ë¥¼ ì´ì–´ë‚˜ê°€ê³  ìˆì–´ìš”!\n",
        "\n",
        "``` python\n",
        "ğŸ¦†\n",
        "Tensors ë¶€ë¶„ì— ì†í•˜ì§€ë©´ ë”°ë¡œ ì •ë¦¬í•˜ê³  ì‹¶ì–´ì„œ\n",
        "ì´ë ‡ê²Œ ë³„ë„ ì„¹ì…˜ìœ¼ë¡œ ë‚˜ëˆ„ì–´ë†“ì•˜ì–´ìš”!\n",
        "```\n",
        "- [Tensors - PyTorch ê³µì‹ ë¬¸ì„œ](https://pytorch.org/docs/stable/torch.html#tensors)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rJZJuicGdHwm"
      },
      "source": [
        "``` python\n",
        "ğŸ¦†\n",
        "ì´ë¦„ì„ ë³´ë©´ \"Tensors\"ë¼ëŠ” ìë£Œêµ¬ì¡°ë¥¼ ë§Œë“œëŠ” í•¨ìˆ˜ë“¤ì´ ëª¨ì—¬ìˆê² ì£ ?\n",
        "ì €ëŠ” ë¨¼ì € ì•„ë˜ ê·¸ë¦¼ì—ì„œ ë¹¨ê°„ ë°•ìŠ¤ ì¹œ ë¶€ë¶„ì„ ìœ ì‹¬íˆ ì½ì–´ë³´ì•˜ì–´ìš”!\n",
        "\"í•¨ìˆ˜ëª…\"ê³¼ ìš°ì¸¡ì— \"í•¨ìˆ˜ì— ëŒ€í•œ ìš”ì•½ ì„¤ëª…\"ì„ ì½ì–´ë‚˜ê°”ì£ !\n",
        "```\n",
        "\n",
        "- âœ… í•¨ìˆ˜ì™€ ìš”ì•½ ì„¤ëª…ì„ ê°€ë³ê²Œ í›‘ì–´ë³´ì„¸ìš”!\n",
        "\n",
        "![](https://github.com/IllgamhoDuck/PyTorch/blob/main/document_image/torch%20-%20tensors%20-%20creation%20ops.png?raw=true)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5b6lTFnCjQwc"
      },
      "source": [
        "```python\n",
        "ğŸ¦†\n",
        "ë­ë“ ì§€ ì§ì ‘ ì†ìœ¼ë¡œ ì³ë³¸ê²Œ ë” ì´í•´ê°€ ì˜ê°€ê³  ê¸°ì–µì— ì˜¤ë˜ ë‚¨ë”ë¼êµ¬ìš”!\n",
        "ê·¸ë˜ì„œ í•¨ìˆ˜ë“¤ì„ ì­‰ ë‘˜ëŸ¬ë³´ê³  3ê°€ì§€ í•¨ìˆ˜ì˜ ì˜ˆì œë¥¼ êµ¬í˜„í•´ë³´ì•˜ì–´ìš”!\n",
        "```\n",
        "\n",
        "- âœ… <font color='yellow'><b>[ Optional ]</b></font> ì›í•˜ëŠ” 3ê°œ í•¨ìˆ˜ë¥¼ ê³¨ë¼ì„œ ì˜ˆì œ ì½”ë“œë¥¼ ëŒë ¤ë³´ì„¸ìš”!\n",
        "    - from_numpy\n",
        "    - zeros\n",
        "    - zeros_like\n",
        "\n",
        "\n",
        "- [torch.from_numpy - PyTorch ê³µì‹ ë¬¸ì„œ](https://pytorch.org/docs/stable/generated/torch.from_numpy.html#torch.from_numpy)\n",
        "- [torch.zeros - PyTorch ê³µì‹ ë¬¸ì„œ](https://pytorch.org/docs/stable/generated/torch.zeros.html#torch.zeros)\n",
        "- [torch.zeros_like - PyTorch ê³µì‹ ë¬¸ì„œ](https://pytorch.org/docs/stable/generated/torch.zeros_like.html#torch.zeros_like)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vhp7vsgE8FY4",
        "outputId": "4d627900-40b0-45f7-b90f-b6f8afc291a6"
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "# ğŸ¦† torch.from_numpy\n",
        "a = np.array([1,2,3])\n",
        "t = torch.from_numpy(a)\n",
        "t"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 2, 3])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1mzqAJDGm9Hd",
        "outputId": "94661fa9-baff-4dcd-b52f-f7477290ed3f"
      },
      "source": [
        "# ğŸ¦† torch.zeros\n",
        "torch.zeros(2, 3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0., 0.],\n",
              "        [0., 0., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BA2pv3pFiu3M",
        "outputId": "0aae08fe-2d6c-4332-e925-d2b4dcf7326b"
      },
      "source": [
        "# ğŸ¦† torch.zeros_like\n",
        "torch.zeros_like(t)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 0, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yBmtQly_nqR7"
      },
      "source": [
        "##### ğŸ’Œ Tensors - Indexing, Slicing, Joining, Mutating Ops\n",
        "> ğŸ¦† ë¶€ë•ì´ê°€ ë§ˆì € ì •ë¦¬í•´ë†“ì•˜ì–´ìš”!\n",
        "\n",
        "``` python\n",
        "ğŸ¦†\n",
        "Tensors í•­ëª©ì˜ ë§ˆì§€ë§‰ ì„¸ë¶€ í•­ëª©ì´ì—ìš”!\n",
        "Indexing, Slicing ë“± ë³´ê¸°ë§Œ í•´ë„ ì¤‘ìš”í•œ í•¨ìˆ˜ë“¤ì´ ëª¨ì—¬ìˆì„ ê²ƒ ê°™ì•„ìš”!\n",
        "```\n",
        "\n",
        "- [Tensors - PyTorch ê³µì‹ ë¬¸ì„œ](https://pytorch.org/docs/stable/torch.html#tensors)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h4iVxzyHnqR-"
      },
      "source": [
        "``` python\n",
        "ğŸ¦†\n",
        "ì½ë‹¤ë³´ë‹ˆê¹Œ ê°€ë”ì€ ì˜ˆì œ ì½”ë“œê°€ ì—†ëŠ” í•¨ìˆ˜ê°€ ì¢…ì¢… ì„ì—¬ìˆì–´ìš”!\n",
        "ì´ëŸ´ë•ŒëŠ” í•¨ìˆ˜ ì„¤ëª…ì„ ë” ìì„¸íˆ ì½ê³  êµ¬í˜„í•´ë´ì•¼ í•  ê±° ê°™ì•„ìš”!\n",
        "```\n",
        "\n",
        "- âœ… í•¨ìˆ˜ì™€ ìš”ì•½ ì„¤ëª…ì„ ê°€ë³ê²Œ í›‘ì–´ë³´ì„¸ìš”!\n",
        "- âœ… <font color='yellow'><b>[ Optional ]</b></font> ì›í•˜ëŠ” 3ê°œ í•¨ìˆ˜ë¥¼ ê³¨ë¼ì„œ ì˜ˆì œ ì½”ë“œë¥¼ ëŒë ¤ë³´ì„¸ìš”!\n",
        "    - chunk\n",
        "    - swapdims\n",
        "    - zeros_like\n",
        "\n",
        "\n",
        "- [torch.chunk - PyTorch ê³µì‹ ë¬¸ì„œ](https://pytorch.org/docs/stable/generated/torch.chunk.html#torch.chunk)\n",
        "- [torch.swapdims - PyTorch ê³µì‹ ë¬¸ì„œ](https://pytorch.org/docs/stable/generated/torch.swapdims.html#torch.swapdims)\n",
        "- [torch.Tensor.scatter_ - PyTorch ê³µì‹ ë¬¸ì„œ](https://pytorch.org/docs/stable/generated/torch.Tensor.scatter_.html#torch.Tensor.scatter_)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nq9zOgoznqR_",
        "outputId": "89ff7c58-99df-4c44-816d-c1b9f4c8f799"
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "# ğŸ¦† torch.chunk\n",
        "t = torch.tensor([[1, 2, 3],\n",
        "                  [4, 5, 6]])\n",
        "\n",
        "# ğŸ¦† ì˜ˆì œëŠ” ì—†ì§€ë§Œ documentationì„ ì½ì–´ì„œ êµ¬í˜„í•´ë³´ì•˜ì–´ìš”!\n",
        "print(torch.chunk(t, 2, 0))\n",
        "print(\" \")\n",
        "print(torch.chunk(t, 3, 1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(tensor([[1, 2, 3]]), tensor([[4, 5, 6]]))\n",
            " \n",
            "(tensor([[1],\n",
            "        [4]]), tensor([[2],\n",
            "        [5]]), tensor([[3],\n",
            "        [6]]))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t7Qy8zEPnqSA",
        "outputId": "3a33a4e1-590e-4948-8f4b-cebeade075e0"
      },
      "source": [
        "# ğŸ¦† torch.swapdims\n",
        "x = torch.tensor([[[0,1],[2,3]],[[4,5],[6,7]]])\n",
        "x\n",
        "x.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 2, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8o6mHeHeutTh",
        "outputId": "59ccb80a-3afb-40e6-a721-bdfa3f41ace0"
      },
      "source": [
        "torch.swapdims(x, 0, 1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[0, 1],\n",
              "         [4, 5]],\n",
              "\n",
              "        [[2, 3],\n",
              "         [6, 7]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8TBo37wDu4xW",
        "outputId": "5b05ec9f-16f0-4055-8946-ab25cb700573"
      },
      "source": [
        "torch.swapdims(x, 0, 2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[0, 4],\n",
              "         [2, 6]],\n",
              "\n",
              "        [[1, 5],\n",
              "         [3, 7]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M08dZW2fnqSB",
        "outputId": "a996df29-90a2-4fc4-f77a-1208f90e9c52"
      },
      "source": [
        "# ğŸ¦† torch.Tensor.scatter_\n",
        "src = torch.arange(1, 11).reshape((2, 5))\n",
        "src"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 1,  2,  3,  4,  5],\n",
              "        [ 6,  7,  8,  9, 10]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z6WstSp-wLU4",
        "outputId": "917c1b8c-e892-41c9-ab4d-f9f1198a920e"
      },
      "source": [
        "# ğŸ¦† ìš°ë¦¬ê°€ í•¨ê»˜ ê³µë¶€í–ˆë˜ gatherì™€ ë¹„ìŠ·í•œ ëŠë‚Œì´ ë‚˜ìš”!\n",
        "index = torch.tensor([[0, 1, 2, 0]])\n",
        "torch.zeros(3, 5, dtype=src.dtype).scatter_(0, index, src)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 0, 0, 4, 0],\n",
              "        [0, 2, 0, 0, 0],\n",
              "        [0, 0, 3, 0, 0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R0yIEAw-xAdV",
        "outputId": "ec91babc-9a61-4e1c-fbd9-9046fc7f907b"
      },
      "source": [
        "index = torch.tensor([[0, 1, 2], [0, 1, 4]])\n",
        "torch.zeros(3, 5, dtype=src.dtype).scatter_(1, index, src)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 2, 3, 0, 0],\n",
              "        [6, 7, 0, 0, 8],\n",
              "        [0, 0, 0, 0, 0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jPvOek5YxfRg"
      },
      "source": [
        "##### ğŸ’Œ Random sampling\n",
        "\n",
        "``` python\n",
        "ğŸ¦†\n",
        "ëœë¤ í•¨ìˆ˜ë“¤ì€ ì´ˆê¸°í™”, ìƒ˜í”Œë§ ë“± ë‹¤ì–‘í•œ ê³³ì— í™œìš©í•  ìˆ˜ ìˆì„ ê²ƒ ê°™ì•„ìš”!\n",
        "ìœ ìš©í•œë§Œí¼ ëˆˆì—¬ê²¨ì„œ ë´ë‘ë©´ ë‚˜ì¤‘ì— ì˜ ì“°ì¼ ê²ƒ ê°™ì•„ìš”!\n",
        "```\n",
        "\n",
        "- [Random sampling - PyTorch ê³µì‹ ë¬¸ì„œ](https://pytorch.org/docs/stable/torch.html#random-sampling)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LAcT0HckxfR7"
      },
      "source": [
        "- âœ… í•¨ìˆ˜ì™€ ìš”ì•½ ì„¤ëª…ì„ ê°€ë³ê²Œ í›‘ì–´ë³´ì„¸ìš”!\n",
        "- âœ… <font color='yellow'><b>[ Optional ]</b></font> ì›í•˜ëŠ” 3ê°œ í•¨ìˆ˜ë¥¼ ê³¨ë¼ì„œ ì˜ˆì œ ì½”ë“œë¥¼ ëŒë ¤ë³´ì„¸ìš”!\n",
        "    - seed\n",
        "    - manual_seed\n",
        "    - initial_seed\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8TCXjpanaRdF",
        "outputId": "e140a608-d9dc-4a21-cbf5-1effcd117510"
      },
      "source": [
        "import torch\n",
        "torch.seed()\n",
        "\n",
        "torch.initial_seed()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "14873066720050693234"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VBC_HD024zT7"
      },
      "source": [
        "##### ğŸ’Œ Math operations - Pointwise Ops\n",
        "\n",
        "``` python\n",
        "ğŸ¦†\n",
        "ì—°ì‚°ê³¼ ê´€ë ¨ëœ ë‹¤ì–‘í•œ í•¨ìˆ˜ë“¤ì´ ëª¨ì—¬ìˆë„¤ìš”!\n",
        "pointwiseë¡œ ì—°ì‚°ì²˜ë¦¬ë¥¼ í•˜ëŠ” í•¨ìˆ˜ë“¤ì¸ê°€ë´ìš”!\n",
        "```\n",
        "\n",
        "- [Math operations - PyTorch ê³µì‹ ë¬¸ì„œ](https://pytorch.org/docs/stable/torch.html#math-operations)\n",
        "- [Pointwise - Wikipedia](https://en.wikipedia.org/wiki/Pointwise)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YQDWkg-S4zT9"
      },
      "source": [
        "- âœ… í•¨ìˆ˜ì™€ ìš”ì•½ ì„¤ëª…ì„ ê°€ë³ê²Œ í›‘ì–´ë³´ì„¸ìš”!\n",
        "- âœ… <font color='yellow'><b>[ Optional ]</b></font> ì›í•˜ëŠ” 3ê°œ í•¨ìˆ˜ë¥¼ ê³¨ë¼ì„œ ì˜ˆì œ ì½”ë“œë¥¼ ëŒë ¤ë³´ì„¸ìš”!\n",
        "    - torch.abs()\n",
        "    - torch.acos()\n",
        "    - torch.asin()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zLFA5jeb7dcB"
      },
      "source": [
        "##### ğŸ’Œ Math operations - Reduction Ops\n",
        "\n",
        "``` python\n",
        "ğŸ¦†\n",
        "í•¨ìˆ˜ë“¤ì´ ì¡°ê±´ì— ë”°ë¼ tensorì—ì„œ íŠ¹ì • ê°’ë§Œì„ ê°€ì ¸ì˜¤ê±°ë‚˜\n",
        "ì—°ì‚°ì„ í†µí•´ì„œ í¬ê¸°ë¥¼ ì¤„ì´ëŠ” ë“± ì£¼ì–´ì§„ tensorì˜ í¬ê¸°ë¥¼ ì¤„ì—¬ì„œ\n",
        "ì¶œë ¥í•˜ê¸° ë•Œë¬¸ì— reductionì˜ ì´ë¦„ì´ ë¶™ì€ ê²ƒ ê°™ì•„ìš”!\n",
        "```\n",
        "\n",
        "- [Math operations - PyTorch ê³µì‹ ë¬¸ì„œ](https://pytorch.org/docs/stable/torch.html#math-operations)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "poy8CCOC7dcC"
      },
      "source": [
        "- âœ… í•¨ìˆ˜ì™€ ìš”ì•½ ì„¤ëª…ì„ ê°€ë³ê²Œ í›‘ì–´ë³´ì„¸ìš”!\n",
        "- âœ… <font color='yellow'><b>[ Optional ]</b></font> ì›í•˜ëŠ” 3ê°œ í•¨ìˆ˜ë¥¼ ê³¨ë¼ì„œ ì˜ˆì œ ì½”ë“œë¥¼ ëŒë ¤ë³´ì„¸ìš”!\n",
        "    - torch.argmax()\n",
        "    - torch.argmin()\n",
        "    - torch.amax()\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-S598A0RjNsc",
        "outputId": "e86ba06e-d40a-4f4b-ac66-68bb41ba5247"
      },
      "source": [
        "import torch\n",
        "\n",
        "a = torch.rand(4,4)\n",
        "print(a)\n",
        "torch.argmax(a,dim=1)\n",
        "torch.amax(a,1)\n",
        "torch.max(a,1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.3322, 0.2981, 0.2168, 0.8911],\n",
            "        [0.6079, 0.7255, 0.9586, 0.7056],\n",
            "        [0.4480, 0.6878, 0.9487, 0.9473],\n",
            "        [0.3409, 0.9462, 0.8056, 0.5572]])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.return_types.max(values=tensor([0.8911, 0.9586, 0.9487, 0.9462]), indices=tensor([3, 2, 2, 1]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IJNyfmll_h_o"
      },
      "source": [
        "##### ğŸ’Œ Math operations - Comparison Ops\n",
        "\n",
        "``` python\n",
        "ğŸ¦†\n",
        "ì‘ì€ì§€ í°ì§€ ì´ëŸ° ë¹„êµì™€ ê´€ë ¨ëœ ê¸°ëŠ¥ì„ í¬í•¨í•˜ëŠ” í•¨ìˆ˜ë“¤ì²˜ëŸ¼ ë³´ì—¬ìš”!\n",
        "if else ë¬¸ë§Œí¼ ìœ ìš©í•  ê²ƒ ê°™ì•„ìš”!\n",
        "```\n",
        "\n",
        "- [Math operations - PyTorch ê³µì‹ ë¬¸ì„œ](https://pytorch.org/docs/stable/torch.html#math-operations)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rOStUYzm_h_p"
      },
      "source": [
        "- âœ… í•¨ìˆ˜ì™€ ìš”ì•½ ì„¤ëª…ì„ ê°€ë³ê²Œ í›‘ì–´ë³´ì„¸ìš”!\n",
        "- âœ… <font color='yellow'><b>[ Optional ]</b></font> ì›í•˜ëŠ” 3ê°œ í•¨ìˆ˜ë¥¼ ê³¨ë¼ì„œ ì˜ˆì œ ì½”ë“œë¥¼ ëŒë ¤ë³´ì„¸ìš”!\n",
        "    - torch.argsort()\n",
        "    - \n",
        "    - "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S0YipGtkkssS",
        "outputId": "73befdac-f645-4e0a-e4da-9fe18aa25386"
      },
      "source": [
        "import torch\n",
        "# torch.seed()\n",
        "# a = torch.randn(4,4)\n",
        "print(a)\n",
        "torch.argsort(a,dim=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-0.2120, -1.7395, -0.1270, -1.6704],\n",
            "        [-0.1977,  0.2853, -0.2305, -1.0576],\n",
            "        [-0.6735, -0.9760,  0.4633, -0.3533],\n",
            "        [-0.5711, -0.3795,  0.0891, -0.3534]])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 3, 0, 2],\n",
              "        [3, 2, 0, 1],\n",
              "        [1, 0, 3, 2],\n",
              "        [0, 1, 3, 2]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qrEsHFT2FRDj"
      },
      "source": [
        "##### ğŸ’Œ Math operations - Other Operations\n",
        "\n",
        "``` python\n",
        "ğŸ¦†\n",
        "íŠ¹ì •í•œ ì„¸ë¶€ í•­ëª©ìœ¼ë¡œ ë¶„ë¥˜í•˜ê¸° í˜ë“  í•¨ìˆ˜ë“¤ì„ ëª¨ì•„ë†¨ë‚˜ë´ìš”!\n",
        "ìœ ìš©í•´ë³´ì´ëŠ” í•¨ìˆ˜ ëª‡ëª‡ ëˆˆì— ë„ë„¤ìš”!\n",
        "íŠ¹íˆ \"einsum\"ì€ ë°°ì¹˜ ë‹¨ìœ„ì˜ í…ì„œ ê³„ì‚°ì— ìœ ìš©í•´ë³´ì—¬ì„œ\n",
        "ì™ ì§€ ê¸°ì–µí•´ë‘ë©´ custom ëª¨ë¸ì„ ë§Œë“¤ë•Œ ì‚¬ìš©í•  ì¼ì´ ìˆì„ ê²ƒ ê°™ì•„ìš”!\n",
        "```\n",
        "\n",
        "- [Math operations - PyTorch ê³µì‹ ë¬¸ì„œ](https://pytorch.org/docs/stable/torch.html#math-operations)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O9dwBl4SFRDk"
      },
      "source": [
        "- âœ… í•¨ìˆ˜ì™€ ìš”ì•½ ì„¤ëª…ì„ ê°€ë³ê²Œ í›‘ì–´ë³´ì„¸ìš”!\n",
        "- âœ… <font color='yellow'><b>[ Optional ]</b></font> ì›í•˜ëŠ” 3ê°œ í•¨ìˆ˜ë¥¼ ê³¨ë¼ì„œ ì˜ˆì œ ì½”ë“œë¥¼ ëŒë ¤ë³´ì„¸ìš”!\n",
        "    - \n",
        "    - torch.einsum()\n",
        "    - "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tQtxvUhcnotR",
        "outputId": "c528471a-3f5a-4d93-bbea-08d2e3b871ea"
      },
      "source": [
        "import torch\n",
        "torch.einsum('ii',torch.rand(4,4))\n",
        "\n",
        "x = torch.arange(9).reshape(3,3)\n",
        "# print(x)\n",
        "torch.einsum('ii',x)\n",
        "\n",
        "#outer product\n",
        "x = torch.arange(5)\n",
        "print(x)\n",
        "y = torch.arange(4)\n",
        "print(y)\n",
        "torch.einsum('i,j->ij',x,y)\n",
        "\n",
        "# batch matrix multiplication\n",
        "As = torch.arange(30).reshape(3,2,5)\n",
        "print(As)\n",
        "Bs = torch.arange(60).reshape(3,5,4)\n",
        "print(Bs)\n",
        "torch.einsum('bij,bjk->bik',As,Bs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0, 1, 2, 3, 4])\n",
            "tensor([0, 1, 2, 3])\n",
            "tensor([[[ 0,  1,  2,  3,  4],\n",
            "         [ 5,  6,  7,  8,  9]],\n",
            "\n",
            "        [[10, 11, 12, 13, 14],\n",
            "         [15, 16, 17, 18, 19]],\n",
            "\n",
            "        [[20, 21, 22, 23, 24],\n",
            "         [25, 26, 27, 28, 29]]])\n",
            "tensor([[[ 0,  1,  2,  3],\n",
            "         [ 4,  5,  6,  7],\n",
            "         [ 8,  9, 10, 11],\n",
            "         [12, 13, 14, 15],\n",
            "         [16, 17, 18, 19]],\n",
            "\n",
            "        [[20, 21, 22, 23],\n",
            "         [24, 25, 26, 27],\n",
            "         [28, 29, 30, 31],\n",
            "         [32, 33, 34, 35],\n",
            "         [36, 37, 38, 39]],\n",
            "\n",
            "        [[40, 41, 42, 43],\n",
            "         [44, 45, 46, 47],\n",
            "         [48, 49, 50, 51],\n",
            "         [52, 53, 54, 55],\n",
            "         [56, 57, 58, 59]]])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 120,  130,  140,  150],\n",
              "         [ 320,  355,  390,  425]],\n",
              "\n",
              "        [[1720, 1780, 1840, 1900],\n",
              "         [2420, 2505, 2590, 2675]],\n",
              "\n",
              "        [[5320, 5430, 5540, 5650],\n",
              "         [6520, 6655, 6790, 6925]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8r1QkKGGJobo"
      },
      "source": [
        "##### ğŸ’Œ Math operations - BLAS and LAPACK Operations\n",
        "\n",
        "``` python\n",
        "ğŸ¦†\n",
        "ìœ„í˜‘ì ìœ¼ë¡œ ë³´ì´ëŠ” ì´ë¦„ì— ë†€ë¼ì…¨ì£ ? ì €ë„ ë†€ëì–´ìš”!\n",
        "\n",
        "- \"BLAS\" - Basic Linear Algebra Subprograms\n",
        "- \"LAPACK\"â€‰- Linear Algebra PACKage\n",
        "\n",
        "ì°¾ì•„ë³´ì•˜ëŠ”ë° ì´ëŠ” ëª¨ë‘ ì„ í˜•ëŒ€ìˆ˜í•™(Linear Algebra)ì™€ ì—°ê´€ëœ ì´ë¦„ì´ì—ìš”!\n",
        "í•¨ìˆ˜ë¥¼ ì‚´í´ë³´ë‹ˆê¹Œ ì¹œìˆ™í•¨ì´ ëŠê»´ì ¸ìš”!\n",
        "```\n",
        "\n",
        "- [Math operations - PyTorch ê³µì‹ ë¬¸ì„œ](https://pytorch.org/docs/stable/torch.html#math-operations)\n",
        "- [BLAS - netlib](http://www.netlib.org/blas/)\n",
        "- [LAPACK - netlib](http://www.netlib.org/lapack/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ZVGkAp5Jobp"
      },
      "source": [
        "- âœ… í•¨ìˆ˜ì™€ ìš”ì•½ ì„¤ëª…ì„ ê°€ë³ê²Œ í›‘ì–´ë³´ì„¸ìš”!\n",
        "- âœ… <font color='yellow'><b>[ Optional ]</b></font> ì›í•˜ëŠ” 3ê°œ í•¨ìˆ˜ë¥¼ ê³¨ë¼ì„œ ì˜ˆì œ ì½”ë“œë¥¼ ëŒë ¤ë³´ì„¸ìš”!\n",
        "    - \n",
        "    - \n",
        "    - "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qbzHU6WTJobq",
        "outputId": "b120dcf4-4f10-4005-9d29-65e80972961d"
      },
      "source": [
        "import torch\n",
        "\n",
        "M = torch.randn(2, 3)\n",
        "mat1 = torch.randn(2, 3)\n",
        "mat2 = torch.randn(3, 3)\n",
        "torch.addmm(M, mat1, mat2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.2715, -0.1265, -1.1123],\n",
              "        [ 1.0081,  0.3057,  0.7136]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uRk9bcnqJobr",
        "outputId": "eb6b9287-c99a-4a7b-d719-d17de377f644"
      },
      "source": [
        "a = torch.eye(10)\n",
        "torch.matrix_rank(a)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: UserWarning: torch.matrix_rank is deprecated in favor of torch.linalg.matrix_rankand will be removed in a future PyTorch release. The parameter 'symmetric' was renamed in torch.linalg.matrix_rank to 'hermitian'. (Triggered internally at  /pytorch/aten/src/ATen/native/LinearAlgebra.cpp:438.)\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g5GegxahJobr",
        "outputId": "39756d58-4f11-402f-8a5c-2b40e05c52d0"
      },
      "source": [
        "b = torch.eye(10)\n",
        "b[0, 0] = 0\n",
        "torch.matrix_rank(b)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(9)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7_b9Xu6qJobs",
        "outputId": "ecf9704e-73ea-4d45-901a-e0f06b0513e3"
      },
      "source": [
        "a = torch.tensor([[12., -51, 4],\n",
        "                  [6, 167, -68],\n",
        "                  [-4, 24, -41]])\n",
        "q, r = torch.qr(a)\n",
        "q"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.8571,  0.3943,  0.3314],\n",
              "        [-0.4286, -0.9029, -0.0343],\n",
              "        [ 0.2857, -0.1714,  0.9429]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W5mBhSmmJobs",
        "outputId": "ddbd5f95-6503-45d4-ccbb-d2523d9c4f7a"
      },
      "source": [
        "r"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ -14.0000,  -21.0000,   14.0000],\n",
              "        [   0.0000, -175.0000,   70.0000],\n",
              "        [   0.0000,    0.0000,  -35.0000]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e9SbUGKmJobs",
        "outputId": "593ac454-8315-497b-d5b5-f770c0bf1389"
      },
      "source": [
        "torch.mm(q, r).round()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 12., -51.,   4.],\n",
              "        [  6., 167., -68.],\n",
              "        [ -4.,  24., -41.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C_2T-Q3EJobt",
        "outputId": "248583c8-600a-4c8d-f67e-b3f05b46d210"
      },
      "source": [
        "torch.allclose(torch.matmul(q, r), a)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GGZDh_Tw4tpS"
      },
      "source": [
        "#### ğŸ“– <font color='gold' ><b>[ ì½ê¸° ]</b></font> torch.linalg ë¬¸ì„œ ì½ê¸°\n",
        "``` python\n",
        "ğŸ¦†\n",
        "torch ë¬¸ì„œë¥¼ ì½ìœ¼ë©´ì„œ ë³´ì•˜ë˜ ì„ í˜•ëŒ€ìˆ˜í•™(linear algebra) ê´€ë ¨ í•¨ìˆ˜ë“¤ì´\n",
        "\"torch.linalg\"ë¡œ ìƒˆë¡­ê²Œ ì •ë¦¬ë˜ë©´ì„œ ê¸°ì¡´ \"torch\"ì— ì†í•´ìˆë˜\n",
        "ì„ í˜•ëŒ€ìˆ˜í•™ ê¸°ëŠ¥ë“¤ì´ deprecated ëœ ê²ƒ ê°™ì•„ìš”!\n",
        "\n",
        "ë””ë ‰í† ë¦¬ê°€ ì´ë™í–ˆì„ ë¿ í•¨ìˆ˜ëª…ì€ ì´ë¯¸ ì¹œìˆ™í•˜ê²Œ ëŠê»´ì§€ë„¤ìš”! ê·¸ë ‡ì§€ ì•Šë‚˜ìš”?\n",
        "```\n",
        "\n",
        "- [torch.linalg ë¬¸ì„œ - PyTorch ê³µì‹ ë¬¸ì„œ](https://pytorch.org/docs/stable/linalg.html#)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tOg5zeq46J0A"
      },
      "source": [
        "- âœ… torch.linalg í•˜ìœ„ ëª©ì°¨ë¥¼ í•œë²ˆ í›‘ì–´ë³´ì„¸ìš”!\n",
        "    - Matrix Properties\n",
        "    - Decompositions\n",
        "    - Solvers\n",
        "    - Inverses\n",
        "    - Matrix Products\n",
        "    - Tensor Operations\n",
        "    - Experimental Functions\n",
        "- âœ… ê° í•˜ìœ„ ëª©ì°¨ë³„ë¡œ ì–´ë–¤ í•¨ìˆ˜ê°€ ì†í•´ìˆëŠ”ì§€ í›‘ì–´ë³´ì„¸ìš”!\n",
        "    - ex) Matrix Propertiesì—ëŠ” `norm`, `vector_norm` ë“±ì´ ìˆë‹¤\n",
        "    - ex) Decompositionsì—ëŠ” `cholesky`, `qr`, `svd` ë“±ì´ ìˆë‹¤\n",
        "    - ex) Inversesì—ëŠ” `inv`, `pinv` 2ê°œì˜ í•¨ìˆ˜ê°€ ìˆë‹¤"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HXUIf4hw8R_A"
      },
      "source": [
        "#### ğŸ“– <font color='gold' ><b>[ ì½ê¸° ]</b></font> torch.nn ë¬¸ì„œ ì½ê¸°\n",
        "``` python\n",
        "ğŸ¦†\n",
        "ì„¤ëª…ì— ê·¸ë˜í”„ë¥¼ ë§Œë“¤ê¸° ìœ„í•œ \"basic building block\"ì´ë¼ê³  ì“°ì—¬ìˆì–´ìš”!\n",
        "\n",
        "ì§€ê¸ˆê¹Œì§€ ì €í¬ê°€ í™•ì¸í•œ ë‹¤ì–‘í•œ í•¨ìˆ˜ë“¤ì„ ì˜ í™œìš©í•˜ë©´\n",
        "ì—¬ê¸°ì„œ ë§í•˜ëŠ” \"basic building block\"ì„ ë§Œë“¤ ìˆ˜ ìˆê² ì§€ë§Œ ì‹œê°„ì´ ê±¸ë¦¬ë‹ˆê¹Œ\n",
        "PyTorchì—ì„œ ë¯¸ë¦¬ ë§Œë“¤ì–´ë‘ê³  ì´ë¥¼ \"torch.nn\"ìœ¼ë¡œ ë¬¶ì–´ë†“ì€ ê²ƒ ê°™ì•„ìš”! \n",
        "\n",
        "ì—¬ê¸°ì„œ ì œê³µí•´ì£¼ëŠ” ë¸”ëŸ­ë“¤ì„ ì˜ ì´ìš©í•˜ë©´ ê·¸ë˜í”„ë¼ëŠ” ë”¥ëŸ¬ë‹ ëª¨ë¸ì„ ë§Œë“¤ ìˆ˜ ìˆì„ ê²ƒ ê°™ì•„ìš”!\n",
        "\n",
        "ë§¤ìš° ì¤‘ìš”í•´ë³´ì´ì§€ë§Œ ë‚´ìš©ì´ ì •ë§ ë§ë„¤ìš”!\n",
        "ì´ ë§ì€ ë‚´ìš©ì„ ë‹¤ ë³¼ ìˆ˜ëŠ” ì—†ìœ¼ë‹ˆê¹Œ ê°„ë‹¨í•˜ê²Œ í›‘ì–´ë³´ê¸°ë§Œ í•´ìš”!\n",
        "ì§€ê¸ˆì€ ìƒì†Œí•˜ê³  ì–´ë ¤ì›Œë³´ì—¬ë„ ì°¨ì¸° ìµìˆ™í•´ì§ˆê²Œ í‹€ë¦¼ì—†ì–´ìš”!\n",
        "```\n",
        "\n",
        "- [torch.nn ë¬¸ì„œ - PyTorch ê³µì‹ ë¬¸ì„œ](https://pytorch.org/docs/stable/nn.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MQjpdQWB8R_S"
      },
      "source": [
        "- âœ… torch.nnì˜ í•˜ìœ„ ëª©ì°¨ë¥¼ í•œë²ˆ í›‘ì–´ë³´ì„¸ìš”!\n",
        "- âœ… ê° í•˜ìœ„ ëª©ì°¨ë³„ë¡œ ì–´ë–¤ ë ˆì´ì–´(Layer)í˜¹ì€ í•¨ìˆ˜(Function)ê°€ ì†í•´ìˆëŠ”ì§€ í›‘ì–´ë³´ì„¸ìš”!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R68OFoe8BzbF"
      },
      "source": [
        "#### ğŸ‘¨â€ğŸ’» <font color='green'><b>[ ì½”ë”© ]</b></font> torch.nn `Linear Layers`\n",
        "\n",
        "``` python\n",
        "ğŸ¦†\n",
        "ê°€ë³ê²Œ ì½ê¸°ë§Œ í•˜ë ¤ê³  í–ˆëŠ”ë° ê·¸ë˜ë„ í•œ ë‘ê°œëŠ” ì§ì ‘ ì˜ˆì œë¥¼ ë”°ë¼í•´ë³´ê³  ì‹¶ì–´ìš”!\n",
        "ë”¥ëŸ¬ë‹ì„ ê³µë¶€í•  ë•Œ ìì£¼ ë‚˜ì˜¤ë˜ y = WX + b ë¼ëŠ” ê³µì‹ì´ ê¸°ì–µë‚˜ì‹œë‚˜ìš”?\n",
        "ì´ linear transformationì„ êµ¬í˜„í•´ë†“ì€ \"nn.Linear\"ê°€ ì†í•´ì‡ëŠ”\n",
        "\"Linear Layers\" í•­ëª©ì„ ì ê¹ë§Œ ê°™ì´ ì‚´í´ë´ìš”!\n",
        "```\n",
        "\n",
        "- [torch.nn Linear Layers - PyTorch ê³µì‹ ë¬¸ì„œ](https://pytorch.org/docs/stable/nn.html#linear-layers)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rZmymVenGzXd"
      },
      "source": [
        "##### ğŸ’¡ nn.Linear\n",
        "\n",
        "\n",
        "``` python\n",
        "ğŸ¦†\n",
        "ì•ìœ¼ë¡œ ì™ ì§€ ì´ \"nn.Linear\"ëŠ” ì •ë§ ìì£¼ ë§ˆì£¼ì¹  ê²ƒë§Œ ê°™ì€ ì˜ˆê°ì´ ë“¤ì–´ìš”!\n",
        "```\n",
        "\n",
        "- [torch.nn.Linear - PyTorch ê³µì‹ ë¬¸ì„œ](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear)\n",
        "\n",
        "ğŸ **íŒíŠ¸** ğŸ\n",
        "- PyTorchì—ëŠ” tensor í¬ê¸°(or ëª¨ì–‘)ë¥¼ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜ê°€ ìˆì–´ìš”! ì˜ì–´ë¡œ í¬ê¸°ê°€ ë¬´ì—‡ì¼ê¹Œìš”?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tjHTIZdrGzXd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67b66e3e-eaf4-4a9c-f82c-f4a36d9202e8"
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "X = torch.Tensor([[1, 2],\n",
        "                  [3, 4]])\n",
        "X.size()\n",
        "# TODO : tensor Xì˜ í¬ê¸°ëŠ” (2, 2)ì…ë‹ˆë‹¤\n",
        "#        nn.Linearë¥¼ ì‚¬ìš©í•˜ì—¬ì„œ (2, 5)ë¡œ í¬ê¸°ë¥¼ ë°”ê¾¸ê³  ì´ í¬ê¸°ë¥¼ ì¶œë ¥í•˜ì„¸ìš”!\n",
        "m = nn.Linear(2,5)\n",
        "output = m(X)\n",
        "print(output.size())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([2, 5])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eU_nhb1vKTi-"
      },
      "source": [
        "##### ğŸ’¡ nn.Identity\n",
        "> ë¯¿ê¸°ì§€ ì•Šê² ì§€ë§Œ ì´ layerë„ ìœ ìš©í•˜ê²Œ ì‚¬ìš©ë©ë‹ˆë‹¤. ë‹¤ë§Œ ë”¥ëŸ¬ë‹ì„ ë§‰ ë°°ìš°ëŠ” ë‹¨ê³„ì—ì„œ ì´ layerë¥¼ ì‚¬ìš©í•  ì¼ì€ ê±°ì˜ ì—†ê¸° ë•Œë¬¸ì— ì‚¬ìš©ì²˜ë¥¼ ì•„ì‹¤ í•„ìš”ëŠ” ì—†ìŠµë‹ˆë‹¤. ë‹¤ë§Œ ê¶ê¸ˆí•´í•˜ì‹¤ ë¶„ë“¤ì„ ìœ„í•´ ë§í¬ë¥¼ ë‚¨ê²¨ë†“ìŠµë‹ˆë‹¤.\n",
        "\n",
        "``` python\n",
        "ğŸ¦†\n",
        "??? ì´ \"nn.Identity\"ëŠ” ë„ëŒ€ì²´.. ë­ì£ ???\n",
        "ì…ë ¥ê³¼ ì¶œë ¥ì´ ë™ì¼í•˜ê²Œ ë‚˜ì˜¤ëŠ”ë° ë„ëŒ€ì²´ ì™œ ë§Œë“¤ì–´ë†“ì€ ê±¸ê¹Œìš”?\n",
        "ê·¸ë˜ë„.. í•œë²ˆ ì‚¬ìš©í•´ë´ìš”!\n",
        "```\n",
        "\n",
        "- [torch.nn.Identity - PyTorch ê³µì‹ ë¬¸ì„œ](https://pytorch.org/docs/stable/generated/torch.nn.Identity.html#torch.nn.Identity)\n",
        "\n",
        "**âœ¨ ìœ ìš©í•œ ìë£Œ âœ¨**\n",
        "- [What is the use of nn.Identity? - PyTorch Forum](https://discuss.pytorch.org/t/what-is-the-use-of-nn-identity/51781)\n",
        "- [What is the idea behind using nn.Identity for residual learning? - Stack Overflow](https://stackoverflow.com/questions/64229717/what-is-the-idea-behind-using-nn-identity-for-residual-learning)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Om5zRqyvKTjA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9824c256-0b7d-4a9b-b5bc-dc59b19e43dd"
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "X = torch.Tensor([[1, 2],\n",
        "                  [3, 4]])\n",
        "\n",
        "# TODO : nn.Identityë¥¼ ìƒì„±í•´ Xë¥¼ ì…ë ¥ì‹œí‚¨ í›„ ë‚˜ì˜¨ ì¶œë ¥ê°’ì´ Xì™€ ë™ì¼í•œì§€ í™•ì¸í•´ë³´ì„¸ìš”!\n",
        "m = nn.Identity()\n",
        "output = m(X)\n",
        "print(output)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1., 2.],\n",
            "        [3., 4.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZRWBmAYkOYgy"
      },
      "source": [
        "#### â“ <font color='red'><b>[ í€´ì¦ˆ ]</b></font> Linear vs LazyLinear\n",
        "``` python\n",
        "ğŸ¦†\n",
        "ê·¸ëƒ¥ ì§€ë‚˜ì¹˜ë ¤ê³  í–ˆëŠ”ë° ì‹ ê²½ì´ ì“°ì—¬ì„œìš”!\n",
        "Linearì™€ LazyLinear ì°¨ì´ê°€ ë­ì£ ?!\n",
        "```\n",
        "\n",
        "- [torch.nn.Linear - PyTorch ê³µì‹ ë¬¸ì„œ](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear)\n",
        "- [torch.nn.LazyLinear - PyTorch ê³µì‹ ë¬¸ì„œ](https://pytorch.org/docs/stable/generated/torch.nn.LazyLinear.html#torch.nn.LazyLinear)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SIrfhKtCOYg6"
      },
      "source": [
        "```python\n",
        "ğŸ˜‚\n",
        "# TODO : ë§ê³  í‹€ë¦¬ê³ ê°€ ì—†ëŠ” ë¬¸ì œì…ë‹ˆë‹¤. ë¬¸ì„œë¥¼ ì½ê³  ë‹µì„ ììœ ë¡œì´ ì ì–´ì£¼ì„¸ìš”\n",
        "LazyLinear functionì€ weightì™€ biasê°€ torch.nn.UninitializedParameter class ì˜ ê²ƒì´ë‹¤. LazyLinearì€ í•œë²ˆ forwardë¥¼ ê±°ì¹œë’¤ Linear functionìœ¼ë¡œ ë³€í•œë‹¤. ì •í™•í•˜ì§€ëŠ” ì•Šì§€ë§Œ ë” ë¹ ë¥¸ í•™ìŠµì„ ìœ„í•´, weightì™€ biasë¥¼ ë¯¸ë¦¬ ëœë¤í•˜ê²Œ ì„¤ì •í•˜ëŠ” ëŒ€ì‹  dataì— ì…ì¶œë ¥ì— ë§ê²Œ ê·¼ì‚¬í•˜ê²Œ ì„¤ì •í•˜ê¸°ìœ„í•œ ìš©ë„ì¸ê²ƒ ê°™ë‹¤. \n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PNriTnyfdI0-"
      },
      "source": [
        "### ğŸ‰ğŸ‰ğŸ‰ Documentation ì™„ë£Œ! ğŸ‰ğŸ‰ğŸ‰\n",
        "\n",
        "```python\n",
        "ğŸ¦†\n",
        "ìš°ë¦¬ê°€ í•¨ê»˜ ì—¬ê¸°ê¹Œì§€ ì˜¤ë‹¤ë‹ˆ ë„ˆë¬´ ê¸°ë»ìš”!\n",
        "ê°™ì´ ì¢€ ë” í˜ë‚´ì„œ ë‚˜ì•„ê°€ë³´ìêµ¬ìš”!\n",
        "```\n",
        "\n",
        "Documentation ì¥ì´ ìƒê°ë³´ë‹¤ ë§ì´ í˜ë“¤ì—ˆì£ ?<br>\n",
        "ì ì§€ ì•Šì€ ë¶„ëŸ‰ì´ì—ˆìŒì—ë„ ë¬´ì‚¬íˆ ë§ˆë¬´ë¦¬ ì§€ìœ¼ì‹  ê²ƒì„ ì •ë§ ì¶•í•˜ë“œë¦½ë‹ˆë‹¤! ğŸ‰<br> ê²°ì½” ì‰½ì§€ ì•Šì€ ì¼ì…ë‹ˆë‹¤.\n",
        "\n",
        "ì—¬ëŸ¬ë¶„ì€ ì´ì œ Documentationì„ í™œìš©í•  ì¤€ë¹„ê°€ ë˜ì—ˆìŠµë‹ˆë‹¤.<br>\n",
        "ì´ì œ ìš°ë¦¬ì˜ ë³¸ë˜ ëª©ì ì¸ ëª¨ë¸ ì œì‘ê³¼ ê´€ë ¨ëœ ë‚´ìš©ì„ ë‹¤ë£° ì°¨ë¡€ì…ë‹ˆë‹¤.<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EYHm2O2t6Usd"
      },
      "source": [
        "## â­ Custom ëª¨ë¸ ì œì‘ì„ ìœ„í•œ nn.Module í´ë˜ìŠ¤\n",
        "\n",
        "```\n",
        "ğŸ’¡ PyTorch ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì œê³µí•´ì£¼ëŠ” ë‹¤ì–‘í•œ ê¸°ëŠ¥ë“¤ê³¼\n",
        "   nn.Moduleë¥¼ í™œìš©í•˜ì—¬ ëª¨ë¸ ì œì‘ ë° ë¶„ì„ì„ ì§„í–‰í•´ë³¼ ê²ƒì…ë‹ˆë‹¤!\n",
        "```\n",
        "\n",
        "Documentationì— ë‚˜ì˜¨ ë‹¤ì–‘í•œ ê¸°ëŠ¥ë“¤ì„ ì°¾ê³  í™œìš©í•˜ëŠ” ë°©ë²•ì„ ë°°ì› ìœ¼ë‹ˆ ì´ì œ PyTorchê°€ ì œê³µí•´ì£¼ëŠ” ê¸°ëŠ¥ë“¤ì„ ì¡°í•©í•˜ì—¬ì„œ ë©‹ì§„ ëª¨ë¸ì„ ë§Œë“¤ ì°¨ë¡€ì…ë‹ˆë‹¤. ëª¨ë¸ì„ ë§Œë“¤ê¸° ìœ„í•´ì„œ ê¸°ëŠ¥ë“¤ì„ ë‹¨ìˆœíˆ ë‚˜ì—´í•´ë†“ê¸°ë§Œ í•œë‹¤ë©´ ì§€ì €ë¶„í•˜ê² ì£ ? ê·¸ë˜ì„œ PyTorchëŠ” ì´ëŸ° ì¼ë ¨ì˜ ê¸°ëŠ¥ë“¤ì„ í•œ ê³³ì— ëª¨ì•„ í•˜ë‚˜ì˜ ëª¨ë¸ë¡œ ì¶”ìƒí™”í•  ìˆ˜ ìˆê²Œë” í´ë˜ìŠ¤ë¥¼ ì œê³µí•©ë‹ˆë‹¤.\n",
        "\n",
        "```\n",
        "ğŸ’¡ nn.Module\n",
        "```\n",
        "- [torch.nn.Module - PyTorch ê³µì‹ ë¬¸ì„œ](https://pytorch.org/docs/stable/generated/torch.nn.Module.html)\n",
        "\n",
        "`nn.Module` í´ë˜ìŠ¤ëŠ” ì—¬ëŸ¬ ê¸°ëŠ¥ë“¤ì„ í•œ ê³³ì— ëª¨ì•„ë†“ëŠ” ìƒì ì—­í• ì„ í•©ë‹ˆë‹¤.<br>\n",
        "`nn.Module`ì´ë¼ëŠ” ìƒìëŠ” ë‹¤ë¥¸ `nn.Module` ìƒìë¥¼ í¬í•¨í•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤!<br>\n",
        "ì–´ë–»ê²Œ ì‚¬ìš©í–ëŠëƒì— ë”°ë¼ `nn.Module` ìƒìëŠ” ë‹¤ë¥¸ ì˜ë¯¸ë¥¼ ê°€ì§‘ë‹ˆë‹¤.\n",
        "\n",
        "- `nn.Module`ì´ë¼ëŠ” ìƒìì— `ê¸°ëŠ¥`ë“¤ì„ ê°€ë“ ëª¨ì•„ë†“ì€ ê²½ìš° `basic building block`\n",
        "- `nn.Module`ì´ë¼ëŠ” ìƒìì— `basic building block`ì¸ `nn.Module`ë“¤ì„ ê°€ë“ ëª¨ì•„ë†“ì€ ê²½ìš° `ë”¥ëŸ¬ë‹ ëª¨ë¸`\n",
        "- `nn.Module`ì´ë¼ëŠ” ìƒìì— `ë”¥ëŸ¬ë‹ ëª¨ë¸`ì¸ `nn.Module`ë“¤ì„ ê°€ë“ ëª¨ì•„ë†“ì€ ê²½ìš° `ë”ìš± í° ë”¥ëŸ¬ë‹ ëª¨ë¸`\n",
        "\n",
        "`nn.Module`ì€ ë¹ˆ ìƒìì¼ ë¿ ì´ë¥¼ ì–´ë–»ê²Œ ì‚¬ìš©í• ì§€ëŠ” ì˜¨ì „íˆ ì„¤ê³„ìì˜ ëª«ì…ë‹ˆë‹¤!<br>\n",
        "`ê¸°ëŠ¥`ê³¼ `basic building block`ê³¼ `ë”¥ëŸ¬ë‹ ëª¨ë¸`ì„ í˜¼ì¬í•´ì„œ ë§ˆêµ¬ì¡ì´ë¡œ ë‹´ì„ ìˆ˜ë„ ìˆê³ <br>\n",
        "`ê¸°ëŠ¥`ì€ `ê¸°ëŠ¥`ë¼ë¦¬ `block`ì€ `block`ë¼ë¦¬ ê³„ì¸µì ìœ¼ë¡œ ë‹´ì„ ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤!\n",
        "\n",
        "ìš°ë¦¬ëŠ” ì—¬ê¸°ì„œ `nn.Module`ë¥¼ ì´ìš©í•´ ëª¨ë¸ì„ ì œì‘í•´ë³´ê³  ì œì‘í•œ ëª¨ë¸ì´ ì–´ë–»ê²Œ êµ¬ì„±ë˜ì–´ìˆëŠ”ì§€ ë¶„ì„í•´ë³¼ ê²ƒì…ë‹ˆë‹¤!<br>\n",
        "ì¶”ê°€ì ìœ¼ë¡œ custom ëª¨ë¸ ì œì‘ì— ìœ ìš©í•  ìˆ˜ ìˆëŠ” `nn.Module`ì˜ ê¸°ëŠ¥ë“¤ë„ ì‚´í´ë³¼ ê²ƒì…ë‹ˆë‹¤!\n",
        "\n",
        "ğŸ¦† ë¶€ë•ì´ê°€ ì†Ÿêµ¬ì¹˜ëŠ” ë°°ì›€ì˜ ìš•êµ¬ë¥¼ ì£¼ì²´í•˜ê¸° ì–´ë ¤ì›Œí•˜ê³  ìˆì–´ìš”!\n",
        "\n",
        "- â˜„ï¸ nn.Module ëª¨ë¸ ì œì‘\n",
        "- â˜„ï¸ nn.Module ë¶„ì„í•˜ê¸°\n",
        "- â˜„ï¸ nn.Module ì•Œì“¸ì‹ ì¡\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yXCog9jT_MJt"
      },
      "source": [
        "### â˜„ï¸ nn.Module ëª¨ë¸ ì œì‘\n",
        "> nn.Moduleì´ ë¬´ì—‡ì¸ì§€ ì´í•´í•œ í›„ ì´ë¥¼ ì´ìš©í•˜ì—¬ì„œ ëª¨ë¸ì„ ì œì‘í•˜ëŠ” ë‹¤ì–‘í•œ ë°©ë²•ì— ëŒ€í•´ì„œ ì‹¤ìŠµí•´ë³´ê³  custom ëª¨ë¸ì„ ì œì‘í•¨ì— ìˆì–´ ì¤‘ìš”í•œ ê°œë…ë“¤ì— ëŒ€í•´ ì´í•´í•˜ëŠ” ì‹œê°„ì„ ê°€ì§ˆ ê²ƒì…ë‹ˆë‹¤\n",
        "\n",
        "- ğŸ“– <font color='gold' ><b>[ ì½ê¸° ]</b></font> torch.nn.Module ë¬¸ì„œ ì½ê¸°\n",
        "- ğŸ‘¨â€ğŸ’» <font color='green'><b>[ ì½”ë”© ]</b></font> 1 + 2\n",
        "- ğŸ‘¨â€ğŸ’» <font color='green'><b>[ ì½”ë”© ]</b></font> Container\n",
        "- â“ <font color='red'><b>[ í€´ì¦ˆ ]</b></font> Python List vs PyTorch ModuleList\n",
        "- ğŸ‘¨â€ğŸ’» <font color='green'><b>[ ì½”ë”© ]</b></font> ì¡°ê±´ë¬¸\n",
        "- ğŸ‘¨â€ğŸ’» <font color='green'><b>[ ì½”ë”© ]</b></font> Moduleë“¤ì˜ íë¦„ ëŠê»´ë³´ê¸°\n",
        "- ğŸ‘¨â€ğŸ’» <font color='green'><b>[ ì½”ë”© ]</b></font> Parameter\n",
        "- â“ <font color='red'><b>[ í€´ì¦ˆ ]</b></font> Tensor vs Parameter\n",
        "- ğŸ‘¨â€ğŸ’» <font color='green'><b>[ ì½”ë”© ]</b></font> Buffer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mgJ38Rsiy2Tc"
      },
      "source": [
        "#### ğŸ“– <font color='gold' ><b>[ ì½ê¸° ]</b></font> torch.nn.Module ë¬¸ì„œ ì½ê¸°\n",
        "``` python\n",
        "ğŸ¦†\n",
        "\"nn.Module\"ì€ ì•ìœ¼ë¡œ ì €í¬ì™€ ê³„ì† í•¨ê»˜í•˜ê²Œë  ìš´ëª…ì´ í‹€ë¦¼ì—†ì–´ìš”!\n",
        "ì ê¹ì´ì§€ë§Œ \"nn.Module\"ì— ëŒ€í•´ì„œ ì•Œì•„ë³´ëŠ” ì‹œê°„ì„ ê°€ì ¸ë´ìš”! \n",
        "```\n",
        "\n",
        "- [Documentation main - PyTorch ê³µì‹ ë¬¸ì„œ](https://pytorch.org/docs/stable/index.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IoDjvw97y2Tr"
      },
      "source": [
        "- âœ… Documentationì—ì„œ nn.Moduleì„ ê²€ìƒ‰í•´ì„œ ì°¾ìœ¼ì„¸ìš”!\n",
        "- âœ… nn.Module ë¬¸ì„œì˜ ì„¤ëª…ì„ ì½ì–´ë³´ì„¸ìš”!\n",
        "    - ![](https://github.com/IllgamhoDuck/PyTorch/blob/main/document_image/nn.Module.png?raw=true)\n",
        "- âœ… nn.Module ë‚´ë¶€ì˜ methodë“¤ì˜ ì´ë¦„ê³¼ ì„¤ëª…ì„ ê°€ë³ê²Œ í›‘ì–´ë³´ì„¸ìš”!\n",
        "```\n",
        "ğŸ”” ì™¸ìš°ê±°ë‚˜ ì´í•´í•˜ëŠ” ì‹œê°„ì´ ì•„ë‹™ë‹ˆë‹¤!\n",
        "     ì„¤ëª…ì´ ëˆˆì— ì˜ ì•ˆë“¤ì–´ì˜¤ê³  ì–´ìƒ‰í•˜ë‹¤ë©´ ë§¤ìš° ì •ìƒì…ë‹ˆë‹¤\n",
        "     ì–µì§€ë¡œ ì½ìœ¼ì‹¤ í•„ìš” ì—†ìŠµë‹ˆë‹¤! ëˆˆì— ì•ˆë“¤ì–´ì˜¤ë©´ ê·¸ëƒ¥ ì§€ë‚˜ê°€ì„¸ìš”!\n",
        "     ì•ìœ¼ë¡œ ê³µë¶€ë¥¼ í•´ê°€ì‹œë©´ì„œ ì ì°¨ ìµìˆ™í•´ì§€ì‹¤ê±°ë‹ˆ ì§€ê¸ˆì€\n",
        "     ê°€ë²¼ìš´ ë§ˆìŒìœ¼ë¡œ í›‘ì–´ë³´ë©´ì„œ ì´ëŸ°ê²Œ ìˆêµ¬ë‚˜~ ì •ë„ë¡œë§Œ ë³´ì„¸ìš”!\n",
        "```\n",
        "    - add_module\n",
        "    - apply\n",
        "    - bfloat16\n",
        "    - buffers\n",
        "    - children\n",
        "    - cpu\n",
        "    - cuda\n",
        "    - double\n",
        "    - dump_patches\n",
        "    - eval\n",
        "    - extra_repr\n",
        "    - float\n",
        "    - forward\n",
        "    - get_buffer\n",
        "    - get_parameter\n",
        "    - get_submodule\n",
        "    - half\n",
        "    - load_state_dict\n",
        "    - modules\n",
        "    - named_buffers\n",
        "    - named_children\n",
        "    - named_modules\n",
        "    - named_parameters\n",
        "    - parameters\n",
        "    - register_backward_hook\n",
        "    - register_buffer\n",
        "    - register_forward_hook\n",
        "    - register_forward_pre_hook\n",
        "    - register_full_backward_hook\n",
        "    - register_parameter\n",
        "    - requires_grad_\n",
        "    - share_memory\n",
        "    - state_dict\n",
        "    - to\n",
        "    - to_empty\n",
        "    - train\n",
        "    - type\n",
        "    - xpu\n",
        "    - zero_grad"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5OhWyjstxvUt"
      },
      "source": [
        "#### ğŸ‘¨â€ğŸ’» <font color='green'><b>[ ì½”ë”© ]</b></font> 1 + 2\n",
        "\n",
        "``` python\n",
        "ğŸ¦†\n",
        "Documentationì„ ì½ì–´ë‚˜ê°€ë‹¤ê°€ ê°€ë³ê²Œ \"torch.add\"ë¥¼ ì´ìš©í•´ì„œ \n",
        "ì‚¬ì¹™ì—°ì‚°ì„ ê³„ì‚°í•œ ê²ƒì„ ê¸°ì–µí•˜ì„¸ìš”?\n",
        "\n",
        "ì´ë²ˆì—ëŠ” \"nn.Module\"ë¥¼ ì´ìš©í•´ì„œ ë”í•˜ê¸° ì—°ì‚°ì„ í•˜ëŠ” ëª¨ë¸ì„ ë§Œë“¤ì–´ë³´ì•„ìš”!\n",
        "```\n",
        "\n",
        "- [Documentation main - PyTorch ê³µì‹ ë¬¸ì„œ](https://pytorch.org/docs/stable/index.html)\n",
        "- [torch.add - PyTorch ê³µì‹ ë¬¸ì„œ](https://pytorch.org/docs/stable/generated/torch.add.html?highlight=add#torch.add)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lF5CCXcgxjWD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55c7da7c-c97a-4739-ecea-179e1e34f9ef"
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "# TODO : Add ëª¨ë¸ì„ ì™„ì„±í•˜ì„¸ìš”!\n",
        "class Add(nn.Module):\n",
        "    def __init__(self):\n",
        "        # TODO : init ê³¼ì •ì—ì„œ ë°˜ë“œì‹œ ë“¤ì–´ê°€ì•¼ í•˜ëŠ” super ê´€ë ¨ ì½”ë“œê°€ ìˆìŠµë‹ˆë‹¤\n",
        "        super().__init__()\n",
        "        \n",
        "\n",
        "    def forward(self, x1, x2):\n",
        "        \n",
        "        return torch.add(x1,x2)\n",
        "        # TODO : torch.add í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•´ì„œ ë”í•˜ê¸° ì—°ì‚°ì„ í•´ì£¼ì„¸ìš”!\n",
        "        \n",
        "\n",
        "\n",
        "# ì•„ë˜ ì½”ë“œëŠ” ìˆ˜ì •í•˜ì‹¤ í•„ìš”ê°€ ì—†ìŠµë‹ˆë‹¤!\n",
        "x1 = torch.tensor([1])\n",
        "x2 = torch.tensor([2])\n",
        "\n",
        "add = Add()\n",
        "output = add(x1, x2)\n",
        "\n",
        "if output == 3:\n",
        "    print(\"ğŸ‰ğŸ‰ğŸ‰ ì„±ê³µ!!! ğŸ‰ğŸ‰ğŸ‰\")\n",
        "else:\n",
        "    print(\"ğŸ¦† ë‹¤ì‹œ ë„ì „í•´ë´ìš”!\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ğŸ‰ğŸ‰ğŸ‰ ì„±ê³µ!!! ğŸ‰ğŸ‰ğŸ‰\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZfhwgR6kYy6i"
      },
      "source": [
        "``` python\n",
        "ğŸ¦†\n",
        "superë¥¼ í†µí•´ì„œ initì„ í•˜ëŠ” ê²ƒì€ ì™œ ê·¸ëŸ°ê±¸ê¹Œìš”?\n",
        "\n",
        "ì•„ë˜ ë§í¬ì˜ ê¸€ì„ ì½ìœ¼ë‹ˆê¹Œ ì˜ë¬¸ì´ ì¢€ í’€ë¦¬ëŠ” ê²ƒ ê°™ì•„ìš”! \n",
        "```\n",
        "\n",
        "**âœ¨ ìœ ìš©í•œ ìë£Œ âœ¨**\n",
        "- [Why is the super constructor necessary in PyTorch custom modules? - Stack Overflow](https://stackoverflow.com/questions/63058355/why-is-the-super-constructor-necessary-in-pytorch-custom-modules)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MpJ51jOZL1pm"
      },
      "source": [
        "#### ğŸ‘¨â€ğŸ’» <font color='green'><b>[ ì½”ë”© ]</b></font> Container\n",
        "\n",
        "``` python\n",
        "ğŸ¦†\n",
        "ì €í¬ê°€ ì›í•˜ëŠ” ëª¨ë“ˆ(Module)ì„ ì„±ê³µì ìœ¼ë¡œ ë§Œë“¤ì—ˆì–´ìš”!\n",
        "ì‹œì‘ì´ ì ˆë°˜! ì¸ì§€ëŠ” ëª¨ë¥´ê² ì§€ë§Œ ëª¨ë¸ì„ ë§Œë“  ê²ƒì€ í‹€ë¦¼ì—†ì£ !\n",
        "\n",
        "ì´ë ‡ê²Œ ë§Œë“  ëª¨ë“ˆ(Module)ë“¤ì„ ë¬¶ì–´ì„œ ì‚¬ìš©í•˜ê³  ì‹¶ì€ë° ì–´ë–»ê²Œ í•˜ëŠ”ê±¸ê¹Œìš”?\n",
        "íŒŒì´ì¬ì˜ ë¦¬ìŠ¤íŠ¸ì— ëª¨ë“ˆë“¤ì„ ë³´ê´€í•˜ë©´ ë˜ëŠ”ê±¸ê¹Œìš”?\n",
        "\n",
        "ì•—! ì°¾ì•˜ì–´ìš”! \n",
        "Documentationì„ ì—´ì‹¬íˆ ì°¾ì•„ë³´ë‹ˆê¹Œ ê´€ë ¨ëœ í•¨ìˆ˜ë“¤ì´\n",
        "\"torch.nn\"ì˜ Container í•­ëª©ì— í¬í•¨ë˜ì–´ìˆë„¤ìš”!\n",
        "```\n",
        "\n",
        "- [Documentation main - PyTorch ê³µì‹ ë¬¸ì„œ](https://pytorch.org/docs/stable/index.html)\n",
        "- [Containers  - PyTorch ê³µì‹ ë¬¸ì„œ](https://pytorch.org/docs/stable/nn.html#containers)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6a_OSRXMgc8j"
      },
      "source": [
        "##### ğŸ’¡ torch.nn.Sequential\n",
        "\n",
        "``` python\n",
        "ğŸ¦†\n",
        "ëª¨ë“ˆ(Module)ë“¤ì„ í•˜ë‚˜ë¡œ ë¬¶ì–´ ìˆœì°¨ì ìœ¼ë¡œ ì‹¤í–‰ì‹œí‚¤ê³  ì‹¶ì„ë•Œ\n",
        "torch.nn.Sequentialë¥¼ ì‚¬ìš©í•œë‹¤ê³  í•˜ë„¤ìš”! ê°™ì´ ë§Œë“¤ì–´ë´ìš”!\n",
        "```\n",
        "\n",
        "- [torch.nn.Sequential - PyTorch ê³µì‹ ë¬¸ì„œ](https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html#torch.nn.Sequential)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZAzm120dL1p4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f04daae-f3a6-4275-8bad-58e79339f008"
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "# TODO : ë‹¤ìŒì˜ ëª¨ë“ˆ(Module)ì„ ì½ê³  ì´í•´í•´ë³´ì„¸ìš”!\n",
        "class Add(nn.Module):\n",
        "    def __init__(self, value):\n",
        "        super().__init__()\n",
        "        self.value = value\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x + self.value\n",
        "\n",
        "    \n",
        "\n",
        "# TODO : ìœ„ì— ëª¨ë“ˆ(Module)ê³¼ nn.Sequentialë¥¼ ì´ìš©í•´ì„œ\n",
        "#        ì…ë ¥ê°’ xê°€ ì£¼ì–´ì§€ë©´ ë‹¤ìŒì˜ ì—°ì‚°ì„ ì²˜ë¦¬í•˜ëŠ” ëª¨ë¸ì„ ë§Œë“¤ì–´ë³´ì„¸ìš”!\n",
        "#        y = x + 3 + 2 + 5\n",
        "calculator = nn.Sequential(\n",
        "    Add(3),\n",
        "    Add(2),\n",
        "    Add(5)\n",
        ")\n",
        "488\n",
        "\n",
        "# ì•„ë˜ ì½”ë“œëŠ” ìˆ˜ì •í•˜ì‹¤ í•„ìš”ê°€ ì—†ìŠµë‹ˆë‹¤!\n",
        "x = torch.tensor([1])\n",
        "\n",
        "output = calculator(x)\n",
        "\n",
        "if output == 11:\n",
        "    print(\"ğŸ‰ğŸ‰ğŸ‰ ì„±ê³µ!!! ğŸ‰ğŸ‰ğŸ‰\")\n",
        "else:\n",
        "    print(\"ğŸ¦† ë‹¤ì‹œ ë„ì „í•´ë´ìš”!\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ğŸ‰ğŸ‰ğŸ‰ ì„±ê³µ!!! ğŸ‰ğŸ‰ğŸ‰\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a-Zs6pnh1925"
      },
      "source": [
        "##### ğŸ’¡ torch.nn.ModuleList\n",
        "\n",
        "``` python\n",
        "ğŸ¦†\n",
        "torch.nn.Sequentialì€ ë¬¶ì–´ë†“ì€ ëª¨ë“ˆë“¤ì„ ì°¨ë¡€ëŒ€ë¡œ ìˆ˜í–‰í•˜ê¸° ë•Œë¬¸ì—\n",
        "ì‹¤í–‰ ìˆœì„œê°€ ì •í•´ì ¸ìˆëŠ” ê¸°ëŠ¥ë“¤ì„ í•˜ë‚˜ë¡œ ë¬¶ì–´ë‘ê¸° ì¢‹ì•„ë³´ì—¬ìš”!\n",
        "\n",
        "í•˜ì§€ë§Œ íŒŒì´ì¬ì˜ listì²˜ëŸ¼ ëª¨ì•„ë‘ê¸°ë§Œ í•˜ê³  ê·¸ë•Œê·¸ë•Œ ì›í•˜ëŠ” ê²ƒë§Œ\n",
        "ì¸ë±ì‹±(indexing)ì„ í†µí•´ ì“°ê³  ì‹¶ìœ¼ë©´ torch.nn.ModuleListì„ ì“°ë©´ ë˜ì§€ ì•Šì„ê¹Œìš”?\n",
        "```\n",
        "\n",
        "- [torch.nn.ModuleList - PyTorch ê³µì‹ ë¬¸ì„œ](https://pytorch.org/docs/stable/generated/torch.nn.ModuleList.html#torch.nn.ModuleList)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7D3cK6pS193J",
        "outputId": "28f53e86-707c-4ed0-f403-e16fa4841d33"
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "# TODO : ë‹¤ìŒì˜ ëª¨ë“ˆ(Module)ì„ ì½ê³  ì´í•´í•´ë³´ì„¸ìš”!\n",
        "class Add(nn.Module):\n",
        "    def __init__(self, value):\n",
        "        super().__init__()\n",
        "        self.value = value\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x + self.value\n",
        "\n",
        "\n",
        "# TODO : Calculator ëª¨ë¸ì„ ì™„ì„±í•˜ì„¸ìš”!\n",
        "class Calculator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.add_list = nn.ModuleList([Add(2), Add(3), Add(5)])\n",
        "\n",
        "    def forward(self, x):\n",
        "        # TODO : self.add_listì— ë‹´ê¸´ ëª¨ë“ˆë“¤ì„ ì´ìš©í•˜ì—¬ì„œ\n",
        "        #        y = ((x + 3) + 2) + 5 ì˜ ì—°ì‚°ì„ êµ¬í˜„í•˜ì„¸ìš”!\n",
        "        add_list = self.add_list\n",
        "        x = add_list[2](add_list[0](add_list[1](x)))\n",
        "        \n",
        "        return x\n",
        "\n",
        "\n",
        "# ì•„ë˜ ì½”ë“œëŠ” ìˆ˜ì •í•˜ì‹¤ í•„ìš”ê°€ ì—†ìŠµë‹ˆë‹¤!\n",
        "x = torch.tensor([1])\n",
        "\n",
        "calculator = Calculator()\n",
        "output = calculator(x)\n",
        "print(output)\n",
        "if output == 11:\n",
        "    print(\"ğŸ‰ğŸ‰ğŸ‰ ì„±ê³µ!!! ğŸ‰ğŸ‰ğŸ‰\")\n",
        "else:\n",
        "    print(\"ğŸ¦† ë‹¤ì‹œ ë„ì „í•´ë´ìš”!\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([11])\n",
            "ğŸ‰ğŸ‰ğŸ‰ ì„±ê³µ!!! ğŸ‰ğŸ‰ğŸ‰\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fl8bTU-FWLWP"
      },
      "source": [
        " **ì´ forward() í•¨ìˆ˜ëŠ” model ê°ì²´ë¥¼ ë°ì´í„°ì™€ í•¨ê»˜ í˜¸ì¶œí•˜ë©´ ìë™ìœ¼ë¡œ ì‹¤í–‰ì´ë©ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´ modelì´ë€ ì´ë¦„ì˜ ê°ì²´ë¥¼ ìƒì„± í›„, model(ì…ë ¥ ë°ì´í„°)ì™€ ê°™ì€ í˜•ì‹ìœ¼ë¡œ ê°ì²´ë¥¼ í˜¸ì¶œí•˜ë©´ ìë™ìœ¼ë¡œ forward ì—°ì‚°ì´ ìˆ˜í–‰ë©ë‹ˆë‹¤.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XLOhs8I56dYA"
      },
      "source": [
        "##### ğŸ’¡ torch.nn.ModuleDict\n",
        "\n",
        "``` python\n",
        "ğŸ¦†\n",
        "torch.nn.ModuleLists ì •ë§ í¸ë¦¬í•˜ë„¤ìš”!!\n",
        "í•˜ì§€ë§Œ ë§Œì•½ ë¦¬ìŠ¤íŠ¸ì— ë‹´ê¸´ ëª¨ë“ˆì˜ í¬ê¸°ê°€ ì •ë§ ì»¤ì§„ë‹¤ë©´\n",
        "ë‚˜ì¤‘ì—ëŠ” ì¸ë±ì‹±(indexing)ìœ¼ë¡œ ì›í•˜ëŠ” ëª¨ë“ˆì„ ì°¾ê¸°ê°€ ì •ë§ í˜ë“¤ì–´ì§ˆ ê²ƒ ê°™ì•„ìš”!\n",
        "\n",
        "íŒŒì´ì¬ì˜ dictì²˜ëŸ¼ íŠ¹ì • ëª¨ë“ˆì„ keyê°’ì„ ì´ìš©í•´ ë³´ê´€í•´ë†“ëŠ”ë‹¤ë©´\n",
        "ë‚˜ì¤‘ì— ì›í•˜ëŠ” ëª¨ë“ˆì„ ê°€ì ¸ì˜¬ë•Œ í›¨ì”¬ ìˆ˜ì›”í•˜ì§€ ì•Šì„ê¹Œìš”?\n",
        "ë§ˆì¹¨ PyTorchì— torch.nn.ModuleDictì´ ìˆë„¤ìš”! ê°™ì´ ì¨ë´ìš”!\n",
        "```\n",
        "\n",
        "- [torch.nn.ModuleDict - PyTorch ê³µì‹ ë¬¸ì„œ](https://pytorch.org/docs/stable/generated/torch.nn.ModuleDict.html#torch.nn.ModuleDict)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "suYi2pjj6dYK",
        "outputId": "128183e2-864c-4ceb-d385-892a6a0e8f7e"
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "# TODO : ë‹¤ìŒì˜ ëª¨ë“ˆ(Module)ì„ ì½ê³  ì´í•´í•´ë³´ì„¸ìš”!\n",
        "class Add(nn.Module):\n",
        "    def __init__(self, value):\n",
        "        super().__init__()\n",
        "        self.value = value\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x + self.value\n",
        "\n",
        "\n",
        "# TODO : Calculator ëª¨ë¸ì„ ì™„ì„±í•˜ì„¸ìš”!\n",
        "class Calculator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.add_dict = nn.ModuleDict({'add2': Add(2),\n",
        "                                       'add3': Add(3),\n",
        "                                       'add5': Add(5)})\n",
        "\n",
        "    def forward(self, x):\n",
        "        # TODO : self.add_dictì— ë‹´ê¸´ ëª¨ë“ˆë“¤ì„ ì´ìš©í•˜ì—¬ì„œ\n",
        "        #        y = ((x + 3) + 2) + 5 ì˜ ì—°ì‚°ì„ êµ¬í˜„í•˜ì„¸ìš”!\n",
        "        add_dict = self.add_dict\n",
        "        x = add_dict[\"add5\"](add_dict[\"add2\"](add_dict[\"add3\"](x)))\n",
        "       \n",
        "        return x\n",
        "\n",
        "\n",
        "# ì•„ë˜ ì½”ë“œëŠ” ìˆ˜ì •í•˜ì‹¤ í•„ìš”ê°€ ì—†ìŠµë‹ˆë‹¤!\n",
        "x = torch.tensor([1])\n",
        "\n",
        "calculator = Calculator()\n",
        "output = calculator(x)\n",
        "\n",
        "if output == 11:\n",
        "    print(\"ğŸ‰ğŸ‰ğŸ‰ ì„±ê³µ!!! ğŸ‰ğŸ‰ğŸ‰\")\n",
        "else:\n",
        "    print(\"ğŸ¦† ë‹¤ì‹œ ë„ì „í•´ë´ìš”!\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ğŸ‰ğŸ‰ğŸ‰ ì„±ê³µ!!! ğŸ‰ğŸ‰ğŸ‰\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CgV9Ntk38ieo"
      },
      "source": [
        "#### â“ <font color='red'><b>[ í€´ì¦ˆ ]</b></font> Python List vs PyTorch ModuleList\n",
        "``` python\n",
        "ğŸ¦†\n",
        "ê·¸ëŸ°ë° ê°€ë§Œíˆ ìƒê°í•´ë³´ë‹ˆê¹Œ íŒŒì´ì¬ì—ë„ Listê°€ ìˆëŠ”ë° ì™œ êµ³ì´\n",
        "PyTorchì—ì„œëŠ” ModuleListë¥¼ ë³„ë„ë¡œ ë§Œë“¤ì–´ë‘ì—ˆì„ê¹Œìš”?\n",
        "\n",
        "ê·¸ ì´ìœ ê°€ ê¶ê¸ˆí•´ìš”!\n",
        "```\n",
        "\n",
        "- [torch.nn.ModuleList - PyTorch ê³µì‹ ë¬¸ì„œ](https://pytorch.org/docs/stable/generated/torch.nn.ModuleList.html#torch.nn.ModuleList)\n",
        "\n",
        "ğŸ **íŒíŠ¸** ğŸ\n",
        "- ì•„ë˜ì— ì‘ì„±ëœ ì½”ë“œë¥¼ ì‹¤í–‰ì‹œí‚¤ì‹œë©´ íŒíŠ¸ë¥¼ ì–»ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p0X4Bi7E9bjz"
      },
      "source": [
        "# ì•„ë˜ ì½”ë“œëŠ” ìˆ˜ì •í•˜ì‹¤ í•„ìš”ê°€ ì—†ìŠµë‹ˆë‹¤!\n",
        "class Add(nn.Module):\n",
        "    def __init__(self, value):\n",
        "        super().__init__()\n",
        "        self.value = value\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x + self.value\n",
        "\n",
        "\n",
        "class PythonList(nn.Module):\n",
        "    \"\"\"Python List\"\"\"\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        # Python List\n",
        "        self.add_list = [Add(2), Add(3), Add(5)]\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.add_list[1](x)\n",
        "        x = self.add_list[0](x)\n",
        "        x = self.add_list[2](x)\n",
        "        \n",
        "        return x\n",
        "\n",
        "class PyTorchList(nn.Module):\n",
        "    \"\"\"PyTorch List\"\"\"\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        # Pytorch ModuleList\n",
        "        self.add_list = nn.ModuleList([Add(2), Add(3), Add(5)])\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.add_list[1](x)\n",
        "        x = self.add_list[0](x)\n",
        "        x = self.add_list[2](x)\n",
        "        \n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wcZcR67F_MbE",
        "outputId": "97fdf526-9a20-455d-e36a-22980e156632"
      },
      "source": [
        "# ì•„ë˜ ì½”ë“œëŠ” ìˆ˜ì •í•˜ì‹¤ í•„ìš”ê°€ ì—†ìŠµë‹ˆë‹¤!\n",
        "x = torch.tensor([1])\n",
        "\n",
        "python_list = PythonList()\n",
        "pytorch_list = PyTorchList()\n",
        "\n",
        "# ê¸°ëŠ¥ ë™ì‘ì€ ë™ì¼í•©ë‹ˆë‹¤!\n",
        "print(python_list(x), pytorch_list(x))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([11]) tensor([11])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o8qgY2EK_lMb",
        "outputId": "f1828a79-37df-4e63-e0d7-a63b26c12292"
      },
      "source": [
        "# Python Listë¡œ ëª¨ì•„ë†“ì€ ëª¨ë“ˆë“¤ì´ ê°ìª½ê°™ì´ ì‚¬ë¼ì¡ŒìŠµë‹ˆë‹¤!\n",
        "python_list"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PythonList()"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I-eFwdj7ABMH",
        "outputId": "531e9fde-17c8-4695-bd0f-6dc774a8f6ba"
      },
      "source": [
        "# í•˜ì§€ë§Œ PyTorchì˜ ModuleListë¡œ ëª¨ì•„ë†“ì€ ëª¨ë“ˆë“¤ì€ ì§ ! í•˜ê³  ë‚˜íƒ€ë‚˜ë„¤ìš”!\n",
        "pytorch_list"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PyTorchList(\n",
              "  (add_list): ModuleList(\n",
              "    (0): Add()\n",
              "    (1): Add()\n",
              "    (2): Add()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8EZ7R-Js8ie5"
      },
      "source": [
        "```python\n",
        "ğŸ˜Œ\n",
        "# TODO : ë§ê³  í‹€ë¦¬ê³ ê°€ ì—†ëŠ” ë¬¸ì œì…ë‹ˆë‹¤. ë¬¸ì„œë¥¼ ì½ê³  ë‹µì„ ììœ ë¡œì´ ì ì–´ì£¼ì„¸ìš”\n",
        " but modules it contains are properly registered, and will be visible by all Module methods.\n",
        " ModuleListë¡œ êµ¬í˜„í•˜ê²Œ ë˜ë©´\n",
        " ëª¨ë“ˆì„ í˜¸ì¶œí–ˆì„ ë•Œ ModuleListê°€ ê°™ì´ ì¶œë ¥ëœë‹¤. \n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ARH3kXTPKEq"
      },
      "source": [
        "#### ğŸ‘¨â€ğŸ’» <font color='green'><b>[ ì½”ë”© ]</b></font> ì¡°ê±´ë¬¸\n",
        "\n",
        "``` python\n",
        "ğŸ¦†\n",
        "ì •ë§ ë§ì€ ê²ƒì„ í•œë²ˆì— ë°°ìš°ë‹ˆê¹Œ ìƒê°ë³´ë‹¤ í˜ë“œë„¤ìš” ê½‰ê½‰!ğŸ’¦\n",
        "ì£„ì†¡í•´ìš”! ë³´í†µ ì¸ê°„ì–´ë¥¼ ì‚¬ìš©í•˜ëŠ”ë° í˜ë“¤ë©´ ê°€ë” ì˜¤ë¦¬ì–´ê°€ ë‚˜ì˜¤ë„¤ìš”!\n",
        "\n",
        "ëª¨ë¸ì„ ë§Œë“¤ë•Œ PyTorchëŠ” ë™ì  ê³„ì‚° ê·¸ë˜í”„ë¥¼ ì‚¬ìš©í•˜ê¸° ë•Œë¬¸ì—\n",
        "if / else ì™€ ê°™ì€ ì¡°ê±´ë¬¸ì„ ì‰½ê²Œ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ì¥ì ì´ ìˆë‹¤ê³  ë“¤ì—ˆì–´ìš”!\n",
        "\n",
        "ì •ë§ ë©‹ì§„ ê²ƒ ê°™ì•„ìš”! ê°™ì´ ì–´ì„œ ì¨ë´ìš”!\n",
        "```\n",
        "\n",
        "- [Documentation main - PyTorch ê³µì‹ ë¬¸ì„œ](https://pytorch.org/docs/stable/index.html)\n",
        "\n",
        "**âœ¨ ìœ ìš©í•œ ìë£Œ âœ¨**\n",
        "- [Can someone explain the use of a dynamic graph? - Reddit](https://www.reddit.com/r/pytorch/comments/8kpsjy/can_someone_explain_the_use_of_a_dynamic_graph/)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mDBSmecjPKE7",
        "outputId": "1dcd919c-4c25-42e9-8362-eb38e364f420"
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "# TODO : ë‹¤ìŒì˜ ëª¨ë“ˆ(Module)ì„ ì½ê³  ì´í•´í•´ë³´ì„¸ìš”!\n",
        "class Add(nn.Module):\n",
        "    def __init__(self, value):\n",
        "        super().__init__()\n",
        "        self.value = value\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x + self.value\n",
        "\n",
        "class Sub(nn.Module):\n",
        "    def __init__(self, value):\n",
        "        super().__init__()\n",
        "        self.value = value\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x - self.value\n",
        "\n",
        "\n",
        "# TODO : Calculator ëª¨ë¸ì„ ì™„ì„±í•˜ì„¸ìš”!\n",
        "class Calculator(nn.Module):\n",
        "    def __init__(self, cal_type):\n",
        "        super().__init__()\n",
        "        self.cal_type = cal_type\n",
        "        self.add = Add(3)\n",
        "        self.sub = Sub(3)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # TODO : cal_typeì— \"add\"ê°€ ì…ë ¥ë˜ë©´ ë”í•˜ê¸° ëª¨ë¸ y = x + 3\n",
        "        #                   \"sub\"ê°€ ì…ë ¥ë˜ë©´ ë¹¼ê¸° ëª¨ë¸ y = x - 3\n",
        "        #                   \"add\", \"sub\"ê°€ ì•„ë‹Œ ë‹¤ë¥¸ ë¬¸ìì—´ì´ ì…ë ¥ë˜ë©´ ValueErrorì„ ì¼ìœ¼í‚¤ì„¸ìš”!\n",
        "        #        if/elif/else ì¡°ê±´ë¬¸ì„ ì‚¬ìš©í•˜ì„¸ìš”! \n",
        "        if self.cal_type == \"add\":\n",
        "            x = self.add(x)\n",
        "        elif self.cal_type == \"sub\":\n",
        "            x = self.sub(x)\n",
        "        else:\n",
        "            raise ValueError\n",
        "        \n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "# ì•„ë˜ ì½”ë“œëŠ” ìˆ˜ì •í•˜ì‹¤ í•„ìš”ê°€ ì—†ìŠµë‹ˆë‹¤!\n",
        "x = torch.tensor([5])\n",
        "\n",
        "try:\n",
        "    calculator = Calculator(\"none\")\n",
        "    output = calculator(x)\n",
        "\n",
        "    print(\"ğŸ¦† ì˜ëª»ëœ ë¬¸ìì—´ ì…ë ¥ì—ëŠ” ì—ëŸ¬ë¥¼ ë°œìƒì‹œí‚¤ì„¸ìš”!!\")\n",
        "except ValueError:\n",
        "    calculator = Calculator(\"add\")\n",
        "    add_output = calculator(x)\n",
        "\n",
        "    calculator = Calculator(\"sub\")\n",
        "    sub_output = calculator(x)\n",
        "    \n",
        "    if add_output == 8 and sub_output == 2:\n",
        "        print(\"ğŸ‰ğŸ‰ğŸ‰ ì„±ê³µ!!! ğŸ‰ğŸ‰ğŸ‰\")\n",
        "    else:\n",
        "        print(\"ğŸ¦† ë‹¤ì‹œ ë„ì „í•´ë´ìš”!\")\n",
        "except:\n",
        "    print(\"ğŸ¦† ValueErrorë¥¼ ë°œìƒì‹œí‚¤ì„¸ìš”!!\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ğŸ‰ğŸ‰ğŸ‰ ì„±ê³µ!!! ğŸ‰ğŸ‰ğŸ‰\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pfdy2siYp4ua"
      },
      "source": [
        "#### ğŸ‘¨â€ğŸ’» <font color='green'><b>[ ì½”ë”© ]</b></font> Moduleë“¤ì˜ íë¦„ ëŠê»´ë³´ê¸°\n",
        "> ğŸ¦† ë¶€ë•ì´ê°€ ì½”ë“œë¥¼ ì‘ì„±í•´ì£¼ì—ˆì–´ìš”\n",
        "\n",
        "``` python\n",
        "ğŸ¦†\n",
        "Moduleì€ Moduleì„ í¬í•¨í•  ìˆ˜ ìˆë‹¤ëŠ” ì‚¬ì‹¤ì´ ë©‹ì ¸ìš”!\n",
        "\n",
        "- ìµœì†Œì˜ ê¸°ëŠ¥ ë‹¨ìœ„ì¸ function\n",
        "- functionë“¤ë¡œ ì´ë£¨ì–´ì§„ layer\n",
        "- layerë¡œ ì´ë£¨ì–´ì§„ model\n",
        "\n",
        "ì‘ì€ ë¶€ë¶„ë¶€í„° ë¸”ëŸ­ì„ í•˜ë‚˜ì”© ìŒ“ê³  ë˜ ìŒ“ë‹¤ë³´ë©´ ì–´ëŠ ìˆœê°„\n",
        "ìš°ë¦¬ëŠ” ê±°ëŒ€í•œ ë”¥ëŸ¬ë‹ ëª¨ë¸ì´ë¼ëŠ” ë©‹ì§„ íƒ‘ì„ ë³¼ ìˆ˜ ìˆê²Œ ë˜ë‹ˆê¹Œìš”!\n",
        "\n",
        "Moduleê³¼ Moduleì˜ ì—°ê²°ì´ ë§Œë“¤ì–´ë‚´ëŠ” íë¦„ì„ ëŠê»´ë³´ì„¸ìš”!\n",
        "ê° Moduleì˜ ì´ˆê¸°í™”ëŠ” ì–´ë–¤ ìˆœì„œë¡œ ë˜ëŠ”ì§€,\n",
        "ì–¸ì œ ì‹œì‘í•˜ê³  ëë‚˜ëŠ”ì§€ ì²œì²œíˆ ìƒê°í•´ë³´ì„¸ìš”!\n",
        "```\n",
        "\n",
        "- [Documentation main - PyTorch ê³µì‹ ë¬¸ì„œ](https://pytorch.org/docs/stable/index.html)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uGPSjEytp4um",
        "outputId": "6aa27a32-4b03-47a4-f4c1-565381c80c46"
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "\n",
        "# Function\n",
        "class Function_A(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        print(f\"        Function A Initialized\")\n",
        "\n",
        "    def forward(self, x):\n",
        "        print(f\"        Function A started\")\n",
        "        print(f\"        Function A done\")\n",
        "\n",
        "class Function_B(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        print(f\"        Function B Initialized\")\n",
        "\n",
        "    def forward(self, x):\n",
        "        print(f\"        Function B started\")\n",
        "        print(f\"        Function B done\")\n",
        "\n",
        "class Function_C(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        print(f\"        Function C Initialized\")\n",
        "\n",
        "    def forward(self, x):\n",
        "        print(f\"        Function C started\")\n",
        "        print(f\"        Function C done\")\n",
        "\n",
        "class Function_D(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        print(f\"        Function D Initialized\")\n",
        "\n",
        "    def forward(self, x):\n",
        "        print(f\"        Function D started\")\n",
        "        print(f\"        Function D done\")\n",
        "\n",
        "\n",
        "# Layer\n",
        "class Layer_AB(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.a = Function_A()\n",
        "        self.b = Function_B()\n",
        "\n",
        "        print(f\"    Layer AB Initialized\")\n",
        "\n",
        "    def forward(self, x):\n",
        "        print(f\"    Layer AB started\")\n",
        "        self.a(x)\n",
        "        self.b(x)\n",
        "        print(f\"    Layer AB done\")\n",
        "\n",
        "class Layer_CD(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.c = Function_C()\n",
        "        self.d = Function_D()\n",
        "\n",
        "        print(f\"    Layer CD Initialized\")\n",
        "\n",
        "    def forward(self, x):\n",
        "        print(f\"    Layer CD started\")\n",
        "        self.c(x)\n",
        "        self.d(x)\n",
        "        print(f\"    Layer CD done\")\n",
        "\n",
        "\n",
        "# Model\n",
        "class Model(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.ab = Layer_AB()\n",
        "        self.cd = Layer_CD()\n",
        "\n",
        "        print(f\"Model ABCD Initialized\\n\")\n",
        "\n",
        "    def forward(self, x):\n",
        "        print(f\"Model ABCD started\")\n",
        "        self.ab(x)\n",
        "        self.cd(x)\n",
        "        print(f\"Model ABCD done\\n\")\n",
        "\n",
        "\n",
        "x = torch.tensor([7])\n",
        "\n",
        "model = Model()\n",
        "model(x)\n",
        "\n",
        "print(\"ğŸ‰ğŸ‰ğŸ‰ ëª¨ë“  ë”¥ëŸ¬ë‹ ëª¨ë¸ì€ ì´ì²˜ëŸ¼ Moduleë“¤ì´ ìŒ“ì´ê³  ìŒ“ì—¬ì„œ ë§Œë“¤ì–´ì§‘ë‹ˆë‹¤! ğŸ‰ğŸ‰ğŸ‰\")\n",
        "print(\"ğŸ‰ğŸ‰ğŸ‰ íë¦„ì„ ëŠê»´ë³´ì‹œê³  ì´ íë¦„ì´ ì´í•´ê°€ ë˜ì‹  ë¶„ì€ ë‹¤ìŒìœ¼ë¡œ ê°€ì‹œë©´ ë©ë‹ˆë‹¤! ğŸ‰ğŸ‰\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "        Function A Initialized\n",
            "        Function B Initialized\n",
            "    Layer AB Initialized\n",
            "        Function C Initialized\n",
            "        Function D Initialized\n",
            "    Layer CD Initialized\n",
            "Model ABCD Initialized\n",
            "\n",
            "Model ABCD started\n",
            "    Layer AB started\n",
            "        Function A started\n",
            "        Function A done\n",
            "        Function B started\n",
            "        Function B done\n",
            "    Layer AB done\n",
            "    Layer CD started\n",
            "        Function C started\n",
            "        Function C done\n",
            "        Function D started\n",
            "        Function D done\n",
            "    Layer CD done\n",
            "Model ABCD done\n",
            "\n",
            "ğŸ‰ğŸ‰ğŸ‰ ëª¨ë“  ë”¥ëŸ¬ë‹ ëª¨ë¸ì€ ì´ì²˜ëŸ¼ Moduleë“¤ì´ ìŒ“ì´ê³  ìŒ“ì—¬ì„œ ë§Œë“¤ì–´ì§‘ë‹ˆë‹¤! ğŸ‰ğŸ‰ğŸ‰\n",
            "ğŸ‰ğŸ‰ğŸ‰ íë¦„ì„ ëŠê»´ë³´ì‹œê³  ì´ íë¦„ì´ ì´í•´ê°€ ë˜ì‹  ë¶„ì€ ë‹¤ìŒìœ¼ë¡œ ê°€ì‹œë©´ ë©ë‹ˆë‹¤! ğŸ‰ğŸ‰\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LYE0lhVK2Vow"
      },
      "source": [
        "#### ğŸ‘¨â€ğŸ’» <font color='green'><b>[ ì½”ë”© ]</b></font> Parameter\n",
        "\n",
        "``` python\n",
        "ğŸ¦†\n",
        "linear transformationì¸ Y = XW + b ì— ëŒ€í•´ì„œ ìƒê°í•˜ê³  ìˆì—ˆì–´ìš”!\n",
        "XëŠ” ì €í¬ê°€ torch.Tensorë¡œ ë§Œë“¤ì–´ì„œ ì œê³µí•˜ëŠ”ë° W, bëŠ” ì–´ë””ì„œ ë§Œë“¤ì£ ?\n",
        "\n",
        "ì–¸ëœ» ì¹œêµ¬í•œí…Œ ë“¤ì—ˆëŠ”ë° nn.Moduleì•ˆì— ë¯¸ë¦¬ ë§Œë“¤ì–´ì§„ tensorë“¤ì„\n",
        "ë³´ê´€í•  ìˆ˜ ìˆë‹¤ê³  ë“¤ì€ ê²ƒ ê°™ì•„ìš”! ë­ë¬ì§€, ì•„ë§ˆ Parameterë¼ê³  í•œ ê²ƒ ê°™ì•„ìš”!\n",
        "```\n",
        "\n",
        "- [Documentation main - PyTorch ê³µì‹ ë¬¸ì„œ](https://pytorch.org/docs/stable/index.html)\n",
        "- [torch.nn.parameter.Parameter - PyTorch ê³µì‹ ë¬¸ì„œ](https://pytorch.org/docs/stable/generated/torch.nn.parameter.Parameter.html?highlight=parameter)\n",
        "\n",
        "ğŸ **íŒíŠ¸** ğŸ\n",
        "- [PyTorch linear.py L81 - L85 - PyTorch ê³µì‹ Github](https://github.com/pytorch/pytorch/blob/master/torch/nn/modules/linear.py#L81-L85)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wQoHSQcA2Vo3",
        "outputId": "2a1a9cc9-f118-41b9-d980-b16ecf3e7641"
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn.parameter import Parameter\n",
        "\n",
        "\n",
        "# TODO : Linear ëª¨ë¸ì„ ì™„ì„±í•˜ì„¸ìš”!\n",
        "class Linear(nn.Module):\n",
        "    def __init__(self, in_features, out_features):\n",
        "        super().__init__()\n",
        "\n",
        "        # TODO : W, b parameterë¥¼ ìƒì„±í•˜ì„¸ìš”! ëª¨ë‘ 1ë¡œ ì´ˆê¸°í™”í•´ì£¼ì„¸ìš”!\n",
        "        self.W = Parameter(torch.ones(out_features, in_features))\n",
        "        self.b = Parameter(torch.ones(out_features))\n",
        "\n",
        "    def forward(self, x):\n",
        "        output = torch.addmm(self.b, x, self.W.T)\n",
        "\n",
        "        return output\n",
        "\n",
        "\n",
        "# ì•„ë˜ ì½”ë“œëŠ” ìˆ˜ì •í•˜ì‹¤ í•„ìš”ê°€ ì—†ìŠµë‹ˆë‹¤!\n",
        "x = torch.Tensor([[1, 2],\n",
        "                  [3, 4]])\n",
        "\n",
        "linear = Linear(2, 3)\n",
        "output = linear(x)\n",
        "\n",
        "if torch.all(output == torch.Tensor([[4, 4, 4],\n",
        "                                     [8, 8, 8]])):\n",
        "    print(\"ğŸ‰ğŸ‰ğŸ‰ ì„±ê³µ!!! ğŸ‰ğŸ‰ğŸ‰\")\n",
        "else:\n",
        "    print(\"ğŸ¦† ë‹¤ì‹œ ë„ì „í•´ë´ìš”!\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ğŸ‰ğŸ‰ğŸ‰ ì„±ê³µ!!! ğŸ‰ğŸ‰ğŸ‰\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S8u8jNL8H_dN"
      },
      "source": [
        "#### â“ <font color='red'><b>[ í€´ì¦ˆ ]</b></font> Tensor vs Parameter\n",
        "``` python\n",
        "ğŸ¦†\n",
        "ìƒê°í•´ë³´ë©´ W, bë„ tensorë¥¼ ì´ìš©í•˜ë©´ ë˜ëŠ” ê²ƒ ì•„ë‹Œê°€ìš”?\n",
        "ì™œ êµ³ì´ Parameterë¼ëŠ” ë³„ê°œì˜ í´ë˜ìŠ¤ë¥¼ ì‚¬ìš©í•˜ëŠ” ê±°ì£ ?\n",
        "```\n",
        "ğŸ **íŒíŠ¸** ğŸ\n",
        "- ì•„ë˜ì— ì‘ì„±ëœ ì½”ë“œë¥¼ ì‹¤í–‰ì‹œí‚¤ì‹œë©´ íŒíŠ¸ë¥¼ ì–»ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ULF5STEQH_dO",
        "outputId": "a0c8ccf1-8615-47ab-f582-0390f8fb8683"
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn.parameter import Parameter\n",
        "\n",
        "\n",
        "class Linear_Parameter(nn.Module):\n",
        "    def __init__(self, in_features, out_features):\n",
        "        super().__init__()\n",
        "\n",
        "        # torch.nn.parameter.Parameter\n",
        "        self.W = Parameter(torch.ones((out_features, in_features)))\n",
        "        self.b = Parameter(torch.ones(out_features))\n",
        "\n",
        "    def forward(self, x):\n",
        "        output = torch.addmm(self.b, x, self.W.T)\n",
        "\n",
        "        return output\n",
        "\n",
        "class Linear_Tensor(nn.Module):\n",
        "    def __init__(self, in_features, out_features):\n",
        "        super().__init__()\n",
        "\n",
        "        # torch.Tensor\n",
        "        self.W = torch.ones((out_features, in_features))\n",
        "        self.b = torch.ones(out_features)\n",
        "\n",
        "    def forward(self, x):\n",
        "        output = torch.addmm(self.b, x, self.W.T)\n",
        "\n",
        "        return output\n",
        "\n",
        "\n",
        "x = torch.Tensor([[1, 2],\n",
        "                  [3, 4]])\n",
        "\n",
        "linear_parameter = Linear_Parameter(2, 3)\n",
        "linear_tensor = Linear_Tensor(2, 3)\n",
        "\n",
        "output_parameter = linear_parameter(x)\n",
        "output_tensor = linear_tensor(x)\n",
        "\n",
        "# ê°’ì€ ë™ì¼í•˜ê²Œ ê³„ì‚°ë˜ëŠ” ê²ƒì„ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤!\n",
        "# í•˜ì§€ë§Œ ì¶œë ¥ì„ ìì„¸íˆ ë³´ì‹œë©´, Parameterë¥¼ ì´ìš©í•´ì„œ W, bë¥¼ ë§Œë“¤ ê²½ìš°ì—ë§Œ\n",
        "# output tensorì— gradientë¥¼ ê³„ì‚°í•˜ëŠ” í•¨ìˆ˜ì¸ grad_fnê°€ ìƒì„±ë©ë‹ˆë‹¤\n",
        "print(output_parameter)\n",
        "print(output_tensor)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[4., 4., 4.],\n",
            "        [8., 8., 8.]], grad_fn=<AddmmBackward>)\n",
            "tensor([[4., 4., 4.],\n",
            "        [8., 8., 8.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SCmHCEEWH_dP",
        "outputId": "e2de0e48-8fd6-4bf7-98ed-d619a36b3add"
      },
      "source": [
        "# Parameterë¡œ ë§Œë“  W, bëŠ” ì €ì¥í•  tensorë¡œ ì§€ì •ë˜ì–´ìˆìŠµë‹ˆë‹¤\n",
        "linear_parameter.state_dict()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('W', tensor([[1., 1.],\n",
              "                      [1., 1.],\n",
              "                      [1., 1.]])), ('b', tensor([1., 1., 1.]))])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5obZKlPzH_dP",
        "outputId": "09dce683-170e-426b-bee4-846a3b92776c"
      },
      "source": [
        "# torch.Tensorë¡œ ë§Œë“  W, bëŠ” ì €ì¥ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤\n",
        "linear_tensor.state_dict()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict()"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KH49yfoYH_dR"
      },
      "source": [
        "```python\n",
        "ğŸ˜\n",
        "# TODO : ë§ê³  í‹€ë¦¬ê³ ê°€ ì—†ëŠ” ë¬¸ì œì…ë‹ˆë‹¤. ë¬¸ì„œë¥¼ ì½ê³  ë‹µì„ ììœ ë¡œì´ ì ì–´ì£¼ì„¸ìš”\n",
        "Parameter class ë¥¼ ì´ìš©í•˜ë©´ auto_gradë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆë‹¤. \n",
        "ë˜ ìƒì†ë°›ì€ ë¶€ëª¨í•¨ìˆ˜ì— ì—°ë™ë˜ì–´ ë” íš¨ê³¼ì ìœ¼ë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆë‹¤. \n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C3WfRph4AYrb"
      },
      "source": [
        "#### ğŸ‘¨â€ğŸ’» <font color='green'><b>[ ì½”ë”© ]</b></font> Buffer\n",
        "\n",
        "``` python\n",
        "ğŸ¦†\n",
        "ì¹œêµ¬ê°€ ë§í•˜ê¸¸ Custom ëª¨ë¸ì„ ë§Œë“¤ë•Œ ëŒ€ë¶€ë¶„ torch.nnì— êµ¬í˜„ëœ layerë“¤ì„\n",
        "ê°€ì ¸ê°€ë‹¤ ì‚¬ìš©í•˜ê¸° ë•Œë¬¸ì— Parameterë¥¼ ì§ì ‘ ë‹¤ë¤„ë³¼ ì¼ì€ ë§¤ìš° ë“œë¬¼ ê²ƒì´ë¼ê³  í•˜ë„¤ìš”!\n",
        "\n",
        "ì €í¬ê°€ ì§ì ‘ ìƒˆë¡œìš´ layerë¥¼ ì‘ì„±í• ê²Œ ì•„ë‹ˆë¼ë©´\n",
        "Parameterë¥¼ ì‚¬ìš©í•  ì¼ì´ ê±°ì˜ ì—†ë‹¤ê³  í•´ìš”!\n",
        "\n",
        "í•˜ì§€ë§Œ Parameterë¥¼ ì‚¬ìš©í• ì¤„ ì•„ëŠ” ê²ƒì€ ì¤‘ìš”í•˜ë‹¤ë©´ì„œ ì¹­ì°¬í•´ì¤¬ì–´ìš”!\n",
        "ì¶”ê°€ì ìœ¼ë¡œ bufferë¼ëŠ” ê²ƒë„ ìˆë‹¤ë©´ì„œ ê°€ë¥´ì¼œì£¼ì—ˆì£ !\n",
        "\n",
        "ì¼ë°˜ì ì¸ TensorëŠ” Parameterì™€ ë‹¤ë¥´ê²Œ gradientë¥¼ ê³„ì‚°í•˜ì§€ ì•Šì•„\n",
        "ê°’ë„ ì—…ë°ì´íŠ¸ ë˜ì§€ ì•Šê³ , ëª¨ë¸ì„ ì €ì¥í•  ë•Œ ë¬´ì‹œë˜ì–ì•„ìš”?\n",
        "\n",
        "í•˜ì§€ë§Œ Parameterë¡œ ì§€ì •í•˜ì§€ ì•Šì•„ì„œ ê°’ì´ ì—…ë°ì´íŠ¸ ë˜ì§€ ì•ŠëŠ”ë‹¤ í•´ë„\n",
        "ì €ì¥í•˜ê³ ì‹¶ì€ tensorê°€ ìˆì„ ìˆ˜ë„ ìˆì–ì•„ìš”?\n",
        "\n",
        "ê·¸ëŸ´ë•ŒëŠ” bufferì— tensorë¥¼ ë“±ë¡í•´ì£¼ë©´ ë˜ìš”!\n",
        "ëª¨ë¸ì„ ì €ì¥í• ë•Œ Parameterë¿ë§Œ ì•„ë‹ˆë¼ bufferë¡œ ë“±ë¡ëœ tensorë“¤ë„ ê°™ì´ ì €ì¥ë˜ìš”!\n",
        "\n",
        "ì •ë¦¬í•˜ë©´ ë‹¤ìŒê³¼ ê°™ì•„ìš”!\n",
        "\n",
        "- \"Tensor\"\n",
        "    - âŒ gradient ê³„ì‚°\n",
        "    - âŒ ê°’ ì—…ë°ì´íŠ¸\n",
        "    - âŒ ëª¨ë¸ ì €ì¥ì‹œ ê°’ ì €ì¥\n",
        "- \"Parameter\"\n",
        "    - âœ… gradient ê³„ì‚°\n",
        "    - âœ… ê°’ ì—…ë°ì´íŠ¸\n",
        "    - âœ… ëª¨ë¸ ì €ì¥ì‹œ ê°’ ì €ì¥\n",
        "- \"Buffer\"\n",
        "    - âŒ gradient ê³„ì‚°\n",
        "    - âŒ ê°’ ì—…ë°ì´íŠ¸\n",
        "    - âœ… ëª¨ë¸ ì €ì¥ì‹œ ê°’ ì €ì¥\n",
        "```\n",
        "\n",
        "- [Documentation main - PyTorch ê³µì‹ ë¬¸ì„œ](https://pytorch.org/docs/stable/index.html)\n",
        "- [register_buffer - PyTorch ê³µì‹ ë¬¸ì„œ](https://pytorch.org/docs/stable/generated/torch.nn.Module.html?highlight=register_buffer#torch.nn.Module.register_buffer)\n",
        "\n",
        "**âœ¨ ìœ ìš©í•œ ìë£Œ âœ¨**\n",
        "- [What is the difference between `register_buffer` and `register_parameter` of `nn.Module` - PyTorch Forum](https://discuss.pytorch.org/t/what-is-the-difference-between-register-buffer-and-register-parameter-of-nn-module/32723)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xU_FYpsgAYri",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5565caa8-8c23-4c3d-8c00-ab4c9e293d24"
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn.parameter import Parameter\n",
        "\n",
        "\n",
        "# TODO : Model ëª¨ë¸ì„ ì™„ì„±í•˜ì„¸ìš”!\n",
        "class Model(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.parameter = Parameter(torch.Tensor([7]))\n",
        "        self.tensor = torch.Tensor([7])\n",
        "        self.register_buffer('buffer', self.tensor)\n",
        "\n",
        "        # TODO : torch.Tensor([7])ë¥¼ bufferì´ë¼ëŠ” ì´ë¦„ìœ¼ë¡œ bufferì— ë“±ë¡í•´ë³´ì„¸ìš”!\n",
        "\n",
        "\n",
        "\n",
        "# ì•„ë˜ ì½”ë“œëŠ” ìˆ˜ì •í•˜ì‹¤ í•„ìš”ê°€ ì—†ìŠµë‹ˆë‹¤!\n",
        "model = Model()\n",
        "\n",
        "try:\n",
        "    buffer = model.get_buffer('buffer')\n",
        "    if buffer == 7:\n",
        "        print(\"ğŸ‰ğŸ‰ğŸ‰ ì„±ê³µ!!! ğŸ‰ğŸ‰ğŸ‰\\n\")\n",
        "        print(\"ğŸ‰ ì´ì œ bufferì— ë“±ë¡ëœ tensorëŠ” ëª¨ë¸ì´ ì €ì¥ë  ë•Œ ê°™ì´ ì €ì¥ë ê±°ì˜ˆìš”! ğŸ‰\")\n",
        "        print(model.state_dict())\n",
        "    else:\n",
        "        print(\"ğŸ¦† ë‹¤ì‹œ ë„ì „í•´ë´ìš”!\")\n",
        "except:\n",
        "    print(\"ğŸ¦† ë‹¤ì‹œ ë„ì „í•´ë´ìš”!\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ğŸ‰ğŸ‰ğŸ‰ ì„±ê³µ!!! ğŸ‰ğŸ‰ğŸ‰\n",
            "\n",
            "ğŸ‰ ì´ì œ bufferì— ë“±ë¡ëœ tensorëŠ” ëª¨ë¸ì´ ì €ì¥ë  ë•Œ ê°™ì´ ì €ì¥ë ê±°ì˜ˆìš”! ğŸ‰\n",
            "OrderedDict([('parameter', tensor([7.])), ('buffer', tensor([7.]))])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HY5I6ZQbScV2"
      },
      "source": [
        "``` python\n",
        "ğŸ˜©\n",
        "ì•„ ë„ˆë¬´ ì–´ë ¤ì›Œìš”... ê·¸ë˜ì„œ ì´ê±¸ ì–´ë””ë‹¤ ì“°ëŠ”ë°ìš”..?\n",
        "```\n",
        "``` python\n",
        "ğŸ¦†\n",
        "ê·¸ ë§ í•  ì¤„ ì•Œì•˜ì–´ìš” ì¤€ë¹„í•´ë‘ì—ˆì£ !\n",
        "í•œê°€ì§€ ì¢‹ì€ ì˜ˆì‹œë¡œ BatchNormì—ì„œ ì‚¬ìš©ë˜ìš”!\n",
        "ì•„ë˜ ë§í¬ë¥¼ ì²¨ë¶€í•´ë†“ì•˜ìœ¼ë‹ˆ ë” ì•Œê³  ì‹¶ìœ¼ë©´ ì½ì–´ë³´ì„¸ìš”!\n",
        "\n",
        "ì´ bufferë„ Parameterì™€ ë§ˆì°¬ê°€ì§€ë¡œ ì‚¬ìš©í•  ì¼ì€ ë“œë¬¼ ê²ƒ ê°™ì•„ìš”!\n",
        "í•˜ì§€ë§Œ ì•Œì•„ë‘ë©´ ì–¸ì  ê°€ ìš”ê¸´í•˜ê²Œ ì“¸ ë‚ ì´ ì˜¤ê² ì£ ?\n",
        "```\n",
        "\n",
        "\n",
        "**âœ¨ ìœ ìš©í•œ ìë£Œ âœ¨**\n",
        "- [torch.nn.BatchNorm1d - PyTorch ê³µì‹ ë¬¸ì„œ](https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm1d.html?highlight=buffer)\n",
        "- [PyTorch batchnorm.py L51 - L52 - PyTorch ê³µì‹ Github](https://github.com/pytorch/pytorch/blob/master/torch/nn/modules/batchnorm.py#L51-L52)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jr6BwccdiH5s"
      },
      "source": [
        "### â˜„ï¸ nn.Module ë¶„ì„í•˜ê¸°\n",
        "> ëª¨ë¸ì„ ì œì‘í•¨ì— ìˆì–´ ì¤‘ìš”í•œ ê¸°ë³¸ ê°œë…ë“¤ì„ ì´í•´í•˜ì˜€ìŠµë‹ˆë‹¤. ì´ì œ ì €í¬ëŠ” ì›í•˜ëŠ” ëª¨ë¸ì„ ì œì‘í•  ìˆ˜ ìˆëŠ” í˜ì„ ì–»ê²Œ ë˜ì—ˆìŠµë‹ˆë‹¤. í•˜ì§€ë§Œ custom ëª¨ë¸ì„ ë§Œë“¤ê³  ë‚œ í›„ ì´ ëª¨ë¸ ë‚´ë¶€ê°€ ì–´ë–»ê²Œ êµ¬ì„±ë˜ì—ˆëŠ”ì§€ ì–´ë–»ê²Œ ì•Œ ìˆ˜ ìˆì„ê¹Œìš”? ìì‹ ì´ ë§Œë“  custom ëª¨ë¸ì´ë¼ë©´ ê·¸ëŸ­ì €ëŸ­ ê¸°ì–µì´ ë‚˜ê¸° ë•Œë¬¸ì— ê´œì°®ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ê·¸ë ‡ë‹¤ë©´ ë‹¤ë¥¸ ì‚¬ëŒì˜ ëª¨ë¸ì„ ì°¸ì¡°í•˜ê¸° ìœ„í•´ì„œ ê°€ì ¸ì™”ëŠ”ë° ì´ëŸ° ê²½ìš° ì–´ë–»ê²Œ ê·¸ ëª¨ë¸ ë‚´ë¶€ë¥¼ ë¶„ì„í•  ìˆ˜ ìˆì„ê¹Œìš”? ìš°ë¦¬ëŠ” ê·¸ ë°©ë²•ì— ëŒ€í•´ì„œ ê°€ë³ê²Œ ì•Œì•„ë³´ëŠ” ì‹œê°„ì„ ê°€ì§ˆ ê²ƒì…ë‹ˆë‹¤. \n",
        "\n",
        "- ğŸ‘¨â€ğŸ’» <font color='green'><b>[ ì½”ë”© ]</b></font> ë¶€ë•ì´ ëª¨ë¸ ë¶„ì„í•´ë³´ê¸°\n",
        "- ğŸ‘¨â€ğŸ’» <font color='green'><b>[ ì½”ë”© ]</b></font> ë¶€ë•ì´ ëª¨ë¸ ìˆ˜ì •í•˜ê¸° - module ì°¸ì¡° ì œê±°\n",
        "- ğŸ‘¨â€ğŸ’» <font color='green'><b>[ ì½”ë”© ]</b></font> ë¶€ë•ì´ ëª¨ë¸ ìˆ˜ì •í•˜ê¸° - module ì¶œë ¥ ë‚´ìš© ë³€ê²½í•˜ê¸°\n",
        "- ğŸ‘¨â€ğŸ’» <font color='green'><b>[ ì½”ë”© ]</b></font> ë¶€ë•ì´ ëª¨ë¸ ìˆ˜ì •í•˜ê¸° - Docstring ì‘ì„±\n",
        "- ğŸ‘¨â€ğŸ’» <font color='green'><b>[ ì½”ë”© ]</b></font> BatchNorm1d ë¶„ì„í•´ë³´ê¸°\n",
        "\n",
        "    \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P0rBcgFOdVTL"
      },
      "source": [
        "#### ğŸ‘¨â€ğŸ’» <font color='green'><b>[ ì½”ë”© ]</b></font> ë¶€ë•ì´ ëª¨ë¸ ë¶„ì„í•´ë³´ê¸°\n",
        "\n",
        "``` python\n",
        "ğŸ¦†\n",
        "PyTorchì— ëŒ€í•´ì„œ ì•„ë¬´ê²ƒë„ ëª°ëì—ˆëŠ”ë°\n",
        "ì§ì ‘ ëª¨ë¸ì„ ë§Œë“¤ì–´ë‚¼ ì¤„ ì•Œê²Œ ë˜ë‹¤ë‹ˆ! ì •ë§ ê¿ˆë§Œ ê°™ì•„ìš”!\n",
        "\n",
        "Moduleë“¤ì˜ íë¦„ì„ ëŠê»´ë³´ê¸° ìœ„í•´ ì œê°€ ì‘ì„±í–ˆë˜ ì½”ë“œë¥¼ ë³´ê³ ìˆìœ¼ë‹ˆ\n",
        "ë§ˆìŒ ì† ê¹Šì€ ê³³ì—ì„œ ë¿Œë“¯í•¨ì´ ì†Ÿêµ¬ì³ ì˜¬ë¼ì™€ ë‚ ê°œ ì¶¤ì„ ë©ˆì¶œ ìˆ˜ê°€ ì—†ë„¤ìš”!\n",
        "\n",
        "ê·¸ëŸ°ë° ëª¨ë¸ì„ ë§Œë“¤ê³  ë‚œ í›„ ì–´ë–¤ moduleê³¼ parameterë¥¼ ì¼ëŠ”ì§€\n",
        "ì–´ë–»ê²Œ ì•Œ ìˆ˜ ìˆëŠ” ê±°ì£ ?\n",
        "\n",
        "ëŠë‚Œìƒ \"nn.Module\" Documentationì— ê·¸ ë°©ë²•ì´ ë‚˜ì™€ìˆì„ ê²ƒ ê°™ì•„ìš”!\n",
        "\n",
        "ì œê°€ ì „ì— ì‘ì„±í•´ë†“ì•˜ë˜ ì½”ë“œë¥¼ ê°€ì ¸ì™”ì–´ìš”! ê·¸ë•Œ ë³´ì…¨ì„ ë•Œì™€ ì¡°ê¸ˆ ë‹¤ë¥´ì£ ?\n",
        "ë°°ìš´ ê²ƒì„ ì ìš©í•´ë³´ëŠë¼ê³  ì¡°ê¸ˆì”© ìˆ˜ì •ì„ í•´ë³´ì•˜ì–´ìš”!\n",
        "ì œê°€ ë§Œë“  ì´ ëª¨ë¸ì„ í•¨ê»˜ ë¶„ì„í•´ë´ìš”!\n",
        "```\n",
        "\n",
        "- [Documentation main - PyTorch ê³µì‹ ë¬¸ì„œ](https://pytorch.org/docs/stable/index.html)\n",
        "- [torch.nn.Module - PyTorch ê³µì‹ ë¬¸ì„œ](https://pytorch.org/docs/stable/generated/torch.nn.Module.html)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0wIMxj_7cxSH",
        "outputId": "211836aa-de6a-4dc5-a011-6eea656dd073"
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn.parameter import Parameter\n",
        "\n",
        "\n",
        "# ì•„ë˜ ì½”ë“œëŠ” ìˆ˜ì •í•˜ì‹¤ í•„ìš”ê°€ ì—†ìŠµë‹ˆë‹¤!\n",
        "# í•˜ì§€ë§Œ ì•„ë˜ ê³¼ì œë¥¼ ì§„í–‰í•˜ê¸° ì „ì— ì•„ë˜ ì½”ë“œë¥¼ ë³´ë©´ì„œ ìµœëŒ€í•œ ì´í•´í•´ë³´ì„¸ìš”!\n",
        "\n",
        "# Function\n",
        "class Function_A(nn.Module):\n",
        "    def __init__(self, name):\n",
        "        super().__init__()\n",
        "        self.name = name\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x * 2\n",
        "        return x\n",
        "\n",
        "class Function_B(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.W1 = Parameter(torch.Tensor([10]))\n",
        "        self.W2 = Parameter(torch.Tensor([2]))\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x / self.W1\n",
        "        x = x / self.W2\n",
        "\n",
        "        return x\n",
        "\n",
        "class Function_C(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.register_buffer('duck', torch.Tensor([7]), persistent=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x * self.duck\n",
        "        \n",
        "        return x\n",
        "\n",
        "class Function_D(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.W1 = Parameter(torch.Tensor([3]))\n",
        "        self.W2 = Parameter(torch.Tensor([5]))\n",
        "        self.c = Function_C()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.W1\n",
        "        x = self.c(x)\n",
        "        x = x / self.W2\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "# Layer\n",
        "class Layer_AB(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.a = Function_A('duck')\n",
        "        self.b = Function_B()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.a(x) / 5\n",
        "        x = self.b(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "class Layer_CD(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.c = Function_C()\n",
        "        self.d = Function_D()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.c(x)\n",
        "        x = self.d(x) + 1\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "# Model\n",
        "class Model(nn.Module):\n",
        "    \"\"\"\n",
        "    docstirng\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.ab = Layer_AB()\n",
        "        self.cd = Layer_CD()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.ab(x)\n",
        "        x = self.cd(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "x = torch.tensor([7])\n",
        "\n",
        "model = Model()\n",
        "model.state_dict()\n",
        "# model(x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('ab.b.W1', tensor([10.])),\n",
              "             ('ab.b.W2', tensor([2.])),\n",
              "             ('cd.c.duck', tensor([7.])),\n",
              "             ('cd.d.W1', tensor([3.])),\n",
              "             ('cd.d.W2', tensor([5.])),\n",
              "             ('cd.d.c.duck', tensor([7.]))])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SvtNG5hkeb2G"
      },
      "source": [
        "##### ğŸ’¡ named_children vs named_modules\n",
        "> ğŸ¦† ë¶€ë•ì´ê°€ ì½”ë“œë¥¼ ì‘ì„±í•´ì£¼ì—ˆì–´ìš”\n",
        "\n",
        "``` python\n",
        "ğŸ¦†\n",
        "ì œê°€ ë§Œë“  ëª¨ë¸ì—ì„œ ì–´ë–¤ moduleë“¤ì´ ìˆì—ˆëŠ”ì§€ ê¸°ì–µì´ ë‚˜ì§ˆ ì•Šì•„ìš”!\n",
        "ê·¸ë˜ì„œ ëª¨ë¸ ë‚´ë¶€ì˜ moduleë“¤ ëª©ë¡ì„ ë³´ê³ ì‹¶ì–´ìš”!\n",
        "\n",
        "Documentationì„ ì°¾ì•„ë³´ë‹ˆê¹Œ childrenì´ë‚˜ moduleì´ë¼ëŠ” ì´ë¦„ì„ ê°€ì§„\n",
        "í•¨ìˆ˜ê°€ ë°”ë¡œ ì œê°€ ì›í•˜ëŠ” ê¸°ëŠ¥ì„ ê°€ì§„ ê²ƒ ê°™ì•„ìš”!\n",
        "\n",
        "í•˜ì§€ë§Œ ì´ ë‘˜ì€ ë¬´ìŠ¨ ì°¨ì´ì¼ê¹Œìš”?\n",
        "ì—­ì‹œ ì§ì ‘ ì½”ë“œë¥¼ í†µí•´ì„œ í™•ì¸í•´ë´ì•¼ê² ì–´ìš”!\n",
        "```\n",
        "\n",
        "- [named_children - PyTorch ê³µì‹ ë¬¸ì„œ](https://pytorch.org/docs/stable/generated/torch.nn.Module.html?highlight=child#torch.nn.Module.named_children)\n",
        "- [named_modules - PyTorch ê³µì‹ ë¬¸ì„œ](https://pytorch.org/docs/stable/generated/torch.nn.Module.html?highlight=named#torch.nn.Module.named_modules)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zSZh9S6SjCSQ",
        "outputId": "87e74f80-d799-40f8-ecc7-26e47348dd6d"
      },
      "source": [
        "for name, module in model.named_modules():\n",
        "    print(f\"[ Name ] : {name}\\n[ Module ]\\n{module}\")\n",
        "    print(\"-\" * 30)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ Name ] : \n",
            "[ Module ]\n",
            "Model(\n",
            "  (ab): Layer_AB(\n",
            "    (a): Function_A()\n",
            "    (b): Function_B()\n",
            "  )\n",
            "  (cd): Layer_CD(\n",
            "    (c): Function_C()\n",
            "    (d): Function_D(\n",
            "      (c): Function_C()\n",
            "    )\n",
            "  )\n",
            ")\n",
            "------------------------------\n",
            "[ Name ] : ab\n",
            "[ Module ]\n",
            "Layer_AB(\n",
            "  (a): Function_A()\n",
            "  (b): Function_B()\n",
            ")\n",
            "------------------------------\n",
            "[ Name ] : ab.a\n",
            "[ Module ]\n",
            "Function_A()\n",
            "------------------------------\n",
            "[ Name ] : ab.b\n",
            "[ Module ]\n",
            "Function_B()\n",
            "------------------------------\n",
            "[ Name ] : cd\n",
            "[ Module ]\n",
            "Layer_CD(\n",
            "  (c): Function_C()\n",
            "  (d): Function_D(\n",
            "    (c): Function_C()\n",
            "  )\n",
            ")\n",
            "------------------------------\n",
            "[ Name ] : cd.c\n",
            "[ Module ]\n",
            "Function_C()\n",
            "------------------------------\n",
            "[ Name ] : cd.d\n",
            "[ Module ]\n",
            "Function_D(\n",
            "  (c): Function_C()\n",
            ")\n",
            "------------------------------\n",
            "[ Name ] : cd.d.c\n",
            "[ Module ]\n",
            "Function_C()\n",
            "------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IKfekNTn3D3n",
        "outputId": "ae7c198f-cd66-4c63-deba-ad807d36ed70"
      },
      "source": [
        "for name, child in model.named_children():\n",
        "    print(f\"[ Name ] : {name}\\n[ Children ]\\n{child}\")\n",
        "    print(\"-\" * 30)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ Name ] : ab\n",
            "[ Children ]\n",
            "Layer_AB(\n",
            "  (a): Function_A()\n",
            "  (b): Function_B()\n",
            ")\n",
            "------------------------------\n",
            "[ Name ] : cd\n",
            "[ Children ]\n",
            "Layer_CD(\n",
            "  (c): Function_C()\n",
            "  (d): Function_D(\n",
            "    (c): Function_C()\n",
            "  )\n",
            ")\n",
            "------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fc5uZnP929pS"
      },
      "source": [
        "``` python\n",
        "ğŸ¦†\n",
        "ì•„í•˜! ì´ì œ ì•Œê² ì–´ìš”!\n",
        "\n",
        "\"children\"ì€ í•œ ë‹¨ê³„ ì•„ë˜ì˜ submoduleê¹Œì§€ë§Œ í‘œì‹œí•˜ëŠ” ê²ƒì´ê³ \n",
        "\"modules\"ëŠ” ìì‹ ì—ê²Œ ì†í•˜ëŠ” ëª¨ë“  submoduleë“¤ì„ í‘œì‹œí•´ì£¼ëŠ” ê²ƒì´êµ°ìš”!\n",
        "\n",
        "\"named_modules\", \"named_children\"ì€ moduleì˜ ì´ë¦„ë„ ëŒë ¤ì£¼ëŠ”ë°\n",
        "ê·¸ëƒ¥ moduleë§Œ í•„ìš”í•œ ê²½ìš°ëŠ” \"modules\", \"children\"ë¥¼ ì‚¬ìš©í•˜ë©´ ë˜ê² ë„¤ìš”!\n",
        "\n",
        "ì•„ë‹ˆ ê·¸ëŸ°ë° ì™œ \"Function_D\"ê°€ \"Function_C\"ë¥¼ ì°¸ì¡°í•˜ëŠ” ì¤‘ì´ì£ ?\n",
        "ê°™ì€ ê¸°ë³¸ ë‹¨ìœ„ëŠ” ì„œë¡œ ë…ë¦½ì ì´ì–´ì•¼ í•˜ëŠ”ë° ì´ëŸ¬ë©´ ë¬¸ì œê°€ ìˆì„ ê²ƒ ê°™ì•„ìš”!\n",
        "ë¶„ì„ì´ ëë‚˜ë©´ ìˆ˜ì •ì„ í•´ì•¼ê² ì–´ìš”!\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bC4XBN5k5g53"
      },
      "source": [
        "##### ğŸ’¡ get_submodule\n",
        "\n",
        "``` python\n",
        "ğŸ¦†\n",
        "ì œê°€ ë§Œë“  ëª¨ë¸ ë‚´ë¶€ì— ì–´ë–¤ moduleë“¤ì´ ìˆëŠ”ì§€ ì˜ ì•Œê² ì–´ìš”!\n",
        "ì´ì œ ì œê°€ ì›í•˜ëŠ” íŠ¹ì • moduleë§Œì„ ê°€ì ¸ì˜¤ê³  ì‹¶ì–´ìš”!\n",
        "\n",
        "Function_Aë¥¼ ê°€ì ¸ë‹¤ ì¤„ ìˆ˜ ìˆì„ê¹Œìš”?\n",
        "```\n",
        "\n",
        "- [get_submodule - PyTorch ê³µì‹ ë¬¸ì„œ](https://pytorch.org/docs/stable/generated/torch.nn.Module.html?highlight=get_submodule#torch.nn.Module.get_submodule)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MSYN3x5hl4Wf",
        "outputId": "9614cd32-bca2-48cc-e381-5cfa7f1c0a20"
      },
      "source": [
        "# TODO : Function_A ë¥¼ ê°€ì ¸ì˜¤ì„¸ìš”!\n",
        "submodule = model.get_submodule('ab.a')\n",
        "\n",
        "\n",
        "# ì•„ë˜ ì½”ë“œëŠ” ìˆ˜ì •í•˜ì‹¤ í•„ìš”ê°€ ì—†ìŠµë‹ˆë‹¤!\n",
        "if submodule.__class__.__name__  == 'Function_A':\n",
        "    print(\"ğŸ‰ğŸ‰ğŸ‰ ì„±ê³µ!!! ğŸ‰ğŸ‰ğŸ‰\")\n",
        "else:\n",
        "    print(\"ğŸ¦† ë‹¤ì‹œ ë„ì „í•´ë´ìš”!\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ğŸ‰ğŸ‰ğŸ‰ ì„±ê³µ!!! ğŸ‰ğŸ‰ğŸ‰\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "87fdrrUW_Eyg"
      },
      "source": [
        "##### ğŸ’¡ Parameter\n",
        "\n",
        "``` python\n",
        "ğŸ¦†\n",
        "ì´ì œ moduleì— ëŒ€í•œ ìì‹ ê°ì´ ìƒê²¼ì–´ìš”!\n",
        "ê·¸ëŸ°ë° ë¬¸ë“ ìƒê°í•´ë³´ë‹ˆê¹Œ Parameterì— ëŒ€í•´ì„œ ê³µë¶€í•˜ë©´ì„œ\n",
        "ì œê°€ ì–´ë–¤ ëª¨ë“ˆì— Parameterë¥¼ ìƒì„±í•´ë†¨ë˜ ê²ƒ ê°™ì•„ìš”!\n",
        "\n",
        "ì €í¬ê°€ moduleì—ì„œ module ëª©ë¡ì„ ë³´ê³  íŠ¹ì • moduleì„\n",
        "ì°¾ê¸°ë„ í–ˆë˜ ê²ƒì²˜ëŸ¼ Parameterì—ì„œë„ ë˜‘ê°™ì´ í•´ë´ìš”!\n",
        "```\n",
        "\n",
        "- [parameters - PyTorch ê³µì‹ ë¬¸ì„œ](https://pytorch.org/docs/stable/generated/torch.nn.Module.html?highlight=parameters#torch.nn.Module.parameters)\n",
        "- [named_parameters - PyTorch ê³µì‹ ë¬¸ì„œ](https://pytorch.org/docs/stable/generated/torch.nn.Module.html?highlight=named#torch.nn.Module.named_parameters)\n",
        "- [get_parameter - PyTorch ê³µì‹ ë¬¸ì„œ](https://pytorch.org/docs/stable/generated/torch.nn.Module.html?highlight=get#torch.nn.Module.get_parameter)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5HZk5-vlly_P",
        "outputId": "49074ca7-40df-463a-9f44-8379b89356f7"
      },
      "source": [
        "# ğŸ¦† ì œê°€ 4ê°œì˜ Parameterë¥¼ ë§Œë“¤ì—ˆì—ˆêµ°ìš”!\n",
        "print(model.state_dict())\n",
        "for name, parameter in model.named_parameters():\n",
        "    print(f\"[ Name ] : {name}\\n[ Parameter ]\\n{parameter}\")\n",
        "    print(\"-\" * 30)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "OrderedDict([('ab.b.W1', tensor([10.])), ('ab.b.W2', tensor([2.])), ('cd.c.duck', tensor([7.])), ('cd.d.W1', tensor([3.])), ('cd.d.W2', tensor([5.])), ('cd.d.c.duck', tensor([7.]))])\n",
            "[ Name ] : ab.b.W1\n",
            "[ Parameter ]\n",
            "Parameter containing:\n",
            "tensor([10.], requires_grad=True)\n",
            "------------------------------\n",
            "[ Name ] : ab.b.W2\n",
            "[ Parameter ]\n",
            "Parameter containing:\n",
            "tensor([2.], requires_grad=True)\n",
            "------------------------------\n",
            "[ Name ] : cd.d.W1\n",
            "[ Parameter ]\n",
            "Parameter containing:\n",
            "tensor([3.], requires_grad=True)\n",
            "------------------------------\n",
            "[ Name ] : cd.d.W2\n",
            "[ Parameter ]\n",
            "Parameter containing:\n",
            "tensor([5.], requires_grad=True)\n",
            "------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lWwtgIOBD5-0"
      },
      "source": [
        "``` python\n",
        "ğŸ¦†\n",
        "ì•„í•˜! ì œê°€ 4ê°œì˜ Parameterë¥¼ ë§Œë“¤ì—ˆì—ˆë„¤ìš”!\n",
        "ì´ë¦„ì„ í‘œì‹œí•˜ë‹ˆê¹Œ Parameterê°€ ì–´ë””ì— ì†í•˜ëŠ”ì§€ ì•Œ ìˆ˜ ìˆì–´ ë„ˆë¬´ ì¢‹ì•„ìš”!\n",
        "\n",
        "- \"Function_B\"ì— W1, W2 Parameter 2ê°œ\n",
        "- \"Function_D\"ì— W1, W2 Parameter 2ê°œ\n",
        "\n",
        "\"parameters\"ë¥¼ ì‚¬ìš©í•´ì„œ ëª©ë¡ì„ í™•ì¸í•´ë„ ë˜ì§€ë§Œ\n",
        "ì´ë¦„ì´ í‘œì‹œ ì•ˆë˜ë‹ˆê¹Œ ì–´ë–¤ moduleì— ì†í•œ\n",
        "Parameterì¸ì§€ ì•Œê¸°ê°€ ë„ˆë¬´ í˜ë“¤ ê²ƒ ê°™ì•„ìš”!\n",
        "\n",
        "Function_Bì— ì†í•´ìˆëŠ” Parameter W1ì„ ì‚¬ìš©í•˜ê³  ì‹¶ì€ë°\n",
        "ì´ë¥¼ ê°€ì ¸ë‹¤ ì£¼ì‹¤ìˆ˜ ìˆë‚˜ìš”?\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hIhreLUX_Eyj",
        "outputId": "cfc41dcd-9b10-4c10-c379-b79d45a3f253"
      },
      "source": [
        "# TODO : Function_Bì— ì†í•˜ëŠ” Parameter W1ì„ ê°€ì ¸ì˜¤ì„¸ìš”!\n",
        "parameter = model.get_parameter('ab.b.W1')\n",
        "\n",
        "\n",
        "# ì•„ë˜ ì½”ë“œëŠ” ìˆ˜ì •í•˜ì‹¤ í•„ìš”ê°€ ì—†ìŠµë‹ˆë‹¤!\n",
        "if parameter  == 10:\n",
        "    print(\"ğŸ‰ğŸ‰ğŸ‰ ì„±ê³µ!!! ğŸ‰ğŸ‰ğŸ‰\")\n",
        "else:\n",
        "    print(\"ğŸ¦† ë‹¤ì‹œ ë„ì „í•´ë´ìš”!\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ğŸ‰ğŸ‰ğŸ‰ ì„±ê³µ!!! ğŸ‰ğŸ‰ğŸ‰\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ZC6RK20H8iC"
      },
      "source": [
        "##### ğŸ’¡ Buffer\n",
        "\n",
        "``` python\n",
        "ğŸ¦†\n",
        "ìƒê°ì„ í•´ë³´ë‹ˆê¹Œ bufferë„ í•˜ë‚˜ ì¶”ê°€í•´ë’€ë˜ ê²ƒ ê°™ì•„ìš”!\n",
        "bufferë„ ê°™ì´ ë¶„ì„í•´ë´ìš”!\n",
        "```\n",
        "\n",
        "- [buffers - PyTorch ê³µì‹ ë¬¸ì„œ](https://pytorch.org/docs/stable/generated/torch.nn.Module.html?highlight=buffers#torch.nn.Module.buffers)\n",
        "- [named_buffers - PyTorch ê³µì‹ ë¬¸ì„œ](https://pytorch.org/docs/stable/generated/torch.nn.Module.html?highlight=named_buffers#torch.nn.Module.named_buffers)\n",
        "- [get_buffer - PyTorch ê³µì‹ ë¬¸ì„œ](https://pytorch.org/docs/stable/generated/torch.nn.Module.html?highlight=get_buffer#torch.nn.Module.get_buffer)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4AxUn_jgH8iE",
        "outputId": "834dcb18-8a6c-4d0c-902d-d34b50e56d0f"
      },
      "source": [
        "# TODO : named_buffersë¥¼ ì‚¬ìš©í•´ì„œ modelì— ì†í•˜ëŠ” buffer ì „ì²´ ëª©ë¡ì„ ê°€ì ¸ì˜¤ì„¸ìš”!\n",
        "for name, buffer in model.named_buffers():\n",
        "    print(f\"[ Name ] : {name}\\n[ Buffer ] : {buffer}\")\n",
        "    print(\"-\" * 30)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ Name ] : cd.c.duck\n",
            "[ Buffer ] : tensor([7.])\n",
            "------------------------------\n",
            "[ Name ] : cd.d.c.duck\n",
            "[ Buffer ] : tensor([7.])\n",
            "------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xWjaJqgWI5r-",
        "outputId": "e7989384-95f9-49b0-a497-f0f7187da285"
      },
      "source": [
        "# TODO : buffersë¥¼ ì‚¬ìš©í•´ì„œ modelì— ì†í•˜ëŠ” buffer ì „ì²´ ëª©ë¡ì„ ê°€ì ¸ì˜¤ì„¸ìš”!\n",
        "for buffer in model.buffers():\n",
        "    print(f\"[ Buffer ] : {buffer}\")\n",
        "    print(\"-\" * 30)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ Buffer ] : tensor([7.])\n",
            "------------------------------\n",
            "[ Buffer ] : tensor([7.])\n",
            "------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B2ePuoOWH8iF",
        "outputId": "3ace4e4f-0f62-4227-f6ea-3e4c889755db"
      },
      "source": [
        "# TODO : Function_Cì— ì†í•˜ëŠ” Bufferë¥¼ ê°€ì ¸ì˜¤ì„¸ìš”!\n",
        "buffer = model.get_buffer('cd.c.duck')\n",
        "\n",
        "\n",
        "# ì•„ë˜ ì½”ë“œëŠ” ìˆ˜ì •í•˜ì‹¤ í•„ìš”ê°€ ì—†ìŠµë‹ˆë‹¤!\n",
        "if buffer == 7:\n",
        "    print(\"ğŸ‰ğŸ‰ğŸ‰ ì„±ê³µ!!! ğŸ‰ğŸ‰ğŸ‰\")\n",
        "else:\n",
        "    print(\"ğŸ¦† ë‹¤ì‹œ ë„ì „í•´ë´ìš”!\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ğŸ‰ğŸ‰ğŸ‰ ì„±ê³µ!!! ğŸ‰ğŸ‰ğŸ‰\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JfrjK8Q5tNH6"
      },
      "source": [
        "##### ğŸ’¡ Docstring\n",
        "\n",
        "``` python\n",
        "ğŸ¦†\n",
        "ì•„ì°¨! ê¹œë¹¡ ìŠì—ˆë„¤ìš”!\n",
        "\n",
        "PyTorchì—ì„œ ì œê³µí•˜ëŠ” í•¨ìˆ˜ë‚˜ í´ë˜ìŠ¤ë“¤ì€ ëª¨ë‘ Docstringì´ ì‘ì„±ë˜ì–´ìˆì–´ìš”!\n",
        "í•˜ì§€ë§Œ Documentationì„ ë³´ëŠ” ê²ƒì´ ë” í¸ë¦¬í•˜ê¸° ë•Œë¬¸ì— êµ³ì´ ì´ìš©í•˜ì§€ëŠ” ì•Šì£ !\n",
        "\n",
        "custom ëª¨ë¸ì„ ë§Œë“œëŠ” ì¤‘ì´ê³  ì´ custom ëª¨ë¸ì„ ì‚¬ìš©í• \n",
        "ë‹¤ë¥¸ ê°œë°œìë“¤ê³¼ ë¯¸ë˜ì˜ ìì‹ ì„ ìœ„í•´ì„œ Docstring ì‘ì„±ì€ í•„ìˆ˜ì—ìš”!\n",
        "ë‚˜ì¤‘ì— Documentationì„ ë§Œë“¤ë•Œë„ ì´ Docstringì´ ìˆë‹¤ë©´ ë§Œë“¤ê¸°ê°€ ìˆ˜ì›”í•˜ê² ì£ ?\n",
        "\n",
        "ê¸°ì´ˆì ì¸ ì‹¤ìˆ˜ë¥¼ í–ˆë„¤ìš”!\n",
        "ë‚˜ì¤‘ì— Docstringì„ ì¶”ê°€í•´ì•¼ê² ì–´ìš”!\n",
        "```\n",
        "- [Docstring - Wikipedia](https://en.wikipedia.org/wiki/Docstring)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tCkBRdsItfTQ",
        "outputId": "5340aeb6-49f0-4cf8-be18-1b7031ce23ac"
      },
      "source": [
        "print(model.__doc__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "    docstirng\n",
            "    \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VeIqAIk1NTUh"
      },
      "source": [
        "#### ğŸ‘¨â€ğŸ’» <font color='green'><b>[ ì½”ë”© ]</b></font> ë¶€ë•ì´ ëª¨ë¸ ìˆ˜ì •í•˜ê¸° - module ì°¸ì¡° ì œê±°\n",
        "\n",
        "``` python\n",
        "ğŸ¦†\n",
        "ì œ ëª¨ë¸ì„ ë¶„ì„í•˜ë©´ì„œ ì•Œê²Œ ë˜ì—ˆëŠ”ë° ì œê°€ ê°€ì¥ ê¸°ë³¸ ë‹¨ìœ„ë¡œ ë§Œë“¤ì–´ë†“ì€\n",
        "\"Function_D\"ê°€ \"Function_C\"ë¥¼ í¬í•¨í•˜ê³  ìˆë”ë¼êµ¬ìš”!\n",
        "ì €ëŠ” ê¸°ë³¸ ë‹¨ìœ„ì¸ moduleë¼ë¦¬ ì„œë¡œ ì°¸ì¡°í•˜ëŠ” ê±¸ ì›í•˜ì§€ ì•Šì•„ìš”!\n",
        "\n",
        "ê·¸ë¦¬ê³  \"Function_C\"ë¥¼ \"Function_D\"ì—ì„œ ì œê±°í•´ë„\n",
        "ì „ì²´ ì—°ì‚°ì˜ ê²°ê³¼ëŠ” ë™ì¼í•˜ê²Œ í•˜ê³  ì‹¶ì–´ìš”!\n",
        "\n",
        "ê°™ì´ ìˆ˜ì • í•´ë´ìš”!\n",
        "```\n",
        "\n",
        "- [Documentation main - PyTorch ê³µì‹ ë¬¸ì„œ](https://pytorch.org/docs/stable/index.html)\n",
        "- [torch.nn.Module - PyTorch ê³µì‹ ë¬¸ì„œ](https://pytorch.org/docs/stable/generated/torch.nn.Module.html)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A95FtG-1Px7k",
        "outputId": "9f3fe836-3092-4b4c-f802-a1c169ea227c"
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn.parameter import Parameter\n",
        "\n",
        "\n",
        "# Function\n",
        "class Function_A(nn.Module):\n",
        "    def __init__(self, name):\n",
        "        super().__init__()\n",
        "        self.name = name\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x * 2\n",
        "        return x\n",
        "\n",
        "class Function_B(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.W1 = Parameter(torch.Tensor([10]))\n",
        "        self.W2 = Parameter(torch.Tensor([2]))\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x / self.W1\n",
        "        x = x / self.W2\n",
        "\n",
        "        return x\n",
        "\n",
        "class Function_C(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.register_buffer('duck', torch.Tensor([7]), persistent=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x * self.duck\n",
        "        \n",
        "        return x\n",
        "\n",
        "# TODO : Function_Cì— ëŒ€í•œ ì°¸ì¡°ë¥¼ ì—†ì• ê³ , ëŒ€ì²´í•  ìˆ˜ ìˆëŠ” ì—°ì‚°ì„ ì¶”ê°€í•˜ì„¸ìš”!\n",
        "#        ì „ì²´ ëª¨ë¸ì˜ ì—°ì‚° ê²°ê³¼ëŠ” ë°”ë€Œë©´ ì•ˆë©ë‹ˆë‹¤!\n",
        "class Function_D(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.W1 = Parameter(torch.Tensor([3]))\n",
        "        self.W2 = Parameter(torch.Tensor([5]))\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.W1\n",
        "        x = x * torch.Tensor([7])\n",
        "        x = x / self.W2\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "# Layer\n",
        "class Layer_AB(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.a = Function_A('duck')\n",
        "        self.b = Function_B()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.a(x) / 5\n",
        "        x = self.b(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "class Layer_CD(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.c = Function_C()\n",
        "        self.d = Function_D()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.c(x)\n",
        "        x = self.d(x) + 1\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "# Model\n",
        "class Model(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.ab = Layer_AB()\n",
        "        self.cd = Layer_CD()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.ab(x)\n",
        "        x = self.cd(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "\n",
        "# ì•„ë˜ ì½”ë“œëŠ” ìˆ˜ì •í•˜ì‹¤ í•„ìš”ê°€ ì—†ìŠµë‹ˆë‹¤!\n",
        "x = torch.tensor([7])\n",
        "\n",
        "model = Model()\n",
        "output = model(x)\n",
        "\n",
        "fixed = 1\n",
        "# test = Function_C()\n",
        "# output = test(torch.Tensor([1]))\n",
        "# print(output)\n",
        "for name, _ in model.named_modules():\n",
        "    if 'cd.d.c' == name:\n",
        "        print(\"ğŸ¦† ì•„ì§ Function_Dê°€ Function_Cë¥¼ ì°¸ì¡°í•˜ê³  ìˆë„¤ìš”!\")\n",
        "        fixed = 0\n",
        "\n",
        "if fixed:\n",
        "    if output == 6.5720:\n",
        "        print(\"ğŸ‰ğŸ‰ğŸ‰ ì„±ê³µ!!! ğŸ‰ğŸ‰ğŸ‰\")\n",
        "    else:\n",
        "        print(output)\n",
        "        print(\"ğŸ¦† moduleê°„ ì°¸ì¡°ëŠ” ì„±ê³µì ìœ¼ë¡œ ìˆ˜ì •ë˜ì—ˆëŠ”ë° ëª¨ë¸ ì—°ì‚°ì´ ë‹¬ë¼ì¡Œì–´ìš”!\")\n",
        "        print(\"ğŸ¦† Function_Cë¥¼ ì œê±°í•˜ì‹œë©´ì„œ í•´ë‹¹ ì—°ì‚°ì„ ëŒ€ì²´í•˜ëŠ” ì—°ì‚°ì„ Function_Dì— ì¶”ê°€í•˜ì„¸ìš”!\")\n",
        "else:\n",
        "    print(\"ğŸ¦† ë‹¤ì‹œ ë„ì „í•´ë´ìš”!\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ğŸ‰ğŸ‰ğŸ‰ ì„±ê³µ!!! ğŸ‰ğŸ‰ğŸ‰\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ij7zgUmsUwD6"
      },
      "source": [
        "#### ğŸ‘¨â€ğŸ’» <font color='green'><b>[ ì½”ë”© ]</b></font> ë¶€ë•ì´ ëª¨ë¸ ìˆ˜ì •í•˜ê¸° - module ì¶œë ¥ ë‚´ìš© ë³€ê²½í•˜ê¸°\n",
        "\n",
        "``` python\n",
        "ğŸ¦†\n",
        "Function ë‹¨ìœ„ moduleì¸ \"Function_A\"ì˜ ê²½ìš°ì—\n",
        "instanceë¥¼ ìƒì„±í•˜ë ¤ë©´ ì´ë¦„ì„ ì…ë ¥í•˜ë„ë¡ í–ˆì–´ìš”!\n",
        "ê·¸ë˜ì„œ ë‹¤ìŒì²˜ëŸ¼ \"Function_A\"ë¥¼ ìƒì„±í•˜ì˜€ì£ !\n",
        "\n",
        "# Function_A('duck')\n",
        "\n",
        "ì €ëŠ” ì™„ì„±ëœ ëª¨ë¸ì„ ì¶œë ¥í•˜ë©´ ë‹¤ìŒì²˜ëŸ¼ ë‚˜ì˜¤ê¸¸ ì›í–ˆì–´ìš”!\n",
        "\n",
        "âœ… ë¶€ë•ì´ê°€ ì›í•˜ëŠ” ì´ìƒì ì¸ ì¶œë ¥\n",
        "Model(\n",
        "  (ab): Layer_AB(\n",
        "    (a): Function_A(name=duck)\n",
        "    (b): Function_B()\n",
        "  )\n",
        "  (cd): Layer_CD(\n",
        "    (c): Function_C()\n",
        "    (d): Function_D()\n",
        "  )\n",
        ")\n",
        "\n",
        "í•˜ì§€ë§Œ ì‹¤ì œë¡œ ì¶œë ¥í•´ë³´ë‹ˆ ë‹¤ìŒê³¼ ê°™ì´ ë‚˜ì˜¤ë”ë¼êµ¬ìš”.\n",
        "\n",
        "âŒ ì‹¤ì œ ì¶œë ¥ ê²°ê³¼\n",
        "Model(\n",
        "  (ab): Layer_AB(\n",
        "    (a): Function_A()\n",
        "    (b): Function_B()\n",
        "  )\n",
        "  (cd): Layer_CD(\n",
        "    (c): Function_C()\n",
        "    (d): Function_D()\n",
        "  )\n",
        ")\n",
        "\n",
        "ì´ë¥¼ ì–´ì©Œë©´ ì¢‹ì„ê¹Œìš”? ê½‰ê½‰!ğŸ’¦\n",
        "```\n",
        "\n",
        "- [Documentation main - PyTorch ê³µì‹ ë¬¸ì„œ](https://pytorch.org/docs/stable/index.html)\n",
        "- [extra_repr - PyTorch ê³µì‹ ë¬¸ì„œ](https://pytorch.org/docs/stable/generated/torch.nn.Module.html?highlight=repr#torch.nn.Module.extra_repr)\n",
        "\n",
        "ğŸ **íŒíŠ¸** ğŸ\n",
        "- nn.Module í´ë˜ìŠ¤ì—ì„œ reprê´€ë ¨ methodë¥¼ ì°¾ì•„ë³´ì„¸ìš”!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "enxjXUKNUwD9",
        "outputId": "478a6639-eca9-4b0f-8bf0-36d479ad8c5b"
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn.parameter import Parameter\n",
        "\n",
        "\n",
        "# Function\n",
        "\n",
        "# TODO : Function_Aë¥¼ ìˆ˜ì •í•´ì„œ ë¶€ë•ì´ê°€ ì›í•˜ëŠ” ì¶œë ¥ì´ ë‚˜ì˜¤ë„ë¡ í•´ì£¼ì„¸ìš”!\n",
        "class Function_A(nn.Module):\n",
        "    def __init__(self, name):\n",
        "        super().__init__()\n",
        "        self.name = name\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x * 2\n",
        "        return x\n",
        "      \n",
        "    # def __repr__(self):\n",
        "    #     return \"Function_A(name=duck)\"\n",
        "    def extra_repr(self):\n",
        "          return \"name={}\".format(self.name)\n",
        "    \n",
        "\n",
        "class Function_B(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.W1 = Parameter(torch.Tensor([10]))\n",
        "        self.W2 = Parameter(torch.Tensor([2]))\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x / self.W1\n",
        "        x = x / self.W2\n",
        "\n",
        "        return x\n",
        "\n",
        "class Function_C(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.register_buffer('duck', torch.Tensor([7]), persistent=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x * self.duck\n",
        "        \n",
        "        return x\n",
        "\n",
        "class Function_D(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.W1 = Parameter(torch.Tensor([3]))\n",
        "        self.W2 = Parameter(torch.Tensor([5]))\n",
        "        self.register_buffer('duck', torch.Tensor([7]), persistent=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.W1\n",
        "        x = x * self.duck\n",
        "        x = x / self.W2\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "# Layer\n",
        "class Layer_AB(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.a = Function_A('duck')\n",
        "        self.b = Function_B()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.a(x) / 5\n",
        "        x = self.b(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "class Layer_CD(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.c = Function_C()\n",
        "        self.d = Function_D()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.c(x)\n",
        "        x = self.d(x) + 1\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "# Model\n",
        "class Model(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.ab = Layer_AB()\n",
        "        self.cd = Layer_CD()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.ab(x)\n",
        "        x = self.cd(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "# ì•„ë˜ ì½”ë“œëŠ” ìˆ˜ì •í•˜ì‹¤ í•„ìš”ê°€ ì—†ìŠµë‹ˆë‹¤!\n",
        "model = Model()\n",
        "\n",
        "model_repr = repr(model)\n",
        "\n",
        "print(\"ëª¨ë¸ ì¶œë ¥ ê²°ê³¼\")\n",
        "print(\"-\" * 30)\n",
        "print(model_repr)\n",
        "print(\"-\" * 30)\n",
        "\n",
        "answer = \"Model(\\n  (ab): Layer_AB(\\n    (a): Function_A(name=duck)\\n    (b): Function_B()\\n  )\\n  (cd): Layer_CD(\\n    (c): Function_C()\\n    (d): Function_D()\\n  )\\n)\"\n",
        "\n",
        "if model_repr == answer:\n",
        "    print(\"ğŸ‰ğŸ‰ğŸ‰ ì„±ê³µ!!! ğŸ‰ğŸ‰ğŸ‰\")\n",
        "    print(\"ğŸ¦† ë„ˆë¬´ ê³ ë§ˆì›Œìš” ê½‰ê½‰!\")\n",
        "else:\n",
        "    print(\"ğŸ¦† ë‹¤ì‹œ ë„ì „í•´ë´ìš”!\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ëª¨ë¸ ì¶œë ¥ ê²°ê³¼\n",
            "------------------------------\n",
            "Model(\n",
            "  (ab): Layer_AB(\n",
            "    (a): Function_A(name=duck)\n",
            "    (b): Function_B()\n",
            "  )\n",
            "  (cd): Layer_CD(\n",
            "    (c): Function_C()\n",
            "    (d): Function_D()\n",
            "  )\n",
            ")\n",
            "------------------------------\n",
            "ğŸ‰ğŸ‰ğŸ‰ ì„±ê³µ!!! ğŸ‰ğŸ‰ğŸ‰\n",
            "ğŸ¦† ë„ˆë¬´ ê³ ë§ˆì›Œìš” ê½‰ê½‰!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B6lHaqZqvnb5"
      },
      "source": [
        "#### ğŸ‘¨â€ğŸ’» <font color='green'><b>[ ì½”ë”© ]</b></font> ë¶€ë•ì´ ëª¨ë¸ ìˆ˜ì •í•˜ê¸° - Docstring ì‘ì„±\n",
        "\n",
        "``` python\n",
        "ğŸ¦†\n",
        "ê°€ë³ê²Œ Docstringì„ ì‘ì„±í•´ë´ìš”!\n",
        "Numpy, Pydoc, Google ë“± ë‹¤ì–‘í•œ ìŠ¤íƒ€ì¼ì´ ìˆìœ¼ë‹ˆê¹Œ ê¶ê¸ˆí•˜ë©´\n",
        "ì•„ë˜ ë§í¬ì—ì„œ ì½ì–´ë³´ë©´ì„œ ê³µë¶€í•´ë³´ë„ë¡ í•´ìš”!\n",
        "\n",
        "ì§€ê¸ˆì€ ìŠ¤íƒ€ì¼ ìƒê´€ì—†ì´ Docstringì´ë¼ëŠ” ê²ƒì„ ì¶”ê°€í•˜ê¸°ë§Œ í•´ë³´ì£ !\n",
        "```\n",
        "\n",
        "- [Documentation main - PyTorch ê³µì‹ ë¬¸ì„œ](https://pytorch.org/docs/stable/index.html)\n",
        "\n",
        "**âœ¨ ìœ ìš©í•œ ìë£Œ âœ¨**\n",
        "- [Docstrings in Python - Data Camp](https://www.datacamp.com/community/tutorials/docstrings-python)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X8_KUU4AvncC",
        "outputId": "034bace3-3e90-43cf-ce58-6fff6c0f3a1a"
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn.parameter import Parameter\n",
        "\n",
        "# TODO : Docstringì„ ì¶”ê°€í•´ë³´ì„¸ìš”!\n",
        "class Model(nn.Module):\n",
        "    \"\"\"\n",
        "    docstring\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "\n",
        "\n",
        "# ì•„ë˜ ì½”ë“œëŠ” ìˆ˜ì •í•˜ì‹¤ í•„ìš”ê°€ ì—†ìŠµë‹ˆë‹¤!\n",
        "model = Model()\n",
        "\n",
        "if model.__doc__:\n",
        "    print(\"ğŸ‰ğŸ‰ğŸ‰ ì„±ê³µ!!! ğŸ‰ğŸ‰ğŸ‰\")\n",
        "else:\n",
        "    print(\"ğŸ¦† ë‹¤ì‹œ ë„ì „í•´ë´ìš”!\")\n",
        "help(model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ğŸ‰ğŸ‰ğŸ‰ ì„±ê³µ!!! ğŸ‰ğŸ‰ğŸ‰\n",
            "Help on Model in module __main__ object:\n",
            "\n",
            "class Model(torch.nn.modules.module.Module)\n",
            " |  docstring\n",
            " |  \n",
            " |  Method resolution order:\n",
            " |      Model\n",
            " |      torch.nn.modules.module.Module\n",
            " |      builtins.object\n",
            " |  \n",
            " |  Methods defined here:\n",
            " |  \n",
            " |  __init__(self)\n",
            " |      Initializes internal Module state, shared by both nn.Module and ScriptModule.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Methods inherited from torch.nn.modules.module.Module:\n",
            " |  \n",
            " |  __call__ = _call_impl(self, *input, **kwargs)\n",
            " |  \n",
            " |  __delattr__(self, name)\n",
            " |      Implement delattr(self, name).\n",
            " |  \n",
            " |  __dir__(self)\n",
            " |      Default dir() implementation.\n",
            " |  \n",
            " |  __getattr__(self, name: str) -> Union[torch.Tensor, ForwardRef('Module')]\n",
            " |  \n",
            " |  __repr__(self)\n",
            " |      Return repr(self).\n",
            " |  \n",
            " |  __setattr__(self, name: str, value: Union[torch.Tensor, ForwardRef('Module')]) -> None\n",
            " |      Implement setattr(self, name, value).\n",
            " |  \n",
            " |  __setstate__(self, state)\n",
            " |  \n",
            " |  add_module(self, name: str, module: Union[ForwardRef('Module'), NoneType]) -> None\n",
            " |      Adds a child module to the current module.\n",
            " |      \n",
            " |      The module can be accessed as an attribute using the given name.\n",
            " |      \n",
            " |      Args:\n",
            " |          name (string): name of the child module. The child module can be\n",
            " |              accessed from this module using the given name\n",
            " |          module (Module): child module to be added to the module.\n",
            " |  \n",
            " |  apply(self: ~T, fn: Callable[[ForwardRef('Module')], NoneType]) -> ~T\n",
            " |      Applies ``fn`` recursively to every submodule (as returned by ``.children()``)\n",
            " |      as well as self. Typical use includes initializing the parameters of a model\n",
            " |      (see also :ref:`nn-init-doc`).\n",
            " |      \n",
            " |      Args:\n",
            " |          fn (:class:`Module` -> None): function to be applied to each submodule\n",
            " |      \n",
            " |      Returns:\n",
            " |          Module: self\n",
            " |      \n",
            " |      Example::\n",
            " |      \n",
            " |          >>> @torch.no_grad()\n",
            " |          >>> def init_weights(m):\n",
            " |          >>>     print(m)\n",
            " |          >>>     if type(m) == nn.Linear:\n",
            " |          >>>         m.weight.fill_(1.0)\n",
            " |          >>>         print(m.weight)\n",
            " |          >>> net = nn.Sequential(nn.Linear(2, 2), nn.Linear(2, 2))\n",
            " |          >>> net.apply(init_weights)\n",
            " |          Linear(in_features=2, out_features=2, bias=True)\n",
            " |          Parameter containing:\n",
            " |          tensor([[ 1.,  1.],\n",
            " |                  [ 1.,  1.]])\n",
            " |          Linear(in_features=2, out_features=2, bias=True)\n",
            " |          Parameter containing:\n",
            " |          tensor([[ 1.,  1.],\n",
            " |                  [ 1.,  1.]])\n",
            " |          Sequential(\n",
            " |            (0): Linear(in_features=2, out_features=2, bias=True)\n",
            " |            (1): Linear(in_features=2, out_features=2, bias=True)\n",
            " |          )\n",
            " |          Sequential(\n",
            " |            (0): Linear(in_features=2, out_features=2, bias=True)\n",
            " |            (1): Linear(in_features=2, out_features=2, bias=True)\n",
            " |          )\n",
            " |  \n",
            " |  bfloat16(self: ~T) -> ~T\n",
            " |      Casts all floating point parameters and buffers to ``bfloat16`` datatype.\n",
            " |      \n",
            " |      .. note::\n",
            " |          This method modifies the module in-place.\n",
            " |      \n",
            " |      Returns:\n",
            " |          Module: self\n",
            " |  \n",
            " |  buffers(self, recurse: bool = True) -> Iterator[torch.Tensor]\n",
            " |      Returns an iterator over module buffers.\n",
            " |      \n",
            " |      Args:\n",
            " |          recurse (bool): if True, then yields buffers of this module\n",
            " |              and all submodules. Otherwise, yields only buffers that\n",
            " |              are direct members of this module.\n",
            " |      \n",
            " |      Yields:\n",
            " |          torch.Tensor: module buffer\n",
            " |      \n",
            " |      Example::\n",
            " |      \n",
            " |          >>> for buf in model.buffers():\n",
            " |          >>>     print(type(buf), buf.size())\n",
            " |          <class 'torch.Tensor'> (20L,)\n",
            " |          <class 'torch.Tensor'> (20L, 1L, 5L, 5L)\n",
            " |  \n",
            " |  children(self) -> Iterator[ForwardRef('Module')]\n",
            " |      Returns an iterator over immediate children modules.\n",
            " |      \n",
            " |      Yields:\n",
            " |          Module: a child module\n",
            " |  \n",
            " |  cpu(self: ~T) -> ~T\n",
            " |      Moves all model parameters and buffers to the CPU.\n",
            " |      \n",
            " |      .. note::\n",
            " |          This method modifies the module in-place.\n",
            " |      \n",
            " |      Returns:\n",
            " |          Module: self\n",
            " |  \n",
            " |  cuda(self: ~T, device: Union[int, torch.device, NoneType] = None) -> ~T\n",
            " |      Moves all model parameters and buffers to the GPU.\n",
            " |      \n",
            " |      This also makes associated parameters and buffers different objects. So\n",
            " |      it should be called before constructing optimizer if the module will\n",
            " |      live on GPU while being optimized.\n",
            " |      \n",
            " |      .. note::\n",
            " |          This method modifies the module in-place.\n",
            " |      \n",
            " |      Args:\n",
            " |          device (int, optional): if specified, all parameters will be\n",
            " |              copied to that device\n",
            " |      \n",
            " |      Returns:\n",
            " |          Module: self\n",
            " |  \n",
            " |  double(self: ~T) -> ~T\n",
            " |      Casts all floating point parameters and buffers to ``double`` datatype.\n",
            " |      \n",
            " |      .. note::\n",
            " |          This method modifies the module in-place.\n",
            " |      \n",
            " |      Returns:\n",
            " |          Module: self\n",
            " |  \n",
            " |  eval(self: ~T) -> ~T\n",
            " |      Sets the module in evaluation mode.\n",
            " |      \n",
            " |      This has any effect only on certain modules. See documentations of\n",
            " |      particular modules for details of their behaviors in training/evaluation\n",
            " |      mode, if they are affected, e.g. :class:`Dropout`, :class:`BatchNorm`,\n",
            " |      etc.\n",
            " |      \n",
            " |      This is equivalent with :meth:`self.train(False) <torch.nn.Module.train>`.\n",
            " |      \n",
            " |      See :ref:`locally-disable-grad-doc` for a comparison between\n",
            " |      `.eval()` and several similar mechanisms that may be confused with it.\n",
            " |      \n",
            " |      Returns:\n",
            " |          Module: self\n",
            " |  \n",
            " |  extra_repr(self) -> str\n",
            " |      Set the extra representation of the module\n",
            " |      \n",
            " |      To print customized extra information, you should re-implement\n",
            " |      this method in your own modules. Both single-line and multi-line\n",
            " |      strings are acceptable.\n",
            " |  \n",
            " |  float(self: ~T) -> ~T\n",
            " |      Casts all floating point parameters and buffers to ``float`` datatype.\n",
            " |      \n",
            " |      .. note::\n",
            " |          This method modifies the module in-place.\n",
            " |      \n",
            " |      Returns:\n",
            " |          Module: self\n",
            " |  \n",
            " |  forward = _forward_unimplemented(self, *input: Any) -> None\n",
            " |      Defines the computation performed at every call.\n",
            " |      \n",
            " |      Should be overridden by all subclasses.\n",
            " |      \n",
            " |      .. note::\n",
            " |          Although the recipe for forward pass needs to be defined within\n",
            " |          this function, one should call the :class:`Module` instance afterwards\n",
            " |          instead of this since the former takes care of running the\n",
            " |          registered hooks while the latter silently ignores them.\n",
            " |  \n",
            " |  get_buffer(self, target: str) -> 'Tensor'\n",
            " |      Returns the buffer given by ``target`` if it exists,\n",
            " |      otherwise throws an error.\n",
            " |      \n",
            " |      See the docstring for ``get_submodule`` for a more detailed\n",
            " |      explanation of this method's functionality as well as how to\n",
            " |      correctly specify ``target``.\n",
            " |      \n",
            " |      Args:\n",
            " |          target: The fully-qualified string name of the buffer\n",
            " |              to look for. (See ``get_submodule`` for how to specify a\n",
            " |              fully-qualified string.)\n",
            " |      \n",
            " |      Returns:\n",
            " |          torch.Tensor: The buffer referenced by ``target``\n",
            " |      \n",
            " |      Raises:\n",
            " |          AttributeError: If the target string references an invalid\n",
            " |              path or resolves to something that is not a\n",
            " |              buffer\n",
            " |  \n",
            " |  get_parameter(self, target: str) -> 'Parameter'\n",
            " |      Returns the parameter given by ``target`` if it exists,\n",
            " |      otherwise throws an error.\n",
            " |      \n",
            " |      See the docstring for ``get_submodule`` for a more detailed\n",
            " |      explanation of this method's functionality as well as how to\n",
            " |      correctly specify ``target``.\n",
            " |      \n",
            " |      Args:\n",
            " |          target: The fully-qualified string name of the Parameter\n",
            " |              to look for. (See ``get_submodule`` for how to specify a\n",
            " |              fully-qualified string.)\n",
            " |      \n",
            " |      Returns:\n",
            " |          torch.nn.Parameter: The Parameter referenced by ``target``\n",
            " |      \n",
            " |      Raises:\n",
            " |          AttributeError: If the target string references an invalid\n",
            " |              path or resolves to something that is not an\n",
            " |              ``nn.Parameter``\n",
            " |  \n",
            " |  get_submodule(self, target: str) -> 'Module'\n",
            " |      Returns the submodule given by ``target`` if it exists,\n",
            " |      otherwise throws an error.\n",
            " |      \n",
            " |      For example, let's say you have an ``nn.Module`` ``A`` that\n",
            " |      looks like this:\n",
            " |      \n",
            " |      .. code-block::text\n",
            " |      \n",
            " |          A(\n",
            " |              (net_b): Module(\n",
            " |                  (net_c): Module(\n",
            " |                      (conv): Conv2d(16, 33, kernel_size=(3, 3), stride=(2, 2))\n",
            " |                  )\n",
            " |                  (linear): Linear(in_features=100, out_features=200, bias=True)\n",
            " |              )\n",
            " |          )\n",
            " |      \n",
            " |      (The diagram shows an ``nn.Module`` ``A``. ``A`` has a nested\n",
            " |      submodule ``net_b``, which itself has two submodules ``net_c``\n",
            " |      and ``linear``. ``net_c`` then has a submodule ``conv``.)\n",
            " |      \n",
            " |      To check whether or not we have the ``linear`` submodule, we\n",
            " |      would call ``get_submodule(\"net_b.linear\")``. To check whether\n",
            " |      we have the ``conv`` submodule, we would call\n",
            " |      ``get_submodule(\"net_b.net_c.conv\")``.\n",
            " |      \n",
            " |      The runtime of ``get_submodule`` is bounded by the degree\n",
            " |      of module nesting in ``target``. A query against\n",
            " |      ``named_modules`` achieves the same result, but it is O(N) in\n",
            " |      the number of transitive modules. So, for a simple check to see\n",
            " |      if some submodule exists, ``get_submodule`` should always be\n",
            " |      used.\n",
            " |      \n",
            " |      Args:\n",
            " |          target: The fully-qualified string name of the submodule\n",
            " |              to look for. (See above example for how to specify a\n",
            " |              fully-qualified string.)\n",
            " |      \n",
            " |      Returns:\n",
            " |          torch.nn.Module: The submodule referenced by ``target``\n",
            " |      \n",
            " |      Raises:\n",
            " |          AttributeError: If the target string references an invalid\n",
            " |              path or resolves to something that is not an\n",
            " |              ``nn.Module``\n",
            " |  \n",
            " |  half(self: ~T) -> ~T\n",
            " |      Casts all floating point parameters and buffers to ``half`` datatype.\n",
            " |      \n",
            " |      .. note::\n",
            " |          This method modifies the module in-place.\n",
            " |      \n",
            " |      Returns:\n",
            " |          Module: self\n",
            " |  \n",
            " |  load_state_dict(self, state_dict: 'OrderedDict[str, Tensor]', strict: bool = True)\n",
            " |      Copies parameters and buffers from :attr:`state_dict` into\n",
            " |      this module and its descendants. If :attr:`strict` is ``True``, then\n",
            " |      the keys of :attr:`state_dict` must exactly match the keys returned\n",
            " |      by this module's :meth:`~torch.nn.Module.state_dict` function.\n",
            " |      \n",
            " |      Args:\n",
            " |          state_dict (dict): a dict containing parameters and\n",
            " |              persistent buffers.\n",
            " |          strict (bool, optional): whether to strictly enforce that the keys\n",
            " |              in :attr:`state_dict` match the keys returned by this module's\n",
            " |              :meth:`~torch.nn.Module.state_dict` function. Default: ``True``\n",
            " |      \n",
            " |      Returns:\n",
            " |          ``NamedTuple`` with ``missing_keys`` and ``unexpected_keys`` fields:\n",
            " |              * **missing_keys** is a list of str containing the missing keys\n",
            " |              * **unexpected_keys** is a list of str containing the unexpected keys\n",
            " |  \n",
            " |  modules(self) -> Iterator[ForwardRef('Module')]\n",
            " |      Returns an iterator over all modules in the network.\n",
            " |      \n",
            " |      Yields:\n",
            " |          Module: a module in the network\n",
            " |      \n",
            " |      Note:\n",
            " |          Duplicate modules are returned only once. In the following\n",
            " |          example, ``l`` will be returned only once.\n",
            " |      \n",
            " |      Example::\n",
            " |      \n",
            " |          >>> l = nn.Linear(2, 2)\n",
            " |          >>> net = nn.Sequential(l, l)\n",
            " |          >>> for idx, m in enumerate(net.modules()):\n",
            " |                  print(idx, '->', m)\n",
            " |      \n",
            " |          0 -> Sequential(\n",
            " |            (0): Linear(in_features=2, out_features=2, bias=True)\n",
            " |            (1): Linear(in_features=2, out_features=2, bias=True)\n",
            " |          )\n",
            " |          1 -> Linear(in_features=2, out_features=2, bias=True)\n",
            " |  \n",
            " |  named_buffers(self, prefix: str = '', recurse: bool = True) -> Iterator[Tuple[str, torch.Tensor]]\n",
            " |      Returns an iterator over module buffers, yielding both the\n",
            " |      name of the buffer as well as the buffer itself.\n",
            " |      \n",
            " |      Args:\n",
            " |          prefix (str): prefix to prepend to all buffer names.\n",
            " |          recurse (bool): if True, then yields buffers of this module\n",
            " |              and all submodules. Otherwise, yields only buffers that\n",
            " |              are direct members of this module.\n",
            " |      \n",
            " |      Yields:\n",
            " |          (string, torch.Tensor): Tuple containing the name and buffer\n",
            " |      \n",
            " |      Example::\n",
            " |      \n",
            " |          >>> for name, buf in self.named_buffers():\n",
            " |          >>>    if name in ['running_var']:\n",
            " |          >>>        print(buf.size())\n",
            " |  \n",
            " |  named_children(self) -> Iterator[Tuple[str, ForwardRef('Module')]]\n",
            " |      Returns an iterator over immediate children modules, yielding both\n",
            " |      the name of the module as well as the module itself.\n",
            " |      \n",
            " |      Yields:\n",
            " |          (string, Module): Tuple containing a name and child module\n",
            " |      \n",
            " |      Example::\n",
            " |      \n",
            " |          >>> for name, module in model.named_children():\n",
            " |          >>>     if name in ['conv4', 'conv5']:\n",
            " |          >>>         print(module)\n",
            " |  \n",
            " |  named_modules(self, memo: Union[Set[ForwardRef('Module')], NoneType] = None, prefix: str = '', remove_duplicate: bool = True)\n",
            " |      Returns an iterator over all modules in the network, yielding\n",
            " |      both the name of the module as well as the module itself.\n",
            " |      \n",
            " |      Args:\n",
            " |          memo: a memo to store the set of modules already added to the result\n",
            " |          prefix: a prefix that will be added to the name of the module\n",
            " |          remove_duplicate: whether to remove the duplicated module instances in the result\n",
            " |          or not\n",
            " |      \n",
            " |      Yields:\n",
            " |          (string, Module): Tuple of name and module\n",
            " |      \n",
            " |      Note:\n",
            " |          Duplicate modules are returned only once. In the following\n",
            " |          example, ``l`` will be returned only once.\n",
            " |      \n",
            " |      Example::\n",
            " |      \n",
            " |          >>> l = nn.Linear(2, 2)\n",
            " |          >>> net = nn.Sequential(l, l)\n",
            " |          >>> for idx, m in enumerate(net.named_modules()):\n",
            " |                  print(idx, '->', m)\n",
            " |      \n",
            " |          0 -> ('', Sequential(\n",
            " |            (0): Linear(in_features=2, out_features=2, bias=True)\n",
            " |            (1): Linear(in_features=2, out_features=2, bias=True)\n",
            " |          ))\n",
            " |          1 -> ('0', Linear(in_features=2, out_features=2, bias=True))\n",
            " |  \n",
            " |  named_parameters(self, prefix: str = '', recurse: bool = True) -> Iterator[Tuple[str, torch.nn.parameter.Parameter]]\n",
            " |      Returns an iterator over module parameters, yielding both the\n",
            " |      name of the parameter as well as the parameter itself.\n",
            " |      \n",
            " |      Args:\n",
            " |          prefix (str): prefix to prepend to all parameter names.\n",
            " |          recurse (bool): if True, then yields parameters of this module\n",
            " |              and all submodules. Otherwise, yields only parameters that\n",
            " |              are direct members of this module.\n",
            " |      \n",
            " |      Yields:\n",
            " |          (string, Parameter): Tuple containing the name and parameter\n",
            " |      \n",
            " |      Example::\n",
            " |      \n",
            " |          >>> for name, param in self.named_parameters():\n",
            " |          >>>    if name in ['bias']:\n",
            " |          >>>        print(param.size())\n",
            " |  \n",
            " |  parameters(self, recurse: bool = True) -> Iterator[torch.nn.parameter.Parameter]\n",
            " |      Returns an iterator over module parameters.\n",
            " |      \n",
            " |      This is typically passed to an optimizer.\n",
            " |      \n",
            " |      Args:\n",
            " |          recurse (bool): if True, then yields parameters of this module\n",
            " |              and all submodules. Otherwise, yields only parameters that\n",
            " |              are direct members of this module.\n",
            " |      \n",
            " |      Yields:\n",
            " |          Parameter: module parameter\n",
            " |      \n",
            " |      Example::\n",
            " |      \n",
            " |          >>> for param in model.parameters():\n",
            " |          >>>     print(type(param), param.size())\n",
            " |          <class 'torch.Tensor'> (20L,)\n",
            " |          <class 'torch.Tensor'> (20L, 1L, 5L, 5L)\n",
            " |  \n",
            " |  register_backward_hook(self, hook: Callable[[ForwardRef('Module'), Union[Tuple[torch.Tensor, ...], torch.Tensor], Union[Tuple[torch.Tensor, ...], torch.Tensor]], Union[NoneType, torch.Tensor]]) -> torch.utils.hooks.RemovableHandle\n",
            " |      Registers a backward hook on the module.\n",
            " |      \n",
            " |      This function is deprecated in favor of :meth:`nn.Module.register_full_backward_hook` and\n",
            " |      the behavior of this function will change in future versions.\n",
            " |      \n",
            " |      Returns:\n",
            " |          :class:`torch.utils.hooks.RemovableHandle`:\n",
            " |              a handle that can be used to remove the added hook by calling\n",
            " |              ``handle.remove()``\n",
            " |  \n",
            " |  register_buffer(self, name: str, tensor: Union[torch.Tensor, NoneType], persistent: bool = True) -> None\n",
            " |      Adds a buffer to the module.\n",
            " |      \n",
            " |      This is typically used to register a buffer that should not to be\n",
            " |      considered a model parameter. For example, BatchNorm's ``running_mean``\n",
            " |      is not a parameter, but is part of the module's state. Buffers, by\n",
            " |      default, are persistent and will be saved alongside parameters. This\n",
            " |      behavior can be changed by setting :attr:`persistent` to ``False``. The\n",
            " |      only difference between a persistent buffer and a non-persistent buffer\n",
            " |      is that the latter will not be a part of this module's\n",
            " |      :attr:`state_dict`.\n",
            " |      \n",
            " |      Buffers can be accessed as attributes using given names.\n",
            " |      \n",
            " |      Args:\n",
            " |          name (string): name of the buffer. The buffer can be accessed\n",
            " |              from this module using the given name\n",
            " |          tensor (Tensor): buffer to be registered.\n",
            " |          persistent (bool): whether the buffer is part of this module's\n",
            " |              :attr:`state_dict`.\n",
            " |      \n",
            " |      Example::\n",
            " |      \n",
            " |          >>> self.register_buffer('running_mean', torch.zeros(num_features))\n",
            " |  \n",
            " |  register_forward_hook(self, hook: Callable[..., NoneType]) -> torch.utils.hooks.RemovableHandle\n",
            " |      Registers a forward hook on the module.\n",
            " |      \n",
            " |      The hook will be called every time after :func:`forward` has computed an output.\n",
            " |      It should have the following signature::\n",
            " |      \n",
            " |          hook(module, input, output) -> None or modified output\n",
            " |      \n",
            " |      The input contains only the positional arguments given to the module.\n",
            " |      Keyword arguments won't be passed to the hooks and only to the ``forward``.\n",
            " |      The hook can modify the output. It can modify the input inplace but\n",
            " |      it will not have effect on forward since this is called after\n",
            " |      :func:`forward` is called.\n",
            " |      \n",
            " |      Returns:\n",
            " |          :class:`torch.utils.hooks.RemovableHandle`:\n",
            " |              a handle that can be used to remove the added hook by calling\n",
            " |              ``handle.remove()``\n",
            " |  \n",
            " |  register_forward_pre_hook(self, hook: Callable[..., NoneType]) -> torch.utils.hooks.RemovableHandle\n",
            " |      Registers a forward pre-hook on the module.\n",
            " |      \n",
            " |      The hook will be called every time before :func:`forward` is invoked.\n",
            " |      It should have the following signature::\n",
            " |      \n",
            " |          hook(module, input) -> None or modified input\n",
            " |      \n",
            " |      The input contains only the positional arguments given to the module.\n",
            " |      Keyword arguments won't be passed to the hooks and only to the ``forward``.\n",
            " |      The hook can modify the input. User can either return a tuple or a\n",
            " |      single modified value in the hook. We will wrap the value into a tuple\n",
            " |      if a single value is returned(unless that value is already a tuple).\n",
            " |      \n",
            " |      Returns:\n",
            " |          :class:`torch.utils.hooks.RemovableHandle`:\n",
            " |              a handle that can be used to remove the added hook by calling\n",
            " |              ``handle.remove()``\n",
            " |  \n",
            " |  register_full_backward_hook(self, hook: Callable[[ForwardRef('Module'), Union[Tuple[torch.Tensor, ...], torch.Tensor], Union[Tuple[torch.Tensor, ...], torch.Tensor]], Union[NoneType, torch.Tensor]]) -> torch.utils.hooks.RemovableHandle\n",
            " |      Registers a backward hook on the module.\n",
            " |      \n",
            " |      The hook will be called every time the gradients with respect to module\n",
            " |      inputs are computed. The hook should have the following signature::\n",
            " |      \n",
            " |          hook(module, grad_input, grad_output) -> tuple(Tensor) or None\n",
            " |      \n",
            " |      The :attr:`grad_input` and :attr:`grad_output` are tuples that contain the gradients\n",
            " |      with respect to the inputs and outputs respectively. The hook should\n",
            " |      not modify its arguments, but it can optionally return a new gradient with\n",
            " |      respect to the input that will be used in place of :attr:`grad_input` in\n",
            " |      subsequent computations. :attr:`grad_input` will only correspond to the inputs given\n",
            " |      as positional arguments and all kwarg arguments are ignored. Entries\n",
            " |      in :attr:`grad_input` and :attr:`grad_output` will be ``None`` for all non-Tensor\n",
            " |      arguments.\n",
            " |      \n",
            " |      .. warning ::\n",
            " |          Modifying inputs or outputs inplace is not allowed when using backward hooks and\n",
            " |          will raise an error.\n",
            " |      \n",
            " |      Returns:\n",
            " |          :class:`torch.utils.hooks.RemovableHandle`:\n",
            " |              a handle that can be used to remove the added hook by calling\n",
            " |              ``handle.remove()``\n",
            " |  \n",
            " |  register_parameter(self, name: str, param: Union[torch.nn.parameter.Parameter, NoneType]) -> None\n",
            " |      Adds a parameter to the module.\n",
            " |      \n",
            " |      The parameter can be accessed as an attribute using given name.\n",
            " |      \n",
            " |      Args:\n",
            " |          name (string): name of the parameter. The parameter can be accessed\n",
            " |              from this module using the given name\n",
            " |          param (Parameter): parameter to be added to the module.\n",
            " |  \n",
            " |  requires_grad_(self: ~T, requires_grad: bool = True) -> ~T\n",
            " |      Change if autograd should record operations on parameters in this\n",
            " |      module.\n",
            " |      \n",
            " |      This method sets the parameters' :attr:`requires_grad` attributes\n",
            " |      in-place.\n",
            " |      \n",
            " |      This method is helpful for freezing part of the module for finetuning\n",
            " |      or training parts of a model individually (e.g., GAN training).\n",
            " |      \n",
            " |      See :ref:`locally-disable-grad-doc` for a comparison between\n",
            " |      `.requires_grad_()` and several similar mechanisms that may be confused with it.\n",
            " |      \n",
            " |      Args:\n",
            " |          requires_grad (bool): whether autograd should record operations on\n",
            " |                                parameters in this module. Default: ``True``.\n",
            " |      \n",
            " |      Returns:\n",
            " |          Module: self\n",
            " |  \n",
            " |  share_memory(self: ~T) -> ~T\n",
            " |      See :meth:`torch.Tensor.share_memory_`\n",
            " |  \n",
            " |  state_dict(self, destination=None, prefix='', keep_vars=False)\n",
            " |      Returns a dictionary containing a whole state of the module.\n",
            " |      \n",
            " |      Both parameters and persistent buffers (e.g. running averages) are\n",
            " |      included. Keys are corresponding parameter and buffer names.\n",
            " |      \n",
            " |      Returns:\n",
            " |          dict:\n",
            " |              a dictionary containing a whole state of the module\n",
            " |      \n",
            " |      Example::\n",
            " |      \n",
            " |          >>> module.state_dict().keys()\n",
            " |          ['bias', 'weight']\n",
            " |  \n",
            " |  to(self, *args, **kwargs)\n",
            " |      Moves and/or casts the parameters and buffers.\n",
            " |      \n",
            " |      This can be called as\n",
            " |      \n",
            " |      .. function:: to(device=None, dtype=None, non_blocking=False)\n",
            " |      \n",
            " |      .. function:: to(dtype, non_blocking=False)\n",
            " |      \n",
            " |      .. function:: to(tensor, non_blocking=False)\n",
            " |      \n",
            " |      .. function:: to(memory_format=torch.channels_last)\n",
            " |      \n",
            " |      Its signature is similar to :meth:`torch.Tensor.to`, but only accepts\n",
            " |      floating point or complex :attr:`dtype`s. In addition, this method will\n",
            " |      only cast the floating point or complex parameters and buffers to :attr:`dtype`\n",
            " |      (if given). The integral parameters and buffers will be moved\n",
            " |      :attr:`device`, if that is given, but with dtypes unchanged. When\n",
            " |      :attr:`non_blocking` is set, it tries to convert/move asynchronously\n",
            " |      with respect to the host if possible, e.g., moving CPU Tensors with\n",
            " |      pinned memory to CUDA devices.\n",
            " |      \n",
            " |      See below for examples.\n",
            " |      \n",
            " |      .. note::\n",
            " |          This method modifies the module in-place.\n",
            " |      \n",
            " |      Args:\n",
            " |          device (:class:`torch.device`): the desired device of the parameters\n",
            " |              and buffers in this module\n",
            " |          dtype (:class:`torch.dtype`): the desired floating point or complex dtype of\n",
            " |              the parameters and buffers in this module\n",
            " |          tensor (torch.Tensor): Tensor whose dtype and device are the desired\n",
            " |              dtype and device for all parameters and buffers in this module\n",
            " |          memory_format (:class:`torch.memory_format`): the desired memory\n",
            " |              format for 4D parameters and buffers in this module (keyword\n",
            " |              only argument)\n",
            " |      \n",
            " |      Returns:\n",
            " |          Module: self\n",
            " |      \n",
            " |      Examples::\n",
            " |      \n",
            " |          >>> linear = nn.Linear(2, 2)\n",
            " |          >>> linear.weight\n",
            " |          Parameter containing:\n",
            " |          tensor([[ 0.1913, -0.3420],\n",
            " |                  [-0.5113, -0.2325]])\n",
            " |          >>> linear.to(torch.double)\n",
            " |          Linear(in_features=2, out_features=2, bias=True)\n",
            " |          >>> linear.weight\n",
            " |          Parameter containing:\n",
            " |          tensor([[ 0.1913, -0.3420],\n",
            " |                  [-0.5113, -0.2325]], dtype=torch.float64)\n",
            " |          >>> gpu1 = torch.device(\"cuda:1\")\n",
            " |          >>> linear.to(gpu1, dtype=torch.half, non_blocking=True)\n",
            " |          Linear(in_features=2, out_features=2, bias=True)\n",
            " |          >>> linear.weight\n",
            " |          Parameter containing:\n",
            " |          tensor([[ 0.1914, -0.3420],\n",
            " |                  [-0.5112, -0.2324]], dtype=torch.float16, device='cuda:1')\n",
            " |          >>> cpu = torch.device(\"cpu\")\n",
            " |          >>> linear.to(cpu)\n",
            " |          Linear(in_features=2, out_features=2, bias=True)\n",
            " |          >>> linear.weight\n",
            " |          Parameter containing:\n",
            " |          tensor([[ 0.1914, -0.3420],\n",
            " |                  [-0.5112, -0.2324]], dtype=torch.float16)\n",
            " |      \n",
            " |          >>> linear = nn.Linear(2, 2, bias=None).to(torch.cdouble)\n",
            " |          >>> linear.weight\n",
            " |          Parameter containing:\n",
            " |          tensor([[ 0.3741+0.j,  0.2382+0.j],\n",
            " |                  [ 0.5593+0.j, -0.4443+0.j]], dtype=torch.complex128)\n",
            " |          >>> linear(torch.ones(3, 2, dtype=torch.cdouble))\n",
            " |          tensor([[0.6122+0.j, 0.1150+0.j],\n",
            " |                  [0.6122+0.j, 0.1150+0.j],\n",
            " |                  [0.6122+0.j, 0.1150+0.j]], dtype=torch.complex128)\n",
            " |  \n",
            " |  to_empty(self: ~T, *, device: Union[str, torch.device]) -> ~T\n",
            " |      Moves the parameters and buffers to the specified device without copying storage.\n",
            " |      \n",
            " |      Args:\n",
            " |          device (:class:`torch.device`): The desired device of the parameters\n",
            " |              and buffers in this module.\n",
            " |      \n",
            " |      Returns:\n",
            " |          Module: self\n",
            " |  \n",
            " |  train(self: ~T, mode: bool = True) -> ~T\n",
            " |      Sets the module in training mode.\n",
            " |      \n",
            " |      This has any effect only on certain modules. See documentations of\n",
            " |      particular modules for details of their behaviors in training/evaluation\n",
            " |      mode, if they are affected, e.g. :class:`Dropout`, :class:`BatchNorm`,\n",
            " |      etc.\n",
            " |      \n",
            " |      Args:\n",
            " |          mode (bool): whether to set training mode (``True``) or evaluation\n",
            " |                       mode (``False``). Default: ``True``.\n",
            " |      \n",
            " |      Returns:\n",
            " |          Module: self\n",
            " |  \n",
            " |  type(self: ~T, dst_type: Union[torch.dtype, str]) -> ~T\n",
            " |      Casts all parameters and buffers to :attr:`dst_type`.\n",
            " |      \n",
            " |      .. note::\n",
            " |          This method modifies the module in-place.\n",
            " |      \n",
            " |      Args:\n",
            " |          dst_type (type or string): the desired type\n",
            " |      \n",
            " |      Returns:\n",
            " |          Module: self\n",
            " |  \n",
            " |  xpu(self: ~T, device: Union[int, torch.device, NoneType] = None) -> ~T\n",
            " |      Moves all model parameters and buffers to the XPU.\n",
            " |      \n",
            " |      This also makes associated parameters and buffers different objects. So\n",
            " |      it should be called before constructing optimizer if the module will\n",
            " |      live on XPU while being optimized.\n",
            " |      \n",
            " |      .. note::\n",
            " |          This method modifies the module in-place.\n",
            " |      \n",
            " |      Arguments:\n",
            " |          device (int, optional): if specified, all parameters will be\n",
            " |              copied to that device\n",
            " |      \n",
            " |      Returns:\n",
            " |          Module: self\n",
            " |  \n",
            " |  zero_grad(self, set_to_none: bool = False) -> None\n",
            " |      Sets gradients of all model parameters to zero. See similar function\n",
            " |      under :class:`torch.optim.Optimizer` for more context.\n",
            " |      \n",
            " |      Args:\n",
            " |          set_to_none (bool): instead of setting to zero, set the grads to None.\n",
            " |              See :meth:`torch.optim.Optimizer.zero_grad` for details.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data descriptors inherited from torch.nn.modules.module.Module:\n",
            " |  \n",
            " |  __dict__\n",
            " |      dictionary for instance variables (if defined)\n",
            " |  \n",
            " |  __weakref__\n",
            " |      list of weak references to the object (if defined)\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data and other attributes inherited from torch.nn.modules.module.Module:\n",
            " |  \n",
            " |  T_destination = ~T_destination\n",
            " |  \n",
            " |  __annotations__ = {'__call__': typing.Callable[..., typing.Any], '_is_...\n",
            " |  \n",
            " |  dump_patches = False\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tka7VMeekxd7"
      },
      "source": [
        "#### ğŸ‘¨â€ğŸ’» <font color='green'><b>[ ì½”ë”© ]</b></font> BatchNorm1d ë¶„ì„í•´ë³´ê¸°\n",
        "\n",
        "``` python\n",
        "ğŸ¦†\n",
        "ì € ì´ì œ ìì‹ ê°ì´ ìƒê¸´ ê²ƒ ê°™ì•„ìš”!\n",
        "\n",
        "PyTorchê°€ ë¯¸ë¦¬ ë§Œë“¤ì–´ë‘” moduleì¤‘ í•˜ë‚˜ë¥¼ ë¶„ì„í•´ì„œ\n",
        "ì œê°€ ì–´ëŠì •ë„ ì„±ì¥í–ˆëŠ”ì§€ ì•Œì•„ë³´ê³  ì‹¶ì–´ìš”!\n",
        "\n",
        "ìŒ.. ë­ê°€ ì¢‹ì§€? BatchNorm1dìœ¼ë¡œ í•´ë´ìš”!\n",
        "```\n",
        "\n",
        "- [Documentation main - PyTorch ê³µì‹ ë¬¸ì„œ](https://pytorch.org/docs/stable/index.html)\n",
        "- [torch.nn.BatchNorm1d - PyTorch ê³µì‹ ë¬¸ì„œ](https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm1d.html#torch.nn.BatchNorm1d)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WUshguoBlTNm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "125075c6-dd75-4e5c-e21f-21581d71dfcc"
      },
      "source": [
        "import torch\n",
        "import torch.nn\n",
        "\n",
        "module = nn.BatchNorm1d(10)\n",
        "\n",
        "# for parameter in module.buffers():\n",
        "#     print(parameter)\n",
        "\n",
        "# TODO : nn.BatchNorm1dì˜ parameterì™€ buffer ê°¯ìˆ˜ë¥¼ ì•Œì•„ë‚´ì„¸ìš”!\n",
        "parameter_n = 2\n",
        "buffer_n = 3\n",
        "\n",
        "# TODO : nn.BatchNorm1dì˜ buffer ì´ë¦„ì„ ì•Œì•„ë‚´ì„¸ìš”!\n",
        "#        [ì´ë¦„, ì´ë¦„, ì´ë¦„] í˜•íƒœë¡œ ì €ì¥í•´ì£¼ì„¸ìš”!\n",
        "\n",
        "buffer_list =[]\n",
        "for name, buffer in module.named_buffers():\n",
        "    buffer_list.append(name)\n",
        "\n",
        "buffer_names = buffer_list\n",
        "print(buffer_list)\n",
        "\n",
        "\n",
        "# ì•„ë˜ ì½”ë“œëŠ” ìˆ˜ì •í•˜ì‹¤ í•„ìš”ê°€ ì—†ìŠµë‹ˆë‹¤!\n",
        "answer = set(['running_mean', 'running_var', 'num_batches_tracked'])\n",
        "\n",
        "if parameter_n == 2 and buffer_n == 3 and answer == set(buffer_names):\n",
        "    print(\"ğŸ‰ğŸ‰ğŸ‰ ì„±ê³µ!!! ğŸ‰ğŸ‰ğŸ‰\")\n",
        "else:\n",
        "    print(\"ğŸ¦† ë‹¤ì‹œ ë„ì „í•´ë´ìš”!\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['running_mean', 'running_var', 'num_batches_tracked']\n",
            "ğŸ‰ğŸ‰ğŸ‰ ì„±ê³µ!!! ğŸ‰ğŸ‰ğŸ‰\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lFLQWT3w0m4v"
      },
      "source": [
        "``` python\n",
        "ğŸ¦†\n",
        "Docstringì„ ë³´ëŠ” ê²ƒë³´ë‹¤ PyTorch ê³µì‹ ë¬¸ì„œë¥¼ ë³´ëŠ”ê²Œ í›¨ì”¬ í¸í•´ì„œ\n",
        "BatchNorm1dëŠ” ë³„ë„ë¡œ Docstringì„ ë³´ì§€ ì•Šì•˜ì–´ìš”!\n",
        "\n",
        "í•˜ì§€ë§Œ Documentationì´ ì—†ëŠ” ëª¨ë¸ì„ ì‚¬ìš©ì¤‘ì´ë¼ë©´\n",
        "Docstringì„ Documentationì²˜ëŸ¼ ì—¬ê¸°ê³  ê¼¼ê¼¼íˆ ë³´ì•„ì•¼ í•´ìš”!\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2clV-zzGiH-v"
      },
      "source": [
        "### â˜„ï¸ nn.Module ì•Œì“¸ì‹ ì¡\n",
        "> ìœ„ì—ì„œ ë‹¤ë£¨ì§€ ì•Šì•˜ì§€ë§Œ nn.Moduleì´ ì œê³µí•˜ëŠ” ê¸°ëŠ¥ ì¤‘ì—ì„œ ì•Œì•„ë‘ë©´ ìœ ìš©í•œ ê¸°ëŠ¥ì— ëŒ€í•´ ì‚´í´ë³¼ ê²ƒì…ë‹ˆë‹¤!\n",
        "\n",
        "- ğŸ‘¨â€ğŸ’» <font color='green'><b>[ ì½”ë”© ]</b></font> hook\n",
        "- ğŸ‘¨â€ğŸ’» <font color='green'><b>[ ì½”ë”© ]</b></font> apply\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7tJVT5Mp9I4S"
      },
      "source": [
        "#### ğŸ‘¨â€ğŸ’» <font color='green'><b>[ ì½”ë”© ]</b></font> hook\n",
        "\n",
        "``` python\n",
        "ğŸ¦†\n",
        "hookë¼ëŠ” ìƒì†Œí•œ ìš©ì–´ë¥¼ ì²˜ìŒ ë“¤ì–´ë³´ì•˜ì–´ìš”!\n",
        "ì´ê²Œ ë¬´ì—‡ì¼ê¹Œìš”? ì™ ì§€ ëª¨ë¥´ê²Œ ê²ì´ ë‚˜ë„¤ìš”!\n",
        "\n",
        "ì¸í„°ë„·ìœ¼ë¡œ ì°¾ì•„ë³´ë‹ˆê¹Œ íŒ¨í‚¤ì§€í™”ëœ ì½”ë“œì—ì„œ ë‹¤ë¥¸ í”„ë¡œê·¸ë˜ë¨¸ê°€\n",
        "custom ì½”ë“œë¥¼ ì¤‘ê°„ì— ì‹¤í–‰ì‹œí‚¬ ìˆ˜ ìˆë„ë¡ ë§Œë“¤ì–´ë†“ì€ ì¸í„°í˜ì´ìŠ¤ë¼ê³  í•˜ë„¤ìš”!\n",
        "\n",
        "- í”„ë¡œê·¸ë¨ì˜ ì‹¤í–‰ ë¡œì§ì„ ë¶„ì„í•˜ê±°ë‚˜\n",
        "- í”„ë¡œê·¸ë¨ì— ì¶”ê°€ì ì¸ ê¸°ëŠ¥ì„ ì œê³µí•˜ê³  ì‹¶ì„ ë•Œ\n",
        "\n",
        "hookì´ ì‚¬ìš©ëœë‹¤ê³  í•´ìš”!\n",
        "\n",
        "ì•Œë“¯ë§ë“¯ í•˜ë„¤ìš”! ì¹œêµ¬ê°€ ë„ì›€ì„ ì¤€ë‹¤ê³  í•˜ë‹ˆ ê°™ì´ ë°°ì›Œë´ìš”! \n",
        "```\n",
        "\n",
        "- [Documentation main - PyTorch ê³µì‹ ë¬¸ì„œ](https://pytorch.org/docs/stable/index.html)\n",
        "- [hook - WhatIs](https://whatis.techtarget.com/definition/hook)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5HujUYII-wih"
      },
      "source": [
        "##### ğŸ’¡ hookì˜ ì›ë¦¬\n",
        "> ğŸ¦† ë¶€ë•ì´ ì¹œêµ¬ê°€ ì½”ë“œë¥¼ ì‘ì„±í•´ì£¼ì—ˆì–´ìš”\n",
        "\n",
        "``` python\n",
        "ğŸ¦†\n",
        "hookì´ ë¬´ì—‡ì¸ì§€ ì •ë§ ëª¨ë¥´ê² ë‹¤ê³  í•˜ë‹ˆê¹Œ ì¹œêµ¬ê°€ ì½”ë“œë¥¼ ì‘ì„±í•´ì£¼ì—ˆì–´ìš”!\n",
        "ì´ ì½”ë“œë¥¼ ë³´ê³ ë‚˜ë©´ í•œê²° ì´í•´ê°€ ìˆ˜ì›”í•´ì§ˆ ê±°ë¼ê³  í•˜ë”ë¼êµ¬ìš”!\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nok5e_w1PjwS",
        "outputId": "f8c6af1f-3b81-4923-94c0-04cd157c0a47"
      },
      "source": [
        "def program_A(x):\n",
        "    print('program A processing!')\n",
        "    return x + 3\n",
        "\n",
        "def program_B(x):\n",
        "    print('program B processing!')\n",
        "    return x - 3\n",
        "\n",
        "def hook(x):\n",
        "    print(\"hook ì‘ë™\")\n",
        "    return x + 1\n",
        "class Package(object):\n",
        "    \"\"\"í”„ë¡œê·¸ë¨ Aì™€ Bë¥¼ ë¬¶ì–´ë†“ì€ íŒ¨í‚¤ì§€ ì½”ë“œ\"\"\"\n",
        "    def __init__(self):\n",
        "        self.programs = [program_A, program_B]\n",
        "        self.hooks = []\n",
        "\n",
        "    def __call__(self, x):\n",
        "        for program in self.programs:\n",
        "            x = program(x)\n",
        "\n",
        "            # Packageë¥¼ ì‚¬ìš©í•˜ëŠ” ì‚¬ëŒì´ ìì‹ ë§Œì˜ custom programì„\n",
        "            # ë“±ë¡í•  ìˆ˜ ìˆë„ë¡ ë¯¸ë¦¬ ë§Œë“¤ì–´ë†“ì€ ì¸í„°í˜ì´ìŠ¤ hook\n",
        "            if self.hooks:\n",
        "                for hook in self.hooks:\n",
        "                    output = hook(x)\n",
        "\n",
        "                    # return ê°’ì´ ìˆëŠ” hookì˜ ê²½ìš°ì—ë§Œ xë¥¼ ì—…ë°ì´íŠ¸ í•œë‹¤\n",
        "                    if output:\n",
        "                        x = output\n",
        "\n",
        "        return x\n",
        "\n",
        "# íŒ¨í‚¤ì§€ ìƒì„±\n",
        "package = Package()\n",
        "package.hooks.append(hook)\n",
        "\n",
        "# íŒ¨í‚¤ì§€ ì‹¤í–‰\n",
        "input = 3\n",
        "output = package(input)\n",
        "\n",
        "# íŒ¨í‚¤ì§€ ê²°ê³¼\n",
        "print(f\"Package Process Result! [ input {input} ] [ output {output} ]\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "program A processing!\n",
            "hook ì‘ë™\n",
            "program B processing!\n",
            "hook ì‘ë™\n",
            "Package Process Result! [ input 3 ] [ output 5 ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0KIn1D59SxDf"
      },
      "source": [
        "``` python\n",
        "ğŸ¦†\n",
        "ì½”ë“œë¥¼ ë³´ê³ ë‚˜ì„œ ì¡°ê¸ˆ ê°ì´ ì˜¤ê¸° ì‹œì‘í•œ ê²ƒ ê°™ì•„ìš”!\n",
        "\n",
        "Packageì€ ì›ë˜ë¶€í„° self.hooks ë¼ëŠ” ë³€ìˆ˜ë¥¼ ê°€ì§€ê³  ìˆì—ˆì–´ìš”!\n",
        "ê·¸ë˜ì„œ Packageë¥¼ ì‹¤í–‰í•˜ë©´ íŒ¨í‚¤ì§€ì— í¬í•¨ëœ í”„ë¡œê·¸ë¨ì„ í•˜ë‚˜ì”© \n",
        "ì‹¤í–‰í•˜ëŠ” ì¤‘ê°„ ì¤‘ê°„ self.hooks ì— ë“±ë¡ëœ í•¨ìˆ˜ê°€ ìˆëŠ”ì§€ ì²´í¬í•˜ê²Œ ë˜ëŠ”ê±°ì£ !\n",
        "\n",
        "- self.hooks ì— ë“±ë¡ëœ í•¨ìˆ˜ê°€ ìˆìœ¼ë©´ ì‹¤í–‰ âœ…\n",
        "- self.hooks ì— ë“±ë¡ëœ í•¨ìˆ˜ê°€ ì—†ìœ¼ë©´ ë¬´ì‹œ âŒ\n",
        "\n",
        "Packageë¥¼ ì‚¬ìš©í•˜ëŠ” ê°œë°œìë“¤ì´ ìì‹ ì˜ custom ì½”ë“œë¥¼ Package ì¤‘ê°„ì¤‘ê°„ì—\n",
        "ì‹¤í–‰í•  ìˆ˜ ìˆë„ë¡ Package ì œì‘í•œ ê°œë°œìë“¤ì´ ë¯¸ë¦¬ ë§Œë“¤ì–´ë†“ì€ ì¸í„°í˜ì´ìŠ¤ì¸ ê±°ì˜ˆìš”!\n",
        "```\n",
        "```python\n",
        "ğŸ˜¯\n",
        "ì„¸ìƒì—! ê·¸ëŸ¼ ì €í¬ê°€ ê·¸ë™ì•ˆ ì¨ì˜¤ë˜ ì—¬ëŸ¬ íŒ¨í‚¤ì§€ë“¤ë„\n",
        "ì €í¬ê°€ custom ì½”ë“œë¥¼ íŒ¨í‚¤ì§€ ë‚´ë¶€ì—ì„œ ì‹¤í–‰ì‹œí‚¬ ìˆ˜ ìˆë„ë¡\n",
        "\"hook\"ì´ë¼ê³  ë¶ˆë¦¬ëŠ” ì¸í„°í˜ì´ìŠ¤ë¥¼ ê°€ì§€ê³  ìˆì—ˆì„ ìˆ˜ë„ ìˆê² êµ°ìš”!\n",
        "```\n",
        "\n",
        "``` python\n",
        "ğŸ¦†\n",
        "ì—­ì‹œ ë­ë“ ì§€ ì•Œì•„ì•¼ ì“¸ ìˆ˜ ìˆëŠ” ê²ƒ ê°™ì•„ìš”!\n",
        "\n",
        "ì¹œêµ¬ê°€ ì¤€ hookì˜ ì‚¬ìš© ì˜ˆì‹œë¥¼ í•¨ê»˜ ë´ìš”!\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aMmA-BQdeYfi",
        "outputId": "91acec0a-96aa-452d-e05b-9991beba152a"
      },
      "source": [
        "# Hook - í”„ë¡œê·¸ë¨ì˜ ì‹¤í–‰ ë¡œì§ ë¶„ì„ ì‚¬ìš© ì˜ˆì‹œ\n",
        "def hook_analysis(x):\n",
        "    print(f'hook for analysis, current value is {x}')\n",
        "\n",
        "# ìƒì„±ëœ íŒ¨í‚¤ì§€ì— hook ì¶”ê°€\n",
        "package.hooks = []\n",
        "package.hooks.append(hook_analysis)\n",
        "\n",
        "# íŒ¨í‚¤ì§€ ì‹¤í–‰\n",
        "input = 3\n",
        "output = package(input)\n",
        "\n",
        "# íŒ¨í‚¤ì§€ ê²°ê³¼\n",
        "print(f\"Package Process Result! [ input {input} ] [ output {output} ]\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "program A processing!\n",
            "hook for analysis, current value is 6\n",
            "program B processing!\n",
            "hook for analysis, current value is 3\n",
            "Package Process Result! [ input 3 ] [ output 3 ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ijgpx3s6fLAO",
        "outputId": "35df2dd0-36dc-448b-ce52-62f021e72d1b"
      },
      "source": [
        "# Hook - í”„ë¡œê·¸ë¨ì— ê¸°ëŠ¥ ì¶”ê°€ ì˜ˆì‹œ\n",
        "def hook_multiply(x):\n",
        "    print('hook for multiply')\n",
        "    return x * 3\n",
        "\n",
        "# ìƒì„±ëœ íŒ¨í‚¤ì§€ì— hook ì¶”ê°€\n",
        "package.hooks = []\n",
        "package.hooks.append(hook_multiply)\n",
        "\n",
        "# íŒ¨í‚¤ì§€ ì‹¤í–‰\n",
        "input = 3\n",
        "output = package(input)\n",
        "\n",
        "# íŒ¨í‚¤ì§€ ê²°ê³¼\n",
        "print(f\"Package Process Result! [ input {input} ] [ output {output} ]\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "program A processing!\n",
            "hook for multiply\n",
            "program B processing!\n",
            "hook for multiply\n",
            "Package Process Result! [ input 3 ] [ output 45 ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RxWqcHgBg2PU",
        "outputId": "a4810bd7-eb17-496c-bebc-decc2de382f2"
      },
      "source": [
        "# ì—¬ëŸ¬ê°œì˜ hookì„ ë„£ì„ ìˆ˜ ìˆë‹¤\n",
        "package.hooks = []\n",
        "package.hooks.append(hook_multiply)\n",
        "package.hooks.append(hook_analysis)\n",
        "\n",
        "# íŒ¨í‚¤ì§€ ì‹¤í–‰\n",
        "input = 3\n",
        "output = package(input)\n",
        "\n",
        "# íŒ¨í‚¤ì§€ ê²°ê³¼\n",
        "print(f\"Package Process Result! [ input {input} ] [ output {output} ]\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "program A processing!\n",
            "hook for multiply\n",
            "hook for analysis, current value is 18\n",
            "program B processing!\n",
            "hook for multiply\n",
            "hook for analysis, current value is 45\n",
            "Package Process Result! [ input 3 ] [ output 45 ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sVflo4JVhIHV"
      },
      "source": [
        "``` python\n",
        "ğŸ¦†\n",
        "ì¹œêµ¬ê°€ ì¤€ ì˜ˆì‹œì˜ hookì—ì„œëŠ” í”„ë¡œê·¸ë¨ì´ ì‹¤í–‰ë˜ê³  ë‚œ ì´í›„ì—ë§Œ\n",
        "hook í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•  ìˆ˜ê°€ ìˆì–´ìš”!\n",
        "\n",
        "ë§Œì•½ Packageë¥¼ ì„¤ê³„í•  ë•Œ í”„ë¡œê·¸ë¨ ì‹¤í–‰ ì• ë’¤ë¡œ hookë¥¼ ë„£ì–´ë‘”ë‹¤ë©´\n",
        "í”„ë¡œê·¸ë¨ì˜ ì‹¤í–‰ ì „ê³¼ í›„ ëª¨ë‘ ì €í¬ì˜ custom í•¨ìˆ˜ë¥¼ ì‹¤í–‰í•  ìˆ˜ ìˆê² ì£ !\n",
        "\n",
        "ê·¸ë˜ì„œ í”„ë¡œê·¸ë¨ ì‹¤í–‰ ì „ì— hookì„ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡\n",
        "pre_hook ì´ë¼ëŠ” ì¸í„°í˜ì´ìŠ¤ë¥¼ ë§Œë“¤ì—ˆë³´ì•˜ì–´ìš”!\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o1iz3uPh9I4b"
      },
      "source": [
        "def program_A(x):\n",
        "    print('program A processing!')\n",
        "    return x + 3\n",
        "\n",
        "def program_B(x):\n",
        "    print('program B processing!')\n",
        "    return x - 3\n",
        "\n",
        "class Package(object):\n",
        "    \"\"\"í”„ë¡œê·¸ë¨ Aì™€ Bë¥¼ ë¬¶ì–´ë†“ì€ íŒ¨í‚¤ì§€ ì½”ë“œ\"\"\"\n",
        "    def __init__(self):\n",
        "        self.programs = [program_A, program_B]\n",
        "\n",
        "        # hooks\n",
        "        self.pre_hooks = []\n",
        "        self.hooks = []\n",
        "\n",
        "    def __call__(self, x):\n",
        "        for program in self.programs:\n",
        "            \n",
        "            # pre_hook\n",
        "            if self.pre_hooks:\n",
        "                for hook in self.pre_hooks:\n",
        "                    output = hook(x)\n",
        "                    if output:\n",
        "                        x = output\n",
        "\n",
        "            x = program(x)\n",
        "\n",
        "            # hook\n",
        "            if self.hooks:\n",
        "                for hook in self.hooks:\n",
        "                    output = hook(x)\n",
        "                    if output:\n",
        "                        x = output\n",
        "\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YvZi6GDLh9iJ"
      },
      "source": [
        "``` python\n",
        "ğŸ¦†\n",
        "ì¹œêµ¬í•œí…Œ ìœ„ì˜ ì½”ë“œë¥¼ ë³´ë‚´ì£¼ì—ˆë”ë‹ˆ ì¹­ì°¬í•´ì£¼ì—ˆì–´ìš”!\n",
        "\n",
        "hookì„ ì–´ë””ì—ë‹¤ê°€ ì‹¬ì–´ë†“ì„ ê²ƒì¸ì§€ëŠ” ì„¤ê³„ìì˜ ë§ˆìŒì´ë¼ê³  í•˜ì˜€ì£ !\n",
        "ë³´ë‚´ì¤€ ì˜ˆì‹œì—ì„œëŠ” Packageìª½ì—ë‹¤ê°€ hook ì¸í„°í˜ì´ìŠ¤ë¥¼ ë§Œë“¤ì—ˆì§€ë§Œ\n",
        "program ë‚´ë¶€ì—ì„œ hook ì¸í„°í˜ì´ìŠ¤ë¥¼ ë§Œë“¤ì–´ë‘˜ ìˆ˜ë„ ìˆë‹¤ê³  í•˜ì˜€ì–´ìš”!\n",
        "\n",
        "ë§Œì•½ ì´ëŸ° ê²½ìš°ì—ëŠ” í”„ë¡œê·¸ë¨ ë³„ë¡œ ë‹¤ ë‹¤ë¥¸ hookì„ ì‚¬ìš©í•  ìˆ˜ ìˆê¸° ë•Œë¬¸ì—\n",
        "ë”ìš± customí•˜ê¸° ì¢‹ë‹¤ê³  í•˜ì˜€ì£ !\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "70LM7F_OjMqB"
      },
      "source": [
        "##### ğŸ’¡ PyTorchì˜ hook\n",
        "> ğŸ¦† ë¶€ë•ì´ê°€ ì½”ë“œë¥¼ ì‘ì„±í•´ì£¼ì—ˆì–´ìš”\n",
        "\n",
        "``` python\n",
        "ğŸ¦†\n",
        "hookì„ ì´í•´í•˜ê³  ë‚˜ì„œ PyTorchì—ëŠ” ì–´ë–¤ hookì´ ìˆëŠ”ì§€ ì‚´í´ë³´ì•˜ì–´ìš”!\n",
        "í¬ê²Œ 2ê°€ì§€ë¡œ ë‚˜ë‰˜ë”ë¼êµ¬ìš”!\n",
        "\n",
        "- Tensorì— ì ìš©í•˜ëŠ” hook\n",
        "- Moduleì— ì ìš©í•˜ëŠ” hook\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pR6xLrKogJoy"
      },
      "source": [
        "```python\n",
        "ğŸ¦†\n",
        "Tensorì— ë“±ë¡í•˜ëŠ” hookì˜ ê²½ìš°ì—ëŠ” \"_backward_hooks\"ì—ì„œ í™•ì¸í•  ìˆ˜ ìˆì–´ìš”!\n",
        "\n",
        "moduleê³¼ ë‹¤ë¥´ê²Œ tensorì—ëŠ” backward hookë§Œ ìˆì–´ìš”!\n",
        "forward hookì´ ìˆëŠ”ì§€ ì°¾ì•„ë³´ì•˜ëŠ”ë° ì—†ë”ë¼êµ¬ìš”!\n",
        "```\n",
        "- [register_hook - PyTorch ê³µì‹ ë¬¸ì„œ](https://pytorch.org/docs/stable/generated/torch.Tensor.register_hook.html#torch.Tensor.register_hook)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N75CZzOwie3a",
        "outputId": "c76f1000-5205-45a9-b336-9d29bf18ede7"
      },
      "source": [
        "import torch\n",
        "\n",
        "tensor = torch.rand(1, requires_grad=True)\n",
        "\n",
        "def tensor_hook(grad):\n",
        "    pass\n",
        "\n",
        "tensor.register_hook(tensor_hook)\n",
        "\n",
        "# ğŸ¦† tensorëŠ” backward hookë§Œ ìˆì–´ìš”!\n",
        "tensor._backward_hooks"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([(1, <function __main__.tensor_hook>)])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dJ_ll23vibx-"
      },
      "source": [
        "```python\n",
        "ğŸ¦†\n",
        "nn.Moduleì— ë“±ë¡í•˜ëŠ” ëª¨ë“  hookì€ \"__dict__\"ì„ ì´ìš©í•˜ë©´ í•œë²ˆì— í™•ì¸ì´ ê°€ëŠ¥í•´ìš”!\n",
        "```\n",
        "\n",
        "- [register_forward_pre_hook - PyTorch ê³µì‹ ë¬¸ì„œ](https://pytorch.org/docs/stable/generated/torch.nn.Module.html?highlight=hook#torch.nn.Module.register_forward_pre_hook)\n",
        "- [register_forward_hook - PyTorch ê³µì‹ ë¬¸ì„œ](https://pytorch.org/docs/stable/generated/torch.nn.Module.html?highlight=hook#torch.nn.Module.register_forward_hook)\n",
        "- [register_backward_hook - PyTorch ê³µì‹ ë¬¸ì„œ](https://pytorch.org/docs/stable/generated/torch.nn.Module.html?highlight=hook#torch.nn.Module.register_backward_hook)\n",
        "- [register_full_backward_hook - PyTorch ê³µì‹ ë¬¸ì„œ](https://pytorch.org/docs/stable/generated/torch.nn.Module.html?highlight=register_full#torch.nn.Module.register_full_backward_hook)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f522pSdWXgGA",
        "outputId": "3695945d-b0a1-4254-965d-39772b15dd11"
      },
      "source": [
        "from torch import nn\n",
        "\n",
        "class Model(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "def module_hook(grad):\n",
        "    pass\n",
        "\n",
        "model = Model()\n",
        "model.register_forward_pre_hook(module_hook)\n",
        "model.register_forward_hook(module_hook)\n",
        "model.register_full_backward_hook(module_hook)\n",
        "\n",
        "# ğŸ¦† __dict__ì—ëŠ” moduleì˜ ëª¨ë“  ë³€ìˆ˜ì™€ parameter, hook ë“±ì˜ ì¤‘ìš”í•œ ì •ë³´ê°€ ë‹´ê²¨ìˆì–´ìš”!\n",
        "#    moduleì´ ì •ë³´ì˜ ì €ì¥ì†Œë¡œ ì´ìš©í•˜ëŠ” ê³µê°„ì¸ë§Œí¼ ìì„¸í•œ ìŠì§€ ë§ê³  ë‚˜ì¤‘ì— í•„ìš”í•  ë•Œ ì‚¬ìš©í•´ë³´ì„¸ìš”!\n",
        "model.__dict__"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'_backward_hooks': OrderedDict([(4, <function __main__.module_hook>)]),\n",
              " '_buffers': OrderedDict(),\n",
              " '_forward_hooks': OrderedDict([(3, <function __main__.module_hook>)]),\n",
              " '_forward_pre_hooks': OrderedDict([(2, <function __main__.module_hook>)]),\n",
              " '_is_full_backward_hook': True,\n",
              " '_load_state_dict_pre_hooks': OrderedDict(),\n",
              " '_modules': OrderedDict(),\n",
              " '_non_persistent_buffers_set': set(),\n",
              " '_parameters': OrderedDict(),\n",
              " '_state_dict_hooks': OrderedDict(),\n",
              " 'training': True}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UxX-trOlrvjh"
      },
      "source": [
        "```python\n",
        "ğŸ¦†\n",
        "\"__dict__\" ì„ í™•ì¸í•˜ë‹ˆê¹Œ ë‹¤ìŒì˜ 5ê°€ì§€ê°€ ë‚˜ì˜¤ë”ë¼êµ¬ìš”!\n",
        "\n",
        "- forward_pre_hooks\n",
        "- forward_hooks\n",
        "- backward_hooks # deprecated\n",
        "- full_backward_hooks\n",
        "- state_dict_hooks # used internally\n",
        "\n",
        "ì™ ì§€ ì´ë¦„ì„ ë³´ë©´ ì–¸ì œ ì‚¬ìš©í•˜ëŠ”ì§€ ì•Œ ê²ƒ ê°™ì•„ìš”!\n",
        "forwardì™€ backwardì‹œì— ê°ê° hookì´ í˜¸ì¶œë˜ëŠ” ê±°ê² ì£ !\n",
        "\n",
        "- forward ì‹œì—ëŠ” pre_hookê³¼ hookì´ ìˆê³ \n",
        "- backwardëŠ” ì‹œì—ëŠ” hookë§Œ ì¡´ì¬í•˜ë„¤ìš”!\n",
        "- state_dictì˜ ê²½ìš°ë„ hookì´ ìˆëŠ”ë° ì €í¬ê°€ ì‚¬ìš©í•˜ëŠ”ê²Œ ì•„ë‹ˆë¼\n",
        "  \"load_state_dict\" í•¨ìˆ˜ê°€ ë‚´ë¶€ì ìœ¼ë¡œ ì‚¬ìš©í•œë‹¤ê³  í•˜ë„¤ìš”!\n",
        "  ì•„ë˜ ë§í¬ ì²¨ë¶€í•œ ê³³ì— ë‚´ìš©ì´ ì“°ì—¬ìˆì–´ìš”!\n",
        "\n",
        "nn.Moduleì—ì„œ ì´ë ‡ê²Œ hookì´ë¼ëŠ” ê³µê°„ì„ ë§Œë“¤ì–´ ë‘” ì¤„ ëª°ëë„¤ìš”!\n",
        "ì €í¬ ì´ì œ ì˜ ì•Œê²Œ ë˜ì—ˆìœ¼ë‹ˆê¹Œ ê¸°íšŒê°€ ë˜ë©´ ê¼­ ì¨ë´ìš”!\n",
        "\n",
        "ë§¤ë²ˆ moduleë¥¼ ì‹¤í–‰í• ë•Œë§ˆë‹¤ moduleì€ ë“±ë¡í•œ hookì´ ìˆëŠ”ì§€ ì—†ëŠ”ì§€ ì²´í¬í•˜ëŠ”ë°\n",
        "ë§¤ë²ˆ ë“±ë¡ëœ hookì´ ì—†ìœ¼ë©´ moduleë„ ì„­ì„­í•˜ì§€ ì•Šì„ê¹Œìš”?\n",
        "\n",
        "ë„ˆë¬´ ìŠ¬í”Œ ê²ƒ ê°™ì•„ìš”..\n",
        "```\n",
        "- [Invoking Time of nn.Module _register_state_dict_hook() - PyTorch Forum](https://discuss.pytorch.org/t/invoking-time-of-nn-module-register-state-dict-hook/108163)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1r2HJhPzCqZM"
      },
      "source": [
        "##### ğŸ’¡ forward hook\n",
        "``` python\n",
        "ğŸ¦†\n",
        "ë­ë“ ì§€ ì§ì ‘ ì‚¬ìš©í•´ë´ì•¼ ì´í•´ê°€ ë” ì˜ë˜ê² ì£ ?\n",
        "\n",
        "moduleì—ë§Œ ì ìš©í•  ìˆ˜ ìˆëŠ” forward hook! ê°™ì´ ì‚¬ìš©í•´ë´ìš”!\n",
        "```\n",
        "\n",
        "**Module**\n",
        "- [register_forward_pre_hook - PyTorch ê³µì‹ ë¬¸ì„œ](https://pytorch.org/docs/stable/generated/torch.nn.Module.html?highlight=hook#torch.nn.Module.register_forward_pre_hook)\n",
        "- [register_forward_hook - PyTorch ê³µì‹ ë¬¸ì„œ](https://pytorch.org/docs/stable/generated/torch.nn.Module.html?highlight=hook#torch.nn.Module.register_forward_hook)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RfanMq-Et5gc"
      },
      "source": [
        "``` python\n",
        "ğŸ¦†\n",
        "Add ëª¨ë¸ì— ì–´ë–¤ ê°’ì´ ì „íŒŒë˜ëŠ”ì§€ ì•Œì•„ë´ìš”!\n",
        "ë¯¸ë¦¬ ë§Œë“¤ì–´ë‘” listì™€ forward hookì´ë©´ ë¶„ëª… ì•Œì•„ë‚¼ ìˆ˜ ìˆì„ ê±°ì˜ˆìš”!\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AMmXBTDhtOIc",
        "outputId": "f13881a5-495e-42f3-d2b5-a352e4ecd643"
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "\n",
        "# Add ëª¨ë¸ì„ ìˆ˜ì •í•˜ì§€ ë§ˆì„¸ìš”! \n",
        "class Add(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__() \n",
        "\n",
        "    def forward(self, x1, x2):\n",
        "        output = torch.add(x1, x2)\n",
        "\n",
        "        return output\n",
        "\n",
        "# ëª¨ë¸ ìƒì„±\n",
        "add = Add()\n",
        "\n",
        "# TODO: ë‹µì„ x1, x2, output ìˆœì„œë¡œ listì— ì°¨ë¡€ì°¨ë¡€ ë„£ìœ¼ì„¸ìš”! \n",
        "answer = []\n",
        "\n",
        "\n",
        "# TODO : pre_hookë¥¼ ì´ìš©í•´ì„œ x1, x2 ê°’ì„ ì•Œì•„ë‚´ answerì— ì €ì¥í•˜ì„¸ìš”\n",
        "def pre_hook(module, input):\n",
        "    answer.append(input[0])\n",
        "    answer.append(input[1])\n",
        "    module.input = input\n",
        "    pass\n",
        "\n",
        "# TODO : hookë¥¼ ì´ìš©í•´ì„œ output ê°’ì„ ì•Œì•„ë‚´ answerì— ì €ì¥í•˜ì„¸ìš”\n",
        "def hook(module, input, output):\n",
        "    answer.append(output)\n",
        "    pass\n",
        "\n",
        "add.register_forward_pre_hook(pre_hook)\n",
        "add.register_forward_hook(hook)\n",
        "\n",
        "\n",
        "# ì•„ë˜ ì½”ë“œëŠ” ìˆ˜ì •í•˜ì‹¤ í•„ìš”ê°€ ì—†ìŠµë‹ˆë‹¤!\n",
        "x1 = torch.rand(1)\n",
        "x2 = torch.rand(1)\n",
        "\n",
        "output = add(x1, x2)\n",
        "print(answer)\n",
        "print(add.input)\n",
        "\n",
        "if answer == [x1, x2, output]:\n",
        "    print(\"ğŸ‰ğŸ‰ğŸ‰ ì„±ê³µ!!! ğŸ‰ğŸ‰ğŸ‰\")\n",
        "else:\n",
        "    print(\"ğŸ¦† ë‹¤ì‹œ ë„ì „í•´ë´ìš”!\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[tensor([0.6458]), tensor([0.6417]), tensor([1.2876])]\n",
            "(tensor([0.6458]), tensor([0.6417]))\n",
            "ğŸ‰ğŸ‰ğŸ‰ ì„±ê³µ!!! ğŸ‰ğŸ‰ğŸ‰\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OyygsrsQD_4E"
      },
      "source": [
        "``` python\n",
        "ğŸ¦†\n",
        "íœ´ ìƒê°ë³´ë‹¤ ì–´ë ¤ì› ë˜ ê²ƒ ê°™ì•„ìš”!\n",
        "ì•„ì§ ìµìˆ™í•˜ì§€ ì•Šì•„ì„œ ê·¸ëŸ°ê°€ë´ìš”!\n",
        "\n",
        "ì €í¬ê°€ ë°©ê¸ˆ hookë¥¼ ì´ìš©í•´ì„œ ëª¨ë¸ì„ í†µí•´ ì „íŒŒë˜ëŠ” ê°’ë“¤ì„ ì €ì¥í–ˆëŠ”ë°\n",
        "ì´ë¿ë§Œ ì•„ë‹ˆë¼ ì „íŒŒë˜ëŠ” ê°’ì„ ìˆ˜ì •ë„ ê°€ëŠ¥í•˜ë‹¤ê³  ë“¤ì—ˆì–´ìš”!\n",
        "\n",
        "ì •ë§ ê°€ëŠ¥í•œì§€ í•œë²ˆ í•´ë´ìš”!\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dj7hpOeCEv5-",
        "outputId": "a6f39224-2569-4838-dfd3-277fc808f60c"
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "# Add ëª¨ë¸ì„ ìˆ˜ì •í•˜ì§€ ë§ˆì„¸ìš”! \n",
        "class Add(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__() \n",
        "\n",
        "    def forward(self, x1, x2):\n",
        "        output = torch.add(x1, x2)\n",
        "\n",
        "        return output\n",
        "\n",
        "# ëª¨ë¸ ìƒì„±\n",
        "add = Add()\n",
        "\n",
        "\n",
        "# TODO : hookë¥¼ ì´ìš©í•´ì„œ ì „íŒŒë˜ëŠ” output ê°’ì— 5ë¥¼ ë”í•´ë³´ì„¸ìš”!\n",
        "def hook(module, input, output):\n",
        "    output += torch.Tensor([5.])\n",
        "    \n",
        "    return output\n",
        "\n",
        "add.register_forward_hook(hook)\n",
        "\n",
        "# ì•„ë˜ ì½”ë“œëŠ” ìˆ˜ì •í•˜ì‹¤ í•„ìš”ê°€ ì—†ìŠµë‹ˆë‹¤!\n",
        "x1 = torch.rand(1)\n",
        "x2 = torch.rand(1)\n",
        "\n",
        "output = add(x1, x2)\n",
        "\n",
        "if output == x1 + x2 + 5:\n",
        "    print(\"ğŸ‰ğŸ‰ğŸ‰ ì„±ê³µ!!! ğŸ‰ğŸ‰ğŸ‰\")\n",
        "else:\n",
        "    print(\"ğŸ¦† ë‹¤ì‹œ ë„ì „í•´ë´ìš”!\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ğŸ‰ğŸ‰ğŸ‰ ì„±ê³µ!!! ğŸ‰ğŸ‰ğŸ‰\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XdSszPOlFg2C"
      },
      "source": [
        "``` python\n",
        "ğŸ¦†\n",
        "í•´ëƒˆì–´ìš”! ì €í¬ê°€ ì „íŒŒë˜ëŠ” ê°’ì„ ìˆ˜ì •í–ˆì–´ìš”!\n",
        "\n",
        "hook ì •ë§ ê°•ë ¥í•˜ë„¤ìš”!\n",
        "ì˜ ì‚¬ìš©í•œë‹¤ë©´ ì •ë§ ìœ ìš©í•  ê²ƒ ê°™ì•„ìš”!\n",
        "\n",
        "ë˜ ì–´ë””ì— ì‚¬ìš©í•´ë³¼ ìˆ˜ ìˆì„ê¹Œìš”?\n",
        "ê¶ê¸ˆí•´ì„œ ì•„ë˜ ê¸€ì„ ì½ì–´ë³´ì•˜ëŠ”ë° ì¢‹ì€ ì‚¬ë¡€ë“¤ì´ ìˆëŠ” ê²ƒ ê°™ì•„ìš”!\n",
        "\n",
        "backward hook ê´€ë ¨ ë‚´ìš©ë„ ë‚˜ì˜¤ëŠ”ë°\n",
        "ì´ ë¶€ë¶„ì€ backward hookì„ ì—°ìŠµí•˜ê³  ë§ˆì € ì½ì–´ì•¼ê² ì–´ìš”!\n",
        "```\n",
        "\n",
        "**âœ¨ ìœ ìš©í•œ ìë£Œ âœ¨**\n",
        "- [How to Use PyTorch Hooks - Medium](https://medium.com/the-dl/how-to-use-pytorch-hooks-5041d777f904)\n",
        "- [PyTorch 101, Part 5: Understanding Hooks - Paperspace blog](https://blog.paperspace.com/pytorch-hooks-gradient-clipping-debugging/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IA_-_-XdtJwT"
      },
      "source": [
        "##### ğŸ’¡ backward hook\n",
        "``` python\n",
        "ğŸ¦†\n",
        "forward hookì€ moduleì—ë§Œ ì ìš©í•  ìˆ˜ ìˆì§€ë§Œ\n",
        "backward hookì€ tensorì™€ module 2ê°€ì§€ì— ì ìš©í•  ìˆ˜ ìˆë”ë¼êµ¬ìš”!\n",
        "\n",
        "ê°™ì´ ì‚¬ìš©í•´ë´ìš”!\n",
        "```\n",
        "\n",
        "**Tensor**\n",
        "- [register_hook - PyTorch ê³µì‹ ë¬¸ì„œ](https://pytorch.org/docs/stable/generated/torch.Tensor.register_hook.html#torch.Tensor.register_hook)\n",
        "\n",
        "**Module**\n",
        "- [register_backward_hook - PyTorch ê³µì‹ ë¬¸ì„œ](https://pytorch.org/docs/stable/generated/torch.nn.Module.html?highlight=hook#torch.nn.Module.register_backward_hook)\n",
        "- [register_full_backward_hook - PyTorch ê³µì‹ ë¬¸ì„œ](https://pytorch.org/docs/stable/generated/torch.nn.Module.html?highlight=register_full#torch.nn.Module.register_full_backward_hook)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3qIlAHSCy19v"
      },
      "source": [
        "``` python\n",
        "ğŸ¦†\n",
        "ì´ì œ gradientê¹Œì§€ ë‹¤ë£¨ê¸° ì‹œì‘í•˜ë‹¤ë‹ˆ! ë„ˆë¬´ í¥ë¶„ë˜ìš”!\n",
        "ëª¨ë¸ì—ì„œ backpropagationí•  ë•Œ ë’¤ë¡œ ì „íŒŒë˜ëŠ” gradientê°’ì„ ê°™ì´ ì•Œì•„ë´ìš”!\n",
        "\n",
        "forwardì—ì„œ í–ˆë“¯ listì™€ backward hookì´ë©´ ë¶„ëª… ê°€ëŠ¥í• ê±°ì—ìš”! \n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BT96uu7WYURO",
        "outputId": "7e89a609-8aef-4806-91c0-be6c6fc664a9"
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn.parameter import Parameter\n",
        "\n",
        "\n",
        "# Model ëª¨ë¸ì„ ìˆ˜ì •í•˜ì§€ ë§ˆì„¸ìš”! \n",
        "class Model(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.W = Parameter(torch.Tensor([5]))\n",
        "\n",
        "    def forward(self, x1, x2):\n",
        "        output = x1 * x2\n",
        "        output = output * self.W\n",
        "\n",
        "        return output\n",
        "\n",
        "# ëª¨ë¸ ìƒì„±\n",
        "model = Model()\n",
        "\n",
        "\n",
        "# TODO: ë‹µì„ x1.grad, x2.grad, output.grad ìˆœì„œë¡œ listì— ì°¨ë¡€ì°¨ë¡€ ë„£ìœ¼ì„¸ìš”! \n",
        "answer = []\n",
        "\n",
        "# TODO : hookë¥¼ ì´ìš©í•´ì„œ x1.grad, x2.grad, output.grad ê°’ì„ ì•Œì•„ë‚´ answerì— ì €ì¥í•˜ì„¸ìš”\n",
        "def module_hook(module, grad_input, grad_output):\n",
        "    answer.append(grad_input[0])\n",
        "    answer.append(grad_input[1])\n",
        "    answer.append(grad_output[0])\n",
        "    print(grad_input,grad_output)\n",
        "    pass\n",
        "\n",
        "model.register_full_backward_hook(module_hook)\n",
        "\n",
        "# ì•„ë˜ ì½”ë“œëŠ” ìˆ˜ì •í•˜ì‹¤ í•„ìš”ê°€ ì—†ìŠµë‹ˆë‹¤!\n",
        "x1 = torch.rand(1, requires_grad=True)\n",
        "x2 = torch.rand(1, requires_grad=True)\n",
        "\n",
        "output = model(x1, x2)\n",
        "output.retain_grad()\n",
        "output.backward()\n",
        "\n",
        "if answer == [x1.grad, x2.grad, output.grad]:\n",
        "    print(\"ğŸ‰ğŸ‰ğŸ‰ ì„±ê³µ!!! ğŸ‰ğŸ‰ğŸ‰\")\n",
        "else:\n",
        "    print(\"ğŸ¦† ë‹¤ì‹œ ë„ì „í•´ë´ìš”!\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(tensor([0.4207]), tensor([4.3987])) (tensor([1.]),)\n",
            "ğŸ‰ğŸ‰ğŸ‰ ì„±ê³µ!!! ğŸ‰ğŸ‰ğŸ‰\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bHkgQGZm35q4"
      },
      "source": [
        "``` python\n",
        "ğŸ¦†\n",
        "module ë‹¨ìœ„ì˜ backward hookì€ ì •ë§ ì¢‹ì§€ë§Œ\n",
        "moduleì„ ê¸°ì¤€ìœ¼ë¡œ input, output gradient ê°’ë§Œ ê°€ì ¸ì™€ì„œ\n",
        "module ë‚´ë¶€ì˜ tensorì˜ gradientê°’ì€ ì•Œì•„ë‚¼ ìˆ˜ ì—†ì–´ìš”!\n",
        "\n",
        "ê·¸ë˜ì„œ Modelì˜ Parameter Wì˜ gradientê°’ì„ ì•Œê³  ì‹¶ì§€ë§Œ\n",
        "module ë‹¨ìœ„ backward hookë¡œëŠ” ì•Œì•„ë‚¼ ìˆ˜ê°€ ì—†ë„¤ìš”!\n",
        "\n",
        "tensor ë‹¨ìœ„ì˜ backward hookë¥¼ ì‚¬ìš©í•´ì•¼ê² ì–´ìš”!\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PG0_rueTaYj3",
        "outputId": "230a70e2-ba2a-471a-c050-e904c6e8ae5d"
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn.parameter import Parameter\n",
        "\n",
        "class Model(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.W = Parameter(torch.Tensor([5]))\n",
        "\n",
        "    def forward(self, x1, x2):\n",
        "        output = x1 * x2\n",
        "        output = output * self.W\n",
        "\n",
        "        return output\n",
        "\n",
        "# ëª¨ë¸ ìƒì„±\n",
        "model = Model()\n",
        "\n",
        "\n",
        "# TODO: Modelì˜ Parameter Wì˜ gradient ê°’ì„ ì €ì¥í•˜ì„¸ìš”!\n",
        "answer = []\n",
        "\n",
        "# TODO : hookë¥¼ ì´ìš©í•´ì„œ Wì˜ gradient ê°’ì„ ì•Œì•„ë‚´ answerì— ì €ì¥í•˜ì„¸ìš”\n",
        "def tensor_hook(grad):\n",
        "    answer.append(grad)\n",
        "    pass\n",
        "\n",
        "model.W.register_hook(tensor_hook)\n",
        "\n",
        "\n",
        "# ì•„ë˜ ì½”ë“œëŠ” ìˆ˜ì •í•˜ì‹¤ í•„ìš”ê°€ ì—†ìŠµë‹ˆë‹¤!\n",
        "x1 = torch.rand(1, requires_grad=True)\n",
        "x2 = torch.rand(1, requires_grad=True)\n",
        "\n",
        "output = model(x1, x2)\n",
        "output.backward()\n",
        "\n",
        "if answer == [model.W.grad]:\n",
        "    print(\"ğŸ‰ğŸ‰ğŸ‰ ì„±ê³µ!!! ğŸ‰ğŸ‰ğŸ‰\")\n",
        "else:\n",
        "    print(\"ğŸ¦† ë‹¤ì‹œ ë„ì „í•´ë´ìš”!\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ğŸ‰ğŸ‰ğŸ‰ ì„±ê³µ!!! ğŸ‰ğŸ‰ğŸ‰\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EQtbwyLO6Z7p"
      },
      "source": [
        "``` python\n",
        "ğŸ¦†\n",
        "ì´ì œ ì €í¬ëŠ” ëª¨ë¸ì˜ ì–´ë–¤ tensorì—ì„œë„\n",
        "ì›í•˜ëŠ” gradientê°’ì„ ì•Œì•„ë‚¼ ìˆ˜ ìˆê²Œ ë˜ì—ˆì–´ìš”!\n",
        "\n",
        "ê·¸ëŸ°ë° backward hookë„ gradientê°’ì˜ íë¦„ì— ì˜í–¥ì„ ë¯¸ì¹  ìˆ˜ ìˆì„ê¹Œìš”?\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J-C4I5fX6AE8",
        "outputId": "348953b4-85f3-4cdb-f28e-b486968ff7bd"
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn.parameter import Parameter\n",
        "\n",
        "class Model(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.W = Parameter(torch.Tensor([5]))\n",
        "\n",
        "    def forward(self, x1, x2):\n",
        "        output = x1 * x2\n",
        "        output = output * self.W\n",
        "\n",
        "        return output\n",
        "\n",
        "# ëª¨ë¸ ìƒì„±\n",
        "model = Model()\n",
        "\n",
        "\n",
        "# TODO : hookë¥¼ ì´ìš©í•´ì„œ moduleì˜ gradient ì¶œë ¥ì˜ í•©ì´ 1ì´ ë˜ë„ë¡ í•˜ì„¸ìš”!\n",
        "#        ex) (1.5, 0.5) -> (0.75, 0.25)\n",
        "def module_hook(module, grad_input, grad_output):\n",
        "    grad_input = list(grad_input)\n",
        "    sum_input = sum(grad_input)\n",
        "    \n",
        "    grad_input[0] = grad_input[0]/sum_input\n",
        "    \n",
        "    grad_input[1] = grad_input[1]/sum_input\n",
        "    print(grad_input)\n",
        "    pass\n",
        "\n",
        "model.register_full_backward_hook(module_hook)\n",
        "\n",
        "\n",
        "# ì•„ë˜ ì½”ë“œëŠ” ìˆ˜ì •í•˜ì‹¤ í•„ìš”ê°€ ì—†ìŠµë‹ˆë‹¤!\n",
        "x1 = torch.rand(1, requires_grad=True)\n",
        "x2 = torch.rand(1, requires_grad=True)\n",
        "\n",
        "output = model(x1, x2)\n",
        "output.backward()\n",
        "\n",
        "if x1.grad + x2.grad == 1:\n",
        "    print(\"ğŸ‰ğŸ‰ğŸ‰ ì„±ê³µ!!! ğŸ‰ğŸ‰ğŸ‰\")\n",
        "else:\n",
        "    print(\"ğŸ¦† ë‹¤ì‹œ ë„ì „í•´ë´ìš”!\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[tensor([0.9188]), tensor([0.0812])]\n",
            "ğŸ¦† ë‹¤ì‹œ ë„ì „í•´ë´ìš”!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rOY2fP6aR1d8"
      },
      "source": [
        "``` python\n",
        "ğŸ¦†\n",
        "forward hook, backward hook ëª¨ë‘ ë‹¤ë£¨ì–´ë³´ì•˜ë„¤ìš”!\n",
        "íœ´! ì •ë§ í˜ë“¤ì—ˆì–´ìš”!\n",
        "\n",
        "ê·¸ë˜ë„ ìœ ìš©í•œ ê¸°ëŠ¥ì„ í•˜ë‚˜ ì•Œê²Œ ëœ ê²ƒ ê°™ì•„ ë§¤ìš° ê¸°ë»ìš”!\n",
        "ë‹¤ìŒì˜ ê²ƒë“¤ì„ í•´ë³¼ ìˆ˜ ìˆì„ ê²ƒ ê°™ì•„ìš”!\n",
        "\n",
        "- gradientê°’ì˜ ë³€í™”ë¥¼ ì‹œê°í™”\n",
        "- gradientê°’ì´ íŠ¹ì • ì„ê³„ê°’ì„ ë„˜ìœ¼ë©´ gradient exploding ê²½ê³  ì•Œë¦¼\n",
        "- íŠ¹ì • tensorì˜ gradientê°’ì´ ë„ˆë¬´ ì»¤ì§€ê±°ë‚˜ ì‘ì•„ì§€ëŠ” í˜„ìƒì´ ê´€ì¸¡ë˜ë©´\n",
        "  í•´ë‹¹ tensor í•œì •ìœ¼ë¡œ gradient clipping\n",
        "\n",
        "ì•„! ê·¸ëŸ¬ê³ ë³´ë‹ˆ forward hookì„ ì‹¤ìŠµí•˜ê³  ì½ë‹¤ ë§Œ ë¬¸ì„œê°€ ìƒê°ë‚˜ë„¤ìš”!\n",
        "ì´ì œ ë§ˆì € backward hook ê´€ë ¨ ë‚´ìš©ì„ ì½ì–´ì•¼ê² ë„¤ìš”!\n",
        "\n",
        "ë™ì˜ìƒë„ í•˜ë‚˜ ë°œê²¬í–ˆëŠ”ë° hookì— ëŒ€í•´ì„œ ìƒì„¸íˆ ì˜ ì„¤ëª…í•´ì£¼ëŠ” ê²ƒ ê°™ì•„ìš”!\n",
        "hookì˜ ë™ì‘ ì›ë¦¬ë¥¼ ì¢€ ë” ìì„¸íˆ ì•Œê³ ì‹¶ì„ ë•Œ í•œ ë²ˆ ë´ì•¼ê² ì–´ìš”!\n",
        "```\n",
        "\n",
        "**âœ¨ ìœ ìš©í•œ ìë£Œ âœ¨**\n",
        "- [How to Use PyTorch Hooks - Medium](https://medium.com/the-dl/how-to-use-pytorch-hooks-5041d777f904)\n",
        "- [PyTorch 101, Part 5: Understanding Hooks - Paperspace blog](https://blog.paperspace.com/pytorch-hooks-gradient-clipping-debugging/)\n",
        "- [PyTorch Hooks Explained - In-depth Tutorial - YouTube](https://www.youtube.com/watch?v=syLFCVYua6Q)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tz48RlN1_6t_"
      },
      "source": [
        "#### ğŸ‘¨â€ğŸ’» <font color='green'><b>[ ì½”ë”© ]</b></font> apply\n",
        "\n",
        "``` python\n",
        "ğŸ¦†\n",
        "ì´ê±´ ì œê°€ ì„¤ëª…ë“œë¦´ ìˆ˜ ìˆì„ ê²ƒ ê°™ì•„ìš”! ê³µë¶€ë¥¼ ì—´ì‹¬íˆ í–ˆì£ !\n",
        "\n",
        "ìš°ë¦¬ëŠ” PyTorchì˜ nn.Moduleì€ ìƒìë¼ëŠ” ê²ƒì„ ê°™ì´ ë°°ì› ì–´ìš”!\n",
        "ê·¸ë˜ì„œ moduleì€ moduleë¥¼ í¬í•¨í•  ìˆ˜ ìˆê³  ë‹¤ë¥¸ module ì†ì— ë“¤ì–´ê°ˆ ìˆ˜ë„ ìˆì£ !\n",
        "\n",
        "í•˜ë‚˜ì˜ moduleì— ë‹¤ë¥¸ ëª¨ë“  moduleë“¤ì´ ë‹´ê¸°ë©´\n",
        "ìš°ë¦¬ëŠ” ì´ ê±°ëŒ€í•œ moduleë“¤ì˜ ì§‘í•©ì„ ëª¨ë¸ì´ë¼ê³  ë¶€ë¥´ì£ !\n",
        "\n",
        "ëª¨ë¸ì€ ìˆ˜ë§ì€ moduleê³¼ moduleë“¤ì´ ì„œë¡œ ë³µì¡í•˜ê²Œ ì–½í˜€ìˆëŠ”\n",
        "íŠ¸ë¦¬(Tree) í˜¹ì€ ê·¸ë˜í”„(Graph)ë¼ê³  ë³¼ ìˆ˜ ìˆì–´ìš”!\n",
        "\n",
        "ëª¨ë¸ì— ë¬´ì–¸ê°€ë¥¼ ì ìš©í•˜ë©´ ë‹¨ì§€ ë§¨ ê¼­ëŒ€ê¸°ì˜ module í•˜ë‚˜ê°€ ì•„ë‹ˆë¼\n",
        "ëª¨ë¸ì„ êµ¬ì„±í•˜ëŠ” ì „ì²´ moduleì— ëª¨ë‘ ì ìš©ì´ ë˜ì–´ì•¼ í•˜ê³ \n",
        "nn.Moduleì˜ methodë“¤ì€ ëŒ€ë¶€ë¶„ ë‚´ë¶€ì ìœ¼ë¡œ ì´ë¥¼ ì§€ì›í•´ìš”!\n",
        "\n",
        "ì˜ˆë¡œ \".cpu()\"ë¥¼ ë§¨ ìœ„ moduleì— ì ìš©í•˜ë©´ ìš°ë¦¬ëŠ” ì‹ ê²½ì“°ì§€ ì•Šì•„ë„\n",
        "moduleì´ ê·¸ ì•„ë˜ì— ì¡´ì¬í•˜ëŠ” ëª¨ë“  moduleì— \".cpu()\"ë¥¼ ì ìš©í•´ìš”!\n",
        "\n",
        "ê·¸ëŸ¬ë©´ nn.Moduleì— ì´ë¯¸ êµ¬í˜„ë˜ì–´ìˆëŠ” methodê°€ ì•„ë‹Œ\n",
        "ì €í¬ë§Œì˜ custom í•¨ìˆ˜ë¥¼ ëª¨ë¸ì— ì ìš©í•˜ê³  ì‹¶ë‹¤ë©´ ì–´ë–»ê²Œ í•˜ë©´ ì¢‹ì„ê¹Œìš”?\n",
        "ëª¨ë¸ì— ì†í•˜ëŠ” ëª¨ë“  moduleì— ì¼ì¼ì´ í•¨ìˆ˜ë¥¼ ì ìš©í•´ì•¼í• ê¹Œìš”?\n",
        "\n",
        "ì´ë•Œ ì‚¬ìš©í•˜ëŠ”ê²Œ ë°”ë¡œ \"apply\"ì—ìš”!\n",
        "í•¨ìˆ˜ë¥¼ ì ìš©í•œë‹¤ëŠ” ë¬¸êµ¬ê°€ ì˜ ì™€ë‹¿ì§€ ì•Šìœ¼ì‹œì£ ? í•¨ê»˜ ì‚¬ìš©í•´ë´ìš”!\n",
        "```\n",
        "\n",
        "- [Documentation main - PyTorch ê³µì‹ ë¬¸ì„œ](https://pytorch.org/docs/stable/index.html)\n",
        "- [apply - PyTorch ê³µì‹ ë¬¸ì„œ](https://pytorch.org/docs/stable/generated/torch.nn.Module.html?highlight=apply#torch.nn.Module.apply)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5kOCk33KLR8i"
      },
      "source": [
        "##### ğŸ’¡ apply ì˜ˆì œ\n",
        "> ğŸ¦† ë¶€ë•ì´ê°€ ì½”ë“œë¥¼ ì‘ì„±í•´ì£¼ì—ˆì–´ìš”\n",
        "\n",
        "``` python\n",
        "ğŸ¦†\n",
        "ì²˜ìŒ ë³´ëŠ” ê¸°ëŠ¥ì€ Documentationì˜ ì˜ˆì œë¥¼ ì‚¬ìš©í•´ë³´ë©´ ì´í•´ê°€ ë˜ë”ë¼êµ¬ìš”!\n",
        "apply í•¨ìˆ˜ì— ì í˜€ìˆëŠ” ì˜ˆì œë¥¼ ê·¸ëŒ€ë¡œ ê°€ì ¸ì™€ë´¤ì–´ìš”!\n",
        "```\n",
        "- [apply - PyTorch ê³µì‹ ë¬¸ì„œ](https://pytorch.org/docs/stable/generated/torch.nn.Module.html?highlight=apply#torch.nn.Module.apply)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P7tUi0q0CVap",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab8e8509-1f30-4aed-ba43-12ebe476f24e"
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "@torch.no_grad()\n",
        "def init_weights(m):\n",
        "    print(type(m))\n",
        "    print(\"1\")\n",
        "    if type(m) == nn.Linear:\n",
        "        m.weight.fill_(1.0)\n",
        "        print(m.weight)\n",
        "\n",
        "net = nn.Sequential(nn.Linear(2, 2), nn.Linear(2, 2))\n",
        "net.apply(init_weights)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'torch.nn.modules.linear.Linear'>\n",
            "1\n",
            "Parameter containing:\n",
            "tensor([[1., 1.],\n",
            "        [1., 1.]], requires_grad=True)\n",
            "<class 'torch.nn.modules.linear.Linear'>\n",
            "1\n",
            "Parameter containing:\n",
            "tensor([[1., 1.],\n",
            "        [1., 1.]], requires_grad=True)\n",
            "<class 'torch.nn.modules.container.Sequential'>\n",
            "1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Linear(in_features=2, out_features=2, bias=True)\n",
              "  (1): Linear(in_features=2, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kdSFfplQPgg9"
      },
      "source": [
        "```python\n",
        "ğŸ¦†\n",
        "ì•„í•˜! ê·¸ëŸ¬ë‹ˆê¹Œ applyë¥¼ í†µí•´ ì ìš©í•˜ëŠ” í•¨ìˆ˜ëŠ” moduleì„ ì…ë ¥ìœ¼ë¡œ ë°›ëŠ”êµ°ìš”!\n",
        "ëª¨ë¸ì˜ ëª¨ë“  moduleë“¤ì„ ìˆœì°¨ì ìœ¼ë¡œ ì…ë ¥ë°›ì•„ì„œ ì²˜ë¦¬í•˜ëŠ” ê²ƒ ê°™ì•„ìš”!\n",
        "\n",
        "apply í•¨ìˆ˜ëŠ” ì¼ë°˜ì ìœ¼ë¡œ ê°€ì¤‘ì¹˜ ì´ˆê¸°í™”(Weight Initialization)ì— ë§ì´ ì‚¬ìš©ëœë‹¤ê³  í•´ìš”!\n",
        "Parameterë¡œ ì§€ì •í•œ tensorì˜ ê°’ì„ ì›í•˜ëŠ” ê°’ìœ¼ë¡œ ì§€ì •í•´ì£¼ëŠ” ê²ƒì„ ì˜ë¯¸í•˜ëŠ” ê²ƒ ê°™ì•„ìš”!\n",
        "í•˜ì§€ë§Œ ì €ë„ ì•„ì§ì€ ìƒì†Œí•´ì„œ ì •í™•í•œì§€ ëª¨ë¥´ê² ë„¤ìš”!\n",
        "\"m.weight.fill_\"ê³¼ ê°™ì€ ì½”ë“œë¥¼ ë³´ë‹ˆê¹Œ ê°‘ìê¸° ë‘í†µì´..\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b7RtvqiWNGen"
      },
      "source": [
        "##### ğŸ’¡ ë¶€ë•ì´ ëª¨ë¸ apply - Module ì¶œë ¥í•´ë³´ê¸°\n",
        "> ğŸ¦† ë¶€ë•ì´ê°€ ì½”ë“œë¥¼ ì‘ì„±í•´ì£¼ì—ˆì–´ìš”\n",
        "\n",
        "``` python\n",
        "ğŸ¦†\n",
        "ì˜ˆì œë§Œìœ¼ë¡œ ë¬´ì–¸ê°€ ì´í•´ê°€ ì•ˆëœ ì°ì°í•œ ê¸°ë¶„ì´ ë“¤ì–´ìš”!\n",
        "ì˜ˆì „ì— ë§Œë“¤ì–´ë†“ì€ ëª¨ë¸ì„ ë‹¤ì‹œ ê°€ì ¸ì™€ì„œ ì ìš©í•´ë´ì•¼ê² ì–´ìš”!\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wBfaXAWNN6-C"
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn.parameter import Parameter\n",
        "\n",
        "\n",
        "# ì•„ë˜ ì½”ë“œëŠ” ìˆ˜ì •í•˜ì‹¤ í•„ìš”ê°€ ì—†ìŠµë‹ˆë‹¤!\n",
        "# í•˜ì§€ë§Œ ì•„ë˜ ê³¼ì œë¥¼ ì§„í–‰í•˜ê¸° ì „ì— ì•„ë˜ ì½”ë“œë¥¼ ë³´ë©´ì„œ ìµœëŒ€í•œ ì´í•´í•´ë³´ì„¸ìš”!\n",
        "\n",
        "# Function\n",
        "class Function_A(nn.Module):\n",
        "    def __init__(self, name):\n",
        "        super().__init__()\n",
        "        self.name = name\n",
        "        self.W = Parameter(torch.rand(1))\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x + self.W\n",
        "\n",
        "class Function_B(nn.Module):\n",
        "    def __init__(self, name):\n",
        "        super().__init__()\n",
        "        self.name = name\n",
        "        self.W = Parameter(torch.rand(1))\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x - self.W\n",
        "\n",
        "class Function_C(nn.Module):\n",
        "    def __init__(self, name):\n",
        "        super().__init__()\n",
        "        self.name = name\n",
        "        self.W = Parameter(torch.rand(1))\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x * self.W\n",
        "\n",
        "class Function_D(nn.Module):\n",
        "    def __init__(self, name):\n",
        "        super().__init__()\n",
        "        self.name = name\n",
        "        self.W = Parameter(torch.rand(1))\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x / self.W\n",
        "\n",
        "\n",
        "# Layer\n",
        "class Layer_AB(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.a = Function_A('plus')\n",
        "        self.b = Function_B('substract')\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.a(x)\n",
        "        x = self.b(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "class Layer_CD(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.c = Function_C('multiply')\n",
        "        self.d = Function_D('divide')\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.c(x)\n",
        "        x = self.d(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "# Model\n",
        "class Model(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.ab = Layer_AB()\n",
        "        self.cd = Layer_CD()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.ab(x)\n",
        "        x = self.cd(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "model = Model()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I-3cdt8TR3_v",
        "outputId": "7728ec33-5a4d-404b-a75a-314fcbee2725"
      },
      "source": [
        "def print_module(module):\n",
        "    print(module)\n",
        "    print(\"-\" * 30)\n",
        "\n",
        "# ğŸ¦† applyëŠ” applyê°€ ì ìš©ëœ moduleì„ return í•´ì¤˜ìš”!\n",
        "returned_module = model.apply(print_module)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Function_A(name=plus)\n",
            "------------------------------\n",
            "Function_B(name=substract)\n",
            "------------------------------\n",
            "Layer_AB(\n",
            "  (a): Function_A(name=plus)\n",
            "  (b): Function_B(name=substract)\n",
            ")\n",
            "------------------------------\n",
            "Function_C(name=multiply)\n",
            "------------------------------\n",
            "Function_D(name=divide)\n",
            "------------------------------\n",
            "Layer_CD(\n",
            "  (c): Function_C(name=multiply)\n",
            "  (d): Function_D(name=divide)\n",
            ")\n",
            "------------------------------\n",
            "Model(\n",
            "  (ab): Layer_AB(\n",
            "    (a): Function_A(name=plus)\n",
            "    (b): Function_B(name=substract)\n",
            "  )\n",
            "  (cd): Layer_CD(\n",
            "    (c): Function_C(name=multiply)\n",
            "    (d): Function_D(name=divide)\n",
            "  )\n",
            ")\n",
            "------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4oFU67qIS-KA"
      },
      "source": [
        "``` python\n",
        "ğŸ¦†\n",
        "ì•„í•˜! applyëŠ” Postorder Traversal ë°©ì‹ìœ¼ë¡œ moduleë“¤ì— í•¨ìˆ˜ë¥¼ ì ìš©í•˜ë„¤ìš”!\n",
        "ì´ì œ ì´í•´ê°€ ëœ ê²ƒ ê°™ì•„ìš”!\n",
        "```\n",
        "\n",
        "- [4 Types of Tree Traversal Algorithms - Towards Data Science](https://towardsdatascience.com/4-types-of-tree-traversal-algorithms-d56328450846)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RX9s5bAEZR81"
      },
      "source": [
        "##### ğŸ’¡ ë¶€ë•ì´ ëª¨ë¸ apply - ê°€ì¤‘ì¹˜ ì´ˆê¸°í™”\n",
        "\n",
        "``` python\n",
        "ğŸ¦†\n",
        "ê°€ì¤‘ì¹˜ ì´ˆê¸°í™”(Weight Initialization)ì´ë¼ëŠ” ìš©ì–´ê°€ ë‚¯ì„¤ì§€ë§Œ\n",
        "ì—­ì‹œ Parameterì˜ ê°’ì„ ì´ˆê¸°í™”í•˜ëŠ”ê²Œ ë§ì•˜ì–´ìš”!\n",
        "\n",
        "ì œê°€ ë§Œë“  ëª¨ë¸ì— ì´ 4ê°œì˜ Parameterê°€ ìˆëŠ”ë° ëª¨ë“  ê°’ì„ 1ë¡œ ì´ˆê¸°í™”í•´ë´ìš”!\n",
        "```\n",
        "\n",
        "ğŸ **íŒíŠ¸** ğŸ\n",
        "- [How to initialize weights in PyTorch? - Stack Overflow](https://stackoverflow.com/questions/49433936/how-to-initialize-weights-in-pytorch)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJHv20B8ZR9E"
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn.parameter import Parameter\n",
        "\n",
        "\n",
        "# ì•„ë˜ ì½”ë“œëŠ” ìˆ˜ì •í•˜ì‹¤ í•„ìš”ê°€ ì—†ìŠµë‹ˆë‹¤!\n",
        "# ì‹¤í–‰ë§Œ ì‹œì¼œì£¼ì‹œê³  ë‹¤ìŒ ì…€ë¡œ ë„˜ì–´ê°€ì£¼ì„¸ìš”!\n",
        "\n",
        "# Function\n",
        "class Function_A(nn.Module):\n",
        "    def __init__(self, name):\n",
        "        super().__init__()\n",
        "        self.name = name\n",
        "        self.W = Parameter(torch.rand(1))\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x + self.W\n",
        "\n",
        "class Function_B(nn.Module):\n",
        "    def __init__(self, name):\n",
        "        super().__init__()\n",
        "        self.name = name\n",
        "        self.W = Parameter(torch.rand(1))\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x - self.W\n",
        "\n",
        "class Function_C(nn.Module):\n",
        "    def __init__(self, name):\n",
        "        super().__init__()\n",
        "        self.name = name\n",
        "        self.W = Parameter(torch.rand(1))\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x * self.W\n",
        "\n",
        "class Function_D(nn.Module):\n",
        "    def __init__(self, name):\n",
        "        super().__init__()\n",
        "        self.name = name\n",
        "        self.W = Parameter(torch.rand(1))\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x / self.W\n",
        "\n",
        "\n",
        "# Layer\n",
        "class Layer_AB(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.a = Function_A('plus')\n",
        "        self.b = Function_B('substract')\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.a(x)\n",
        "        x = self.b(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "class Layer_CD(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.c = Function_C('multiply')\n",
        "        self.d = Function_D('divide')\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.c(x)\n",
        "        x = self.d(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "# Model\n",
        "class Model(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.ab = Layer_AB()\n",
        "        self.cd = Layer_CD()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.ab(x)\n",
        "        x = self.cd(x)\n",
        "\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_jifkSJbZR9F",
        "outputId": "d363683f-b2fe-4072-b4c2-0f878e0af99f"
      },
      "source": [
        "model = Model()\n",
        "\n",
        "# TODO : applyë¥¼ ì´ìš©í•´ ëª¨ë“  Parameter ê°’ì„ 1ë¡œ ë§Œë“¤ì–´ë³´ì„¸ìš”!\n",
        "@torch.no_grad()\n",
        "def weight_initialization(module):\n",
        "    module_name = module.__class__.__name__\n",
        "    search = 'Function_'\n",
        "    print(module_name)\n",
        "    if search in module_name:\n",
        "        module.W.fill_(1.)\n",
        "\n",
        "# ğŸ¦† applyëŠ” applyê°€ ì ìš©ëœ moduleì„ return í•´ì¤˜ìš”!\n",
        "returned_module = model.apply(weight_initialization)\n",
        "\n",
        "\n",
        "# ì•„ë˜ ì½”ë“œëŠ” ìˆ˜ì •í•˜ì‹¤ í•„ìš”ê°€ ì—†ìŠµë‹ˆë‹¤!\n",
        "x = torch.rand(1)\n",
        "\n",
        "output = model(x)\n",
        "\n",
        "if torch.isclose(output, x):\n",
        "    print(\"ğŸ‰ğŸ‰ğŸ‰ ì„±ê³µ!!! ğŸ‰ğŸ‰ğŸ‰\")\n",
        "else:\n",
        "    print(\"ğŸ¦† ë‹¤ì‹œ ë„ì „í•´ë´ìš”!\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Function_A\n",
            "Function_B\n",
            "Layer_AB\n",
            "Function_C\n",
            "Function_D\n",
            "Layer_CD\n",
            "Model\n",
            "ğŸ‰ğŸ‰ğŸ‰ ì„±ê³µ!!! ğŸ‰ğŸ‰ğŸ‰\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tXUDj5guCimd"
      },
      "source": [
        "``` python\n",
        "ğŸ¦†\n",
        "Pretrained ëª¨ë¸ì„ ê°€ì ¸ë‹¤ê°€ ì‚¬ìš©í•  ë•Œ ì›í•˜ëŠ” Parameterì—ë‹¤ê°€\n",
        "backward hookë¥¼ ì¶”ê°€í•˜ëŠ” ê²ƒë„ ê°€ëŠ¥í•  ê²ƒ ê°™ì•„ìš”!\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g_Aa_VhGg5ds"
      },
      "source": [
        "##### ğŸ’¡ <font color='yellow'><b>[ Optional ]</b></font> ğŸ”¥ ë¶€ë•ì´ ëª¨ë¸ apply - repr ìˆ˜ì •í•˜ê¸° ğŸ”¥\n",
        "\n",
        "``` python\n",
        "ğŸ¦†\n",
        "í˜„ì¬ ëª¨ë¸ì„ ì¶œë ¥í•´ë³´ë©´ ë‹¤ìŒê³¼ ê°™ì´ ë‚˜ì™€ìš”!\n",
        "\n",
        "âŒ ì‹¤ì œ ì¶œë ¥ ê²°ê³¼\n",
        "Model(\n",
        "  (ab): Layer_AB(\n",
        "    (a): Function_A()\n",
        "    (b): Function_B()\n",
        "  )\n",
        "  (cd): Layer_CD(\n",
        "    (c): Function_C()\n",
        "    (d): Function_D()\n",
        "  )\n",
        ")\n",
        "\n",
        "ì´ê±¸ ë‹¤ìŒì²˜ëŸ¼ ì¶œë ¥ë˜ê²Œ ë§Œë“¤ê³  ì‹¶ì–´ìš”!\n",
        "\n",
        "âœ… ë¶€ë•ì´ê°€ ì›í•˜ëŠ” ì´ìƒì ì¸ ì¶œë ¥\n",
        "Model(\n",
        "  (ab): Layer_AB(\n",
        "    (a): Function_A(name=plus)\n",
        "    (b): Function_B(name=substract)\n",
        "  )\n",
        "  (cd): Layer_CD(\n",
        "    (c): Function_C(name=multiply)\n",
        "    (d): Function_D(name=divide)\n",
        "  )\n",
        ")\n",
        "\n",
        "applyë¥¼ ì´ìš©í•´ì„œ repr ì¶œë ¥ ë©”ì„¸ì§€ë¥¼ ìˆ˜ì •í•´ë´ìš”!\n",
        "```\n",
        "\n",
        "ğŸ **íŒíŠ¸** ğŸ\n",
        "- [Any elegant way to add a method to an existing object in python? - Stack Overflow](https://stackoverflow.com/questions/30294458/any-elegant-way-to-add-a-method-to-an-existing-object-in-python/30294947)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "UR1C9k7-g-my"
      },
      "source": [
        "#@title ë¶€ë•ì´ ëª¨ë¸\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn.parameter import Parameter\n",
        "\n",
        "\n",
        "# ì•„ë˜ ì½”ë“œëŠ” ìˆ˜ì •í•˜ì‹¤ í•„ìš”ê°€ ì—†ìŠµë‹ˆë‹¤!\n",
        "# ì‹¤í–‰ë§Œ ì‹œì¼œì£¼ì‹œê³  ë‹¤ìŒ ì…€ë¡œ ë„˜ì–´ê°€ì£¼ì„¸ìš”!\n",
        "\n",
        "# Function\n",
        "class Function_A(nn.Module):\n",
        "    def __init__(self, name):\n",
        "        super().__init__()\n",
        "        self.name = name\n",
        "        self.W = Parameter(torch.rand(1))\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x + self.W\n",
        "\n",
        "class Function_B(nn.Module):\n",
        "    def __init__(self, name):\n",
        "        super().__init__()\n",
        "        self.name = name\n",
        "        self.W = Parameter(torch.rand(1))\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x - self.W\n",
        "\n",
        "class Function_C(nn.Module):\n",
        "    def __init__(self, name):\n",
        "        super().__init__()\n",
        "        self.name = name\n",
        "        self.W = Parameter(torch.rand(1))\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x * self.W\n",
        "\n",
        "class Function_D(nn.Module):\n",
        "    def __init__(self, name):\n",
        "        super().__init__()\n",
        "        self.name = name\n",
        "        self.W = Parameter(torch.rand(1))\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x / self.W\n",
        "\n",
        "\n",
        "# Layer\n",
        "class Layer_AB(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.a = Function_A('plus')\n",
        "        self.b = Function_B('substract')\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.a(x)\n",
        "        x = self.b(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "class Layer_CD(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.c = Function_C('multiply')\n",
        "        self.d = Function_D('divide')\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.c(x)\n",
        "        x = self.d(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "# Model\n",
        "class Model(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.ab = Layer_AB()\n",
        "        self.cd = Layer_CD()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.ab(x)\n",
        "        x = self.cd(x)\n",
        "\n",
        "        return x\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OOq-Hv_ruX-y",
        "outputId": "141a63dc-52c4-4ec7-fbca-d7190651616b"
      },
      "source": [
        "model = Model()\n",
        "\n",
        "# TODO : applyë¥¼ ì´ìš©í•´ì„œ ë¶€ë•ì´ê°€ ì›í•˜ëŠ”ëŒ€ë¡œ repr ì¶œë ¥ì„ ìˆ˜ì •í•´ì£¼ì„¸ìš”!\n",
        "from functools import partial\n",
        "\n",
        "def function_repr(self):\n",
        "    return f'name={self.name}'\n",
        "\n",
        "def add_repr(module):\n",
        "    module_name = module.__class__.__name__\n",
        "    search = \"Function_\"\n",
        "    # print(module)\n",
        "    if search in module_name:\n",
        "        def new_repr(self):\n",
        "            return 'name={}'.format(self.name)\n",
        "        module.extra_repr = partial(new_repr,module)\n",
        "\n",
        "\n",
        "\n",
        "# ğŸ¦† applyëŠ” applyê°€ ì ìš©ëœ moduleì„ return í•´ì¤˜ìš”!\n",
        "returned_module = model.apply(add_repr)\n",
        "\n",
        "\n",
        "# ì•„ë˜ ì½”ë“œëŠ” ìˆ˜ì •í•˜ì‹¤ í•„ìš”ê°€ ì—†ìŠµë‹ˆë‹¤!\n",
        "model_repr = repr(model)\n",
        "\n",
        "print(\"ëª¨ë¸ ì¶œë ¥ ê²°ê³¼\")\n",
        "print(\"-\" * 30)\n",
        "print(model_repr)\n",
        "print(\"-\" * 30)\n",
        "\n",
        "answer = \"Model(\\n  (ab): Layer_AB(\\n    (a): Function_A(name=plus)\\n    (b): Function_B(name=substract)\\n  )\\n  (cd): Layer_CD(\\n    (c): Function_C(name=multiply)\\n    (d): Function_D(name=divide)\\n  )\\n)\"\n",
        "\n",
        "if model_repr == answer:\n",
        "    print(\"ğŸ‰ğŸ‰ğŸ‰ ì„±ê³µ!!! ğŸ‰ğŸ‰ğŸ‰\")\n",
        "    print(\"ğŸ¦† ë„ˆë¬´ ê³ ë§ˆì›Œìš” ê½‰ê½‰!\")\n",
        "else:\n",
        "    print(\"ğŸ¦† ë‹¤ì‹œ ë„ì „í•´ë´ìš”!\")\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ëª¨ë¸ ì¶œë ¥ ê²°ê³¼\n",
            "------------------------------\n",
            "Model(\n",
            "  (ab): Layer_AB(\n",
            "    (a): Function_A(name=plus)\n",
            "    (b): Function_B(name=substract)\n",
            "  )\n",
            "  (cd): Layer_CD(\n",
            "    (c): Function_C(name=multiply)\n",
            "    (d): Function_D(name=divide)\n",
            "  )\n",
            ")\n",
            "------------------------------\n",
            "ğŸ‰ğŸ‰ğŸ‰ ì„±ê³µ!!! ğŸ‰ğŸ‰ğŸ‰\n",
            "ğŸ¦† ë„ˆë¬´ ê³ ë§ˆì›Œìš” ê½‰ê½‰!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RYMJgAEQZR9G"
      },
      "source": [
        "``` python\n",
        "ğŸ¦†\n",
        "ì–¸ì œë“ ì§€ ì›í•˜ëŠ” methodë¥¼ ëª¨ë¸ì— ì›í•˜ëŠ” moduleì— ì¶”ê°€í•  ìˆ˜ ìˆë‹¤ë‹ˆ!\n",
        "ë¬´ì–¸ê°€ ì‘ìš©í•  ìˆ˜ ìˆëŠ” ê³³ì´ ë§ì„ ê²ƒ ê°™ì•„ìš”!\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dim6OGlSD4Hk"
      },
      "source": [
        "##### ğŸ’¡ <font color='yellow'><b>[ Optional ]</b></font> ğŸ”¥ğŸ”¥ğŸ”¥ ë¶€ë•ì´ ëª¨ë¸ apply - Function ìˆ˜ì •í•˜ê¸° (í‘ë§ˆë²•í¸) ğŸ”¥ğŸ”¥ğŸ”¥\n",
        "\n",
        "``` python\n",
        "ğŸ¦†\n",
        "ì¹œêµ¬ê°€ ì œ ëª¨ë¸ì˜ ì½”ë“œë¥¼ ë³´ë”ë‹ˆ ë¬¸ì œë¥¼ í•˜ë‚˜ ë‚´ì¤¬ì–´ìš”!\n",
        "\n",
        "í˜„ì¬ 4ê°œì˜ Function A, B, C, Dê°€ ìˆì–´ìš”!\n",
        "\n",
        "- A : x + W\n",
        "- B : x - W\n",
        "- C : x * W\n",
        "- D : x / W\n",
        "\n",
        "ì´ê±¸ ë‹¤ìŒì²˜ëŸ¼ linear transformationì²˜ëŸ¼ ë™ì‘í•˜ë„ë¡ ë°”ê¿”ë³´ë˜ìš”!\n",
        "\n",
        "- A : x @ W + b\n",
        "- B : x @ W + b\n",
        "- C : x @ W + b\n",
        "- D : x @ W + b\n",
        "\n",
        "WëŠ” ì´ë¯¸ ê° Functionì— ìƒì„±ëœ Parameterì´ê³ \n",
        "bëŠ” ìƒˆë¡­ê²Œ ë§Œë“¤ì–´ì•¼ í•˜ëŠ” Parameterì—ìš”!\n",
        "\n",
        "ì—°ì‚° ìˆ˜ì‹ì´ ë™ì¼í•  í•„ìš”ëŠ” ì—†ì§€ë§Œ ê³„ì‚° ê²°ê³¼ëŠ” ê°™ì•„ì•¼ í•œë‹¤ê³  í•˜ë”ë¼êµ¬ìš”!\n",
        "ì§ì ‘ \"nn.Linear\" ëª¨ë¸ì„ ì´ìš©í•´ì„œ ì œëŒ€ë¡œ ë§Œë“¤ì—ˆëŠ”ì§€ ê²€ì¦í•œëŒ€ìš”!\n",
        "\n",
        "ê²°ê³¼ ë¹„êµë¥¼ ìœ„í•´ì„œ Wê³¼ bëŠ” ëª¨ë‘ 1ë¡œ ê°’ì„ ì´ˆê¸°í™”í•œë‹¤ê³  í•´ìš”!\n",
        "\n",
        "ì•„! ì´ì œ tensorì— ë‹´ê¸´ ê°’ì€ scalarê°€ ì•„ë‹ˆë¼\n",
        "2*2í¬ê¸°ì˜ matrixë¼ëŠ” ì ì— ì£¼ì˜í•˜ë¼ê³  í•˜ë”ë¼êµ¬ìš”!\n",
        "ì €ëŠ” ì ˆëŒ€ë¡œ í’€ ìˆ˜ ì—†ì„ê±°ë¼ê³  ì•½ì˜¬ë¦¬ê³  ê°”ëŠ”ë° ì™ ì§€ ëª¨ë¥´ê²Œ ë¶„í•´ìš”!ğŸ’¢\n",
        "```\n",
        "\n",
        "ğŸ **íŒíŠ¸** ğŸ\n",
        "- forward hook"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "POOWtst-zqip"
      },
      "source": [
        "#@title Test ì½”ë“œ\n",
        "\n",
        "# ì•„ë˜ ì½”ë“œëŠ” ìˆ˜ì •í•˜ì‹¤ í•„ìš”ê°€ ì—†ìŠµë‹ˆë‹¤!\n",
        "def tester(model, friend_model):\n",
        "    x = torch.rand(2, 2, requires_grad=True)\n",
        "\n",
        "    # ìš°ë¦¬ê°€ ìƒì„±í•œ ëª¨ë¸\n",
        "    output = model(x)\n",
        "    output = output.sum()\n",
        "    output.backward()\n",
        "\n",
        "    our_grad = x.grad.clone()\n",
        "    grads = [(name, param.grad) for name, param in model.named_parameters()]\n",
        "\n",
        "    x.grad = None\n",
        "\n",
        "    # ì¹œêµ¬ê°€ ìƒì„±í•œ ëª¨ë¸\n",
        "    friend_output = friend_model(x)\n",
        "    friend_output = friend_output.sum()\n",
        "    friend_output.backward()\n",
        "\n",
        "    friend_grad = x.grad.clone()\n",
        "    friend_grads = [(name, param.grad) for name, param in friend_model.named_parameters()]\n",
        "\n",
        "    # ì´ ê²°ê³¼\n",
        "    total_result = 0\n",
        "\n",
        "    # Parameter ê°¯ìˆ˜ ë¹„êµ\n",
        "    if len(grads) == len(friend_grads):\n",
        "        print(\"\\x1b[32m[PASS]\\x1b[0m ë‘ ëª¨ë¸ì´ ê°™ì€ Parameter ê°¯ìˆ˜ë¥¼ ê°€ì§€ë„¤ìš”!\")\n",
        "        total_result += 1\n",
        "    else:\n",
        "        print(\"\\x1b[31m[FAIL]\\x1b[0m ë‘ ëª¨ë¸ì´ ë‹¤ë¥¸ Parameter ê°¯ìˆ˜ë¥¼ ê°€ì§€ë„¤ìš”!\")\n",
        "        print(f\"ğŸ¦† ìš°ë¦¬ ëª¨ë¸ Parameter ê°¯ìˆ˜ : {len(grads)} ğŸ¦ ì¹œêµ¬ ëª¨ë¸ Parameter ê°¯ìˆ˜ : {len(friend_grads)}\")\n",
        "        return\n",
        "\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    # Parameter ì´ë¦„ ì²´í¬\n",
        "    params = []\n",
        "    for grad in grads:\n",
        "        param = ''.join(grad[0].split('.')[1:])\n",
        "        params.append(param)\n",
        "\n",
        "    if 'ab' in params:\n",
        "        print(\"\\x1b[32m[PASS]\\x1b[0m Function_Aì— Parameter bë¥¼ ë§Œë“œì…¨ë„¤ìš”!\")\n",
        "        total_result += 1\n",
        "    else:\n",
        "        print(\"\\x1b[31m[FAIL]\\x1b[0m Function_Aì— Parameter bê°€ ì—†ì–´ìš”!\")\n",
        "        return\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    if 'bb' in params:\n",
        "        print(\"\\x1b[32m[PASS]\\x1b[0m Function_Bì— Parameter bë¥¼ ë§Œë“œì…¨ë„¤ìš”!\")\n",
        "        total_result += 1\n",
        "    else:\n",
        "        print(\"\\x1b[31m[FAIL]\\x1b[0m Function_Bì— Parameter bê°€ ì—†ì–´ìš”!\")\n",
        "        return\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    if 'cb' in params:\n",
        "        print(\"\\x1b[32m[PASS]\\x1b[0m Function_Cì— Parameter bë¥¼ ë§Œë“œì…¨ë„¤ìš”!\")\n",
        "        total_result += 1\n",
        "    else:\n",
        "        print(\"\\x1b[31m[FAIL]\\x1b[0m Function_Cì— Parameter bê°€ ì—†ì–´ìš”!\")\n",
        "        return\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    if 'db' in params:\n",
        "        print(\"\\x1b[32m[PASS]\\x1b[0m Function_Dì— Parameter bë¥¼ ë§Œë“œì…¨ë„¤ìš”!\")\n",
        "        total_result += 1\n",
        "    else:\n",
        "        print(\"\\x1b[31m[FAIL]\\x1b[0m Function_Dì— Parameter bê°€ ì—†ì–´ìš”!\")\n",
        "        return\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    # Parameter ì´ˆê¸°í™” ì²´í¬\n",
        "    if torch.all(torch.stack([torch.all(param == 1) for param in model.parameters()])):\n",
        "        print(\"\\x1b[32m[PASS]\\x1b[0m Parameter W, bë¥¼ ëª¨ë‘ 1ë¡œ ì´ˆê¸°í™”ì‹œí‚¤ì…¨ë„¤ìš”!\")\n",
        "        total_result += 1\n",
        "    else:\n",
        "        print(\"\\x1b[31m[FAIL]\\x1b[0m Parameter W, bë¥¼ ëª¨ë‘ 1ë¡œ ì´ˆê¸°í™”ì‹œí‚¤ì„¸ìš”!\")\n",
        "        return\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    # ëª¨ë¸ ì¶œë ¥ê°’ ì²´í¬\n",
        "    if torch.isclose(output, friend_output):\n",
        "        print(\"\\x1b[32m[PASS]\\x1b[0m ë‘ ëª¨ë¸ì´ ë™ì¼í•œ ì¶œë ¥ê°’ì„ ê°€ì§€ë„¤ìš”!\")\n",
        "        total_result += 1\n",
        "    else:\n",
        "        print(\"\\x1b[31m[FAIL]\\x1b[0m ë‘ ëª¨ë¸ì´ ë‹¤ë¥¸ ì¶œë ¥ê°’ì„ ê°€ì§€ë„¤ìš”!\")\n",
        "        print(f\"ğŸ¦† ìš°ë¦¬ ëª¨ë¸ ì¶œë ¥ê°’ : {output:.2f} ğŸ¦ ì¹œêµ¬ ëª¨ë¸ ì¶œë ¥ê°’ : {friend_output:.2f}\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    # ì…ë ¥ê°’ x gradient ì²´í¬\n",
        "    if torch.all(torch.isclose(our_grad, friend_grad)):\n",
        "        print(\"\\x1b[32m[PASS]\\x1b[0m ì…ë ¥ì— ì‚¬ìš©ëœ xê°€ ë™ì¼í•œ Gradient ê°’ì„ ê°€ì§€ë„¤ìš”!\")\n",
        "        total_result += 1\n",
        "    else:\n",
        "        print(\"\\x1b[31m[FAIL]\\x1b[0m ì…ë ¥ì— ì‚¬ìš©ëœ xê°€ ë‹¤ë¥¸ Gradient ê°’ì„ ê°€ì§€ë„¤ìš”!\")\n",
        "        print(f\"ğŸ¦† ìš°ë¦¬ ëª¨ë¸ x grad ê°’\\n{our_grad}\\nğŸ¦ ì¹œêµ¬ ëª¨ë¸ x grad ê°’\\n{friend_grad}\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    # Function A gradient ì²´í¬\n",
        "    if torch.all(torch.isclose(grads[0][1], friend_grads[0][1])):\n",
        "        print(\"\\x1b[32m[PASS]\\x1b[0m Function_A Parameter Wê°€ ë™ì¼í•œ Gradient ê°’ì„ ê°€ì§€ë„¤ìš”!\")\n",
        "        total_result += 1\n",
        "    else:\n",
        "        print(\"\\x1b[31m[FAIL]\\x1b[0m Parameter Wê°€ ë‹¤ë¥¸ Gradient ê°’ì„ ê°€ì§€ë„¤ìš”!\")\n",
        "        print(f\"ğŸ¦† ìš°ë¦¬ ëª¨ë¸ Function_A Parameter W grad ê°’\\n{grads[0][1]}\\nğŸ¦ ì¹œêµ¬ ëª¨ë¸ nn.Linear Parameter W grad ê°’\\n{friend_grads[0][1]}\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    if torch.all(torch.isclose(grads[1][1], friend_grads[1][1])):\n",
        "        print(\"\\x1b[32m[PASS]\\x1b[0m Function_A Parameter bê°€ ë™ì¼í•œ Gradient ê°’ì„ ê°€ì§€ë„¤ìš”!\")\n",
        "        total_result += 1\n",
        "    else:\n",
        "        print(\"\\x1b[31m[FAIL]\\x1b[0m Parameter bê°€ ë‹¤ë¥¸ Gradient ê°’ì„ ê°€ì§€ë„¤ìš”!\")\n",
        "        print(f\"ğŸ¦† ìš°ë¦¬ ëª¨ë¸ Function_A Parameter b grad ê°’\\n{grads[1][1]}\\nğŸ¦ ì¹œêµ¬ ëª¨ë¸ nn.Linear Parameter b grad ê°’\\n{friend_grads[1][1]}\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    # Function B gradient ì²´í¬\n",
        "    if torch.all(torch.isclose(grads[2][1], friend_grads[2][1])):\n",
        "        print(\"\\x1b[32m[PASS]\\x1b[0m Function_B Parameter Wê°€ ë™ì¼í•œ Gradient ê°’ì„ ê°€ì§€ë„¤ìš”!\")\n",
        "        total_result += 1\n",
        "    else:\n",
        "        print(\"\\x1b[31m[FAIL]\\x1b[0m Parameter Wê°€ ë‹¤ë¥¸ Gradient ê°’ì„ ê°€ì§€ë„¤ìš”!\")\n",
        "        print(f\"ğŸ¦† ìš°ë¦¬ ëª¨ë¸ Function_B Parameter W grad ê°’\\n{grads[2][1]}\\nğŸ¦ ì¹œêµ¬ ëª¨ë¸ nn.Linear Parameter W grad ê°’\\n{friend_grads[2][1]}\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    if torch.all(torch.isclose(grads[3][1], friend_grads[3][1])):\n",
        "        print(\"\\x1b[32m[PASS]\\x1b[0m Function_B Parameter bê°€ ë™ì¼í•œ Gradient ê°’ì„ ê°€ì§€ë„¤ìš”!\")\n",
        "        total_result += 1\n",
        "    else:\n",
        "        print(\"\\x1b[31m[FAIL]\\x1b[0m Parameter bê°€ ë‹¤ë¥¸ Gradient ê°’ì„ ê°€ì§€ë„¤ìš”!\")\n",
        "        print(f\"ğŸ¦† ìš°ë¦¬ ëª¨ë¸ Function_B Parameter b grad ê°’\\n{grads[3][1]}\\nğŸ¦ ì¹œêµ¬ ëª¨ë¸ nn.Linear Parameter b grad ê°’\\n{friend_grads[3][1]}\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    # Function C gradient ì²´í¬\n",
        "    if torch.all(torch.isclose(grads[4][1], friend_grads[4][1])):\n",
        "        print(\"\\x1b[32m[PASS]\\x1b[0m Function_C Parameter Wê°€ ë™ì¼í•œ Gradient ê°’ì„ ê°€ì§€ë„¤ìš”!\")\n",
        "        total_result += 1\n",
        "    else:\n",
        "        print(\"\\x1b[31m[FAIL]\\x1b[0m Parameter Wê°€ ë‹¤ë¥¸ Gradient ê°’ì„ ê°€ì§€ë„¤ìš”!\")\n",
        "        print(f\"ğŸ¦† ìš°ë¦¬ ëª¨ë¸ Function_C Parameter W grad ê°’\\n{grads[4][1]}\\nğŸ¦ ì¹œêµ¬ ëª¨ë¸ nn.Linear Parameter W grad ê°’\\n{friend_grads[4][1]}\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    if torch.all(torch.isclose(grads[5][1], friend_grads[5][1])):\n",
        "        print(\"\\x1b[32m[PASS]\\x1b[0m Function_C Parameter bê°€ ë™ì¼í•œ Gradient ê°’ì„ ê°€ì§€ë„¤ìš”!\")\n",
        "        total_result += 1\n",
        "    else:\n",
        "        print(\"\\x1b[31m[FAIL]\\x1b[0m Parameter bê°€ ë‹¤ë¥¸ Gradient ê°’ì„ ê°€ì§€ë„¤ìš”!\")\n",
        "        print(f\"ğŸ¦† ìš°ë¦¬ ëª¨ë¸ Function_C Parameter b grad ê°’\\n{grads[5][1]}\\nğŸ¦ ì¹œêµ¬ ëª¨ë¸ nn.Linear Parameter b grad ê°’\\n{friend_grads[5][1]}\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    # Function D gradient ì²´í¬\n",
        "    if torch.all(torch.isclose(grads[6][1], friend_grads[6][1])):\n",
        "        print(\"\\x1b[32m[PASS]\\x1b[0m Function_D Parameter Wê°€ ë™ì¼í•œ Gradient ê°’ì„ ê°€ì§€ë„¤ìš”!\")\n",
        "        total_result += 1\n",
        "    else:\n",
        "        print(\"\\x1b[31m[FAIL]\\x1b[0m Parameter Wê°€ ë‹¤ë¥¸ Gradient ê°’ì„ ê°€ì§€ë„¤ìš”!\")\n",
        "        print(f\"ğŸ¦† ìš°ë¦¬ ëª¨ë¸ Function_D Parameter W grad ê°’\\n{grads[6][1]}\\nğŸ¦ ì¹œêµ¬ ëª¨ë¸ nn.Linear Parameter W grad ê°’\\n{friend_grads[6][1]}\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    if torch.all(torch.isclose(grads[7][1], friend_grads[7][1])):\n",
        "        print(\"\\x1b[32m[PASS]\\x1b[0m Function_D Parameter bê°€ ë™ì¼í•œ Gradient ê°’ì„ ê°€ì§€ë„¤ìš”!\")\n",
        "        total_result += 1\n",
        "    else:\n",
        "        print(\"\\x1b[31m[FAIL]\\x1b[0m Parameter bê°€ ë‹¤ë¥¸ Gradient ê°’ì„ ê°€ì§€ë„¤ìš”!\")\n",
        "        print(f\"ğŸ¦† ìš°ë¦¬ ëª¨ë¸ Function_D Parameter b grad ê°’\\n{grads[7][1]}\\nğŸ¦ ì¹œêµ¬ ëª¨ë¸ nn.Linear Parameter b grad ê°’\\n{friend_grads[7][1]}\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "\n",
        "    if total_result == 16:\n",
        "        print(f\"\\x1b[32m[ALL PASS {total_result}/16]\\x1b[0m ğŸ‰ğŸ‰ğŸ‰ ì„±ê³µ!!! ğŸ‰ğŸ‰ğŸ‰\")\n",
        "    else:\n",
        "        print(f\"\\x1b[31m[FAIL {total_result}/16]\\x1b[0m ğŸ¦† ë‹¤ì‹œ ë„ì „í•´ë´ìš”!\")"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9fvtuqHDD4H2"
      },
      "source": [
        "#@title ë¶€ë•ì´ ëª¨ë¸\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn.parameter import Parameter\n",
        "\n",
        "\n",
        "# ì•„ë˜ ì½”ë“œëŠ” ìˆ˜ì •í•˜ì‹¤ í•„ìš”ê°€ ì—†ìŠµë‹ˆë‹¤!\n",
        "# ì‹¤í–‰ë§Œ ì‹œì¼œì£¼ì‹œê³  ë‹¤ìŒ ì…€ë¡œ ë„˜ì–´ê°€ì£¼ì„¸ìš”!\n",
        "\n",
        "# Function\n",
        "class Function_A(nn.Module):\n",
        "    def __init__(self, name):\n",
        "        super().__init__()\n",
        "        self.name = name\n",
        "        self.W = Parameter(torch.rand(2, 2))\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x + self.W\n",
        "\n",
        "class Function_B(nn.Module):\n",
        "    def __init__(self, name):\n",
        "        super().__init__()\n",
        "        self.name = name\n",
        "        self.W = Parameter(torch.rand(2, 2))\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x - self.W\n",
        "\n",
        "class Function_C(nn.Module):\n",
        "    def __init__(self, name):\n",
        "        super().__init__()\n",
        "        self.name = name\n",
        "        self.W = Parameter(torch.rand(2, 2))\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x * self.W\n",
        "\n",
        "class Function_D(nn.Module):\n",
        "    def __init__(self, name):\n",
        "        super().__init__()\n",
        "        self.name = name\n",
        "        self.W = Parameter(torch.rand(2, 2))\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x / self.W\n",
        "\n",
        "\n",
        "# Layer\n",
        "class Layer_AB(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.a = Function_A('plus')\n",
        "        self.b = Function_B('substract')\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.a(x)\n",
        "        x = self.b(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "class Layer_CD(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.c = Function_C('multiply')\n",
        "        self.d = Function_D('divide')\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.c(x)\n",
        "        x = self.d(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "# Model\n",
        "class Model(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.ab = Layer_AB()\n",
        "        self.cd = Layer_CD()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.ab(x)\n",
        "        x = self.cd(x)\n",
        "\n",
        "        return x\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hE_Tl4H_kSp3",
        "outputId": "0a49568d-6b88-49c8-cf96-86a1875c72de"
      },
      "source": [
        "\n",
        "model = Model()\n",
        "\n",
        "\n",
        "\n",
        "def add_method(obj, func):\n",
        "\n",
        "    setattr(obj, func.__name__, partial(func, obj))\n",
        "\n",
        "\n",
        "\n",
        "# TODO : applyë¥¼ ì´ìš©í•´ Parameter bë¥¼ ì¶”ê°€í•´ë³´ì„¸ìš”!\n",
        "def add_bias(module):\n",
        "    module_name = module.__class__.__name__\n",
        "    search = 'Function_'\n",
        "    if search in module_name:\n",
        "        module.register_parameter(name='b',param=torch.nn.Parameter(torch.rand(1,2)))\n",
        "\n",
        "\n",
        "# TODO : applyë¥¼ ì´ìš©í•´ ì¶”ê°€ëœ bë„ ê°’ì„ 1ë¡œ ì´ˆê¸°í™”í•´ì£¼ì„¸ìš”!\n",
        "def weight_initialization(module):\n",
        "    module_name = module.__class__.__name__\n",
        "\n",
        "    if module_name.split('_')[0] == \"Function\":\n",
        "        module.W.data.fill_(1.)\n",
        "        module.b.data.fill_(1.)\n",
        "\n",
        "\n",
        "# TODO : applyë¥¼ ì´ìš©í•´ ëª¨ë“  Functionì„ linear transformationìœ¼ë¡œ ë°”ê¿”ë³´ì„¸ìš”!\n",
        "#        X @ W + b\n",
        "def linear_transformation(module):\n",
        "    module_name = module.__class__.__name__\n",
        "\n",
        "    if module_name.split('_')[0] == \"Function\":\n",
        "        module.register_forward_hook(lambda x,y,z : y[0] @ x.W.T + x.b)\n",
        "       \n",
        "        \n",
        "\n",
        "\n",
        "\n",
        "returned_module = model.apply(add_bias)\n",
        "returned_module = model.apply(weight_initialization)\n",
        "returned_module = model.apply(linear_transformation)\n",
        "\n",
        "\n",
        "print(model.get_parameter('ab.a.W'))\n",
        "\n",
        "# ğŸ¦† ì¹œêµ¬ê°€ ë¹„êµë¥¼ ìœ„í•´ì„œ ì‘ì„±í•´ë†“ì€ ì½”ë“œì—ìš”!\n",
        "class FriendLinearModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__() \n",
        "        self.linear = nn.Sequential(nn.Linear(2, 2),\n",
        "                                    nn.Linear(2, 2),\n",
        "                                    nn.Linear(2, 2),\n",
        "                                    nn.Linear(2, 2))\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.linear(x)\n",
        "\n",
        "def friends_init_weights(m):\n",
        "    if type(m) == nn.Linear:\n",
        "        m.weight.data.fill_(1.0)\n",
        "        m.bias.data.fill_(1.0)\n",
        "\n",
        "friend_model = FriendLinearModel()\n",
        "friend_model.apply(friends_init_weights)\n",
        "# print(friend_model.state_dict())\n",
        "# print(model.state_dict())\n",
        "# ğŸ¦† ì²´í¬í•´ë³´ì„¸ìš”!\n",
        "\n",
        "grads = tester(model, friend_model)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Parameter containing:\n",
            "tensor([[1., 1.],\n",
            "        [1., 1.]], requires_grad=True)\n",
            "\u001b[32m[PASS]\u001b[0m ë‘ ëª¨ë¸ì´ ê°™ì€ Parameter ê°¯ìˆ˜ë¥¼ ê°€ì§€ë„¤ìš”!\n",
            "--------------------------------------------------\n",
            "\u001b[32m[PASS]\u001b[0m Function_Aì— Parameter bë¥¼ ë§Œë“œì…¨ë„¤ìš”!\n",
            "--------------------------------------------------\n",
            "\u001b[32m[PASS]\u001b[0m Function_Bì— Parameter bë¥¼ ë§Œë“œì…¨ë„¤ìš”!\n",
            "--------------------------------------------------\n",
            "\u001b[32m[PASS]\u001b[0m Function_Cì— Parameter bë¥¼ ë§Œë“œì…¨ë„¤ìš”!\n",
            "--------------------------------------------------\n",
            "\u001b[32m[PASS]\u001b[0m Function_Dì— Parameter bë¥¼ ë§Œë“œì…¨ë„¤ìš”!\n",
            "--------------------------------------------------\n",
            "\u001b[32m[PASS]\u001b[0m Parameter W, bë¥¼ ëª¨ë‘ 1ë¡œ ì´ˆê¸°í™”ì‹œí‚¤ì…¨ë„¤ìš”!\n",
            "--------------------------------------------------\n",
            "\u001b[32m[PASS]\u001b[0m ë‘ ëª¨ë¸ì´ ë™ì¼í•œ ì¶œë ¥ê°’ì„ ê°€ì§€ë„¤ìš”!\n",
            "--------------------------------------------------\n",
            "\u001b[32m[PASS]\u001b[0m ì…ë ¥ì— ì‚¬ìš©ëœ xê°€ ë™ì¼í•œ Gradient ê°’ì„ ê°€ì§€ë„¤ìš”!\n",
            "--------------------------------------------------\n",
            "\u001b[32m[PASS]\u001b[0m Function_A Parameter Wê°€ ë™ì¼í•œ Gradient ê°’ì„ ê°€ì§€ë„¤ìš”!\n",
            "--------------------------------------------------\n",
            "\u001b[32m[PASS]\u001b[0m Function_A Parameter bê°€ ë™ì¼í•œ Gradient ê°’ì„ ê°€ì§€ë„¤ìš”!\n",
            "--------------------------------------------------\n",
            "\u001b[32m[PASS]\u001b[0m Function_B Parameter Wê°€ ë™ì¼í•œ Gradient ê°’ì„ ê°€ì§€ë„¤ìš”!\n",
            "--------------------------------------------------\n",
            "\u001b[32m[PASS]\u001b[0m Function_B Parameter bê°€ ë™ì¼í•œ Gradient ê°’ì„ ê°€ì§€ë„¤ìš”!\n",
            "--------------------------------------------------\n",
            "\u001b[32m[PASS]\u001b[0m Function_C Parameter Wê°€ ë™ì¼í•œ Gradient ê°’ì„ ê°€ì§€ë„¤ìš”!\n",
            "--------------------------------------------------\n",
            "\u001b[32m[PASS]\u001b[0m Function_C Parameter bê°€ ë™ì¼í•œ Gradient ê°’ì„ ê°€ì§€ë„¤ìš”!\n",
            "--------------------------------------------------\n",
            "\u001b[32m[PASS]\u001b[0m Function_D Parameter Wê°€ ë™ì¼í•œ Gradient ê°’ì„ ê°€ì§€ë„¤ìš”!\n",
            "--------------------------------------------------\n",
            "\u001b[32m[PASS]\u001b[0m Function_D Parameter bê°€ ë™ì¼í•œ Gradient ê°’ì„ ê°€ì§€ë„¤ìš”!\n",
            "--------------------------------------------------\n",
            "\u001b[32m[ALL PASS 16/16]\u001b[0m ğŸ‰ğŸ‰ğŸ‰ ì„±ê³µ!!! ğŸ‰ğŸ‰ğŸ‰\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t_Ka8OvED4H4"
      },
      "source": [
        "```python\n",
        "ğŸ¦\n",
        "ì•„.. ì•„ë‹ˆ ì´ê±¸ í•´ë‚´ë‹¤ë‹ˆ!!!!!\n",
        "```\n",
        "``` python\n",
        "ğŸ¦†\n",
        "ë§ˆìŒ ë¨¹ìœ¼ë©´ ì´ì¯¤ì´ì•¼!\n",
        "\n",
        "íœ´ ì •ë§ ì–´ë ¤ì› ì–´ìš”! ê·¸ëŸ°ë° ì •ë§ ë†€ëì–´ìš”!\n",
        "ì´ë¯¸ ë§Œë“¤ì–´ì§„ ëª¨ë¸ì„ ì½”ë“œë¥¼ ì „í˜€ ê±´ë“¤ì´ì§€ ì•Šê³  ìƒˆë¡œìš´ ëª¨ë¸ë¡œ íƒˆë°”ê¿ˆì‹œí‚¤ë‹¤ë‹ˆ!\n",
        "ì‹¬ì§€ì–´ PyTorchì˜ \"nn.Linear\"ëª¨ë¸ê³¼ ì™„ë²½íˆ ë™ì¼í•˜ê²Œ ë™ì‘í•˜ê³  ìˆì–´ìš”!\n",
        "forward, backward ëª¨ë‘ ë§ì´ì£ !\n",
        "\n",
        "applyë¥¼ ì¨ì•¼ì§€ë§Œ í•  ìˆ˜ ìˆëŠ” ê²ƒì€ ì•„ë‹ˆì—ˆì§€ë§Œ applyë¥¼ ì‚¬ìš©í•´ì„œ í•˜ë‹ˆê¹Œ\n",
        "í•¨ìˆ˜ê°€ ê¹”ë”í•˜ê²Œ ì •ë¦¬ë˜ì–´ì„œ ê°€ë…ì„±ì´ ì¦ê°€í•œ ëŠë‚Œì´ì—ìš”!\n",
        "\n",
        "ê·¸ëŸ°ë° ì´ê±¸ ëŒ€ì²´ ì–´ë””ë‹¤ ì“°ëŠ”ê±°ì£ ?\n",
        "```\n",
        "```python\n",
        "ğŸ¦\n",
        "ë°˜ê°€ì›Œìš”! ì œê°€ ë°”ë¡œ ë¶€ë•ì´ ì¹œêµ¬ ë¶€ì•µì´ì—ìš”!\n",
        "\n",
        "ì´ ê³¼ì œë¥¼ í‘¸ëŠ”ë° í° ë„ì›€ì„ ì£¼ì—ˆë‹¤ê³  ë“¤ì—ˆì–´ìš”!\n",
        "ì—­ì‹œ ë¶€ë•ì´ê°€ ì´ê±¸ í˜¼ì í•´ë‚¼ë¦¬ê°€ ì—†ì£ !\n",
        "\n",
        "ì•ìœ¼ë¡œ PyTorchë¥¼ ì‚¬ìš©í•˜ë©´ì„œ Pretrainedëœ ëª¨ë¸ì„ ë§ì´ ì‚¬ìš©í•˜ì‹œê²Œ ë í…ë°\n",
        "ëª¨ë¸ ìì²´ì— ë²„ê·¸ê°€ ìˆê±°ë‚˜, í˜¹ì€ ìˆ˜ì •í•´ì„œ ì¨ì•¼ë§Œ í•˜ëŠ” ë“±ì˜ ì‚¬í•­ë“¤ì´ ë°œìƒí•  ìˆ˜ ìˆì–´ìš”.\n",
        "ì´ëŸ° ê²½ìš° ì˜¤ëŠ˜ ì—¬ê¸°ì—ì„œ ì—°ìŠµí•˜ì‹  ëª¨ë¸ì„ ìˆ˜ì •í•˜ëŠ” í›ˆë ¨ì´ í° ë„ì›€ì´ ë  ê±°ì˜ˆìš”!\n",
        "\n",
        "ì†”ì§íˆ í’€ ì¤„ì€ ëª°ëëŠ”ë° ì •ë§ ë†€ëì–´ìš”! ì°¬ì‚¬ë¥¼ ë³´ëƒ…ë‹ˆë‹¤!\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aI-eQLReB_b0"
      },
      "source": [
        "### ğŸ‰ğŸ‰ğŸ‰ nn.Module ì™„ë£Œ! ğŸ‰ğŸ‰ğŸ‰\n",
        "\n",
        "```python\n",
        "ğŸ¦†\n",
        "ì—¬ê¸°ê¹Œì§€ ì˜¤ë‹¤ë‹ˆ ì •ë§ ë¯¿ê¸°ì§€ ì•Šì•„ìš”!\n",
        "PyTorchì— ëŒ€í•´ì„œ ì•„ë¬´ê²ƒë„ ëª°ëë˜ ì œê°€ ì´ì œëŠ” ì›í•˜ëŠ” ëª¨ë¸ì„ ë§Œë“¤ ìˆ˜ ìˆê²Œ ë˜ì—ˆì–´ìš”!\n",
        "ì•„ì§ ë°°ìš¸ ê²ƒì´ ë§ë‹¤ëŠ” ê²ƒì€ ì•Œê³  ìˆì§€ë§Œ ê·¸ë˜ë„ ë„ˆë¬´ ê¸°ë»ìš”!\n",
        "```\n",
        "\n",
        "Custom ëª¨ë¸ì„ ë§Œë“¤ê¸° ìœ„í•´ \n",
        "ì ì§€ ì•Šì€ ë¶„ëŸ‰ì´ì—ˆìŒì—ë„ ë¬´ì‚¬íˆ ë§ˆë¬´ë¦¬ ì§€ìœ¼ì‹  ê²ƒì„ ì •ë§ ì¶•í•˜ë“œë¦½ë‹ˆë‹¤! ğŸ‰<br>\n",
        "ì´ë²ˆ ì±•í„°ëŠ” Documentationì— ë¹„í•  ë°” ì—†ì´ ë†’ì€ ë‚œì´ë„ë¥¼ ê°€ì§€ê³  ìˆì—ˆìŠµë‹ˆë‹¤.<br>\n",
        "í•˜ì§€ë§Œ ëª¨ë‘ ì´ê²¨ë‚´ì‹œê³  ì—¬ê¸°ê¹Œì§€ ì˜¤ì…¨êµ°ìš”! ì´ê±´ ì •ë§ ëŒ€ë‹¨í•œ ì¼ì…ë‹ˆë‹¤.\n",
        "\n",
        "ë§ì´ ì§€ì¹˜ì…¨ì„ ê²ë‹ˆë‹¤! í•˜ì§€ë§Œ ì•ˆì‹¬í•˜ì„¸ìš”! ì—¬ê¸°ê¹Œì§€ ì˜¨ ì´ìƒ ë‹¤ ëë‚œê²ƒê³¼ ê°™ìŠµë‹ˆë‹¤<br>\n",
        "Githubê³¼ ê´€ë ¨ëœ ë‚´ìš©ì´ ë‚˜ì˜¤ì§€ë§Œ ì‰¬ì–´ê°€ëŠ” ì½”ë„ˆì— ê°€ê¹ìŠµë‹ˆë‹¤.<br>\n",
        "ì‹œê°„ë„ ì–¼ë§ˆ ì•ˆê±¸ë¦¬ê³  ë‚´ìš©ë„ ì§§ìœ¼ë‹ˆ ì´ì œëŠ” ê¸´ì¥ì„ í‘¸ì…”ë„ ì¢‹ìŠµë‹ˆë‹¤!<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gsjw07-c6Vgf"
      },
      "source": [
        "## ğŸš€ <font color='yellow'><b>[ Optional ]</b></font> Custom ëª¨ë¸ ì œì‘ì„ ìœ„í•œ Github ì°¸ì¡°\n",
        "\n",
        "```\n",
        "ğŸ’¡ ë‹¤ë¥¸ ì‚¬ëŒë“¤ì€ ì–´ë–»ê²Œ custom ëª¨ë¸ì„ ë§Œë“¤ê³  ìˆì„ê¹Œìš”?\n",
        "   ìš°ë¦¬ëŠ” Githubì„ ë°©ë¬¸í•˜ì—¬ ê·¸ ë‹µì„ ì•Œì•„ë³´ëŠ” ì‹œê°„ì„ ê°€ì§ˆ ê²ƒì…ë‹ˆë‹¤.\n",
        "```\n",
        "\n",
        "# ğŸŒğŸ£\n",
        "Custom ëª¨ë¸ì„ ì œì‘í•˜ê¸° ìœ„í•´ í•„ìš”í•œ ì¤€ë¹„ë¥¼ ë§ˆì³¤ìŠµë‹ˆë‹¤!<br>\n",
        "ë¹„ë¡ ì‰½ì§€ ì•Šì€ ì—¬ì •ì´ì—ˆì§€ë§Œ ì—¬ëŸ¬ë¶„ì€ í•´ëƒˆê³  ì´ì œ ì—¬í–‰ì„ ë– ë‚  ì¤€ë¹„ê°€ ë˜ì—ˆìŠµë‹ˆë‹¤.<br>\n",
        "ì§€êµ¬ë¥¼ ë– ë‚  ì‹œê°„ì…ë‹ˆë‹¤.\n",
        "\n",
        "# â­ğŸ¤\n",
        "ì„¸ìƒì—ëŠ” ë‹¤ì–‘í•˜ê³  ë³µì¡í•œ ëª¨ë¸ë“¤ì´ ìˆìŠµë‹ˆë‹¤. ì—¬ê¸°ì—ì„œ ë°°ìš´ ì§€ì‹ë“¤ë¡œëŠ” ì°¨ë§ˆ ë‹¤ ì´í•´í•˜ì§€ ëª»í•  ê±°ëŒ€í•˜ê³  ë³µì¡í•œ í˜„ë€í•œ ëª¨ë¸ë“¤ì´ ìš°ì£¼ì˜ ë³„ë§Œí¼ ë§ì§€ëŠ” ì•Šì§€ë§Œ ì•„ë¬´íŠ¼ ë§ìŠµë‹ˆë‹¤. ì—¬ê¸°ì„œ ë°°ìš´ ì§€ì‹ì€ ë§ì€ ì§€ì‹ì€ ì•„ë‹ˆì§€ë§Œ ì´ì œ ìŠ¤ìŠ¤ë¡œ ì„œì„œ ê·¸ ëª¨ë¸ë“¤ì„ ë§ˆì£¼í•  ì •ë„ëŠ” ë©ë‹ˆë‹¤. ë¶€ì¡±í•œ ë¶€ë¶„ì´ ìˆë‹¤ë©´ ì±„ì›Œê°€ë©´ì„œ ì–´ë ¤ì›Œì„œ ë¬¼ëŸ¬ì„œê³  ì‹¶ë‹¤ë©´ ë²„í‹°ë©´ì„œ ì´ì œ ë‚˜ì•„ê°ˆ ì‹œê°„ì…ë‹ˆë‹¤. ë¹›ë‚˜ëŠ” ë³„ì„ í–¥í•´ ë§ì´ì£ ! \n",
        "\n",
        "# ğŸš€\n",
        "ê·¸ëŸ¼ ì´ì œ ë³„ë“¤ì„ ì°½ì¡°í•œ ì™¸ê³„ì˜ ì¡´ì¬ë“¤ì„ ë§Œë‚˜ëŸ¬ ê°€ë³¼ê¹Œìš”?\n",
        "\n",
        "- ğŸ›¸ Github ëª¨ë¸ ì°¾ê¸°\n",
        "- ğŸ›¸ Github ëª¨ë¸ ë¼ì´ì„¼ìŠ¤ ì²´í¬\n",
        "- ğŸ›¸ Github Repository íƒìƒ‰\n",
        "- ğŸ›¸ Github ëª¨ë¸ ì¸ìš©"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7hmoOk31nohg"
      },
      "source": [
        "### ğŸ›¸ Github ëª¨ë¸ ì°¾ê¸°\n",
        "> ì›í•˜ëŠ” Github ëª¨ë¸ì„ ì°¾ëŠ” ëª‡ ê°€ì§€ ë°©ë²•ì— ëŒ€í•´ì„œ ê°€ë³ê²Œ ì‚´í´ë³´ëŠ” ì‹œê°„ì…ë‹ˆë‹¤.\n",
        "\n",
        "- ğŸ“– <font color='gold' ><b>[ ì½ê¸° ]</b></font> êµ¬ê¸€ ê³ ê¸‰ ê²€ìƒ‰ (Google Advanced Search)\n",
        "- ğŸ“– <font color='gold' ><b>[ ì½ê¸° ]</b></font> ê¹ƒí—™ ê³ ê¸‰ ê²€ìƒ‰ (Github Advanced Search)\n",
        "- ğŸ“– <font color='gold' ><b>[ ì½ê¸° ]</b></font> ëª¨ë¸ íë ˆì´ì…˜ ì‚¬ì´íŠ¸"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OhQbpvUgaT45"
      },
      "source": [
        "#### ğŸ“– <font color='gold' ><b>[ ì½ê¸° ]</b></font> êµ¬ê¸€ ê³ ê¸‰ ê²€ìƒ‰ (Google Advanced Search)\n",
        "``` python\n",
        "ğŸ¦†\n",
        "ì´ë²ˆ ì¥ì„ ì˜¤ì‹œìë§ˆì ë– ì˜¬ë¦¬ì…¨ì„ ê²ƒ ê°™ì•„ìš”!\n",
        "í˜„ ì‹œëŒ€ì˜ í•„ìˆ˜ ê²€ìƒ‰ ë„êµ¬ êµ¬ê¸€(Google)ì´ì£ !\n",
        "\n",
        "í•˜ì§€ë§Œ êµ¬ê¸€ì´ ë‹¨ì§€ ì…ë ¥í•œ ë‹¨ì–´ë§Œ ê²€ìƒ‰í•˜ëŠ”ê²Œ ì•„ë‹ˆë¼\n",
        "ë‹¤ì–‘í•œ ê²€ìƒ‰ ì˜µì…˜ì´ ìˆë‹¤ëŠ” ê²ƒì„ ì•Œê³  ê³„ì‹ ê°€ìš”?\n",
        "\n",
        "êµ¬ê¸€ ê²€ìƒ‰ë„ í•˜ë‚˜ì˜ í”„ë¡œê·¸ë¨ì´ì—ìš”!\n",
        "ì˜ ë§Œë“¤ì–´ì§„ í”„ë¡œê·¸ë¨ì— ì˜µì…˜ì´ ì—†ì„ë¦¬ê°€ ì—†ì£ !\n",
        "ì—¬ëŸ¬ë¶„ë“¤ì´ ì‚¬ìš©í•˜ëŠ” êµ¬ê¸€ ê²€ìƒ‰ì°½ì€\n",
        "ì‰˜ë¡œ ë”°ì§€ìë©´ ëª…ë ¹ì–´ë¥¼ ì…ë ¥ë°›ëŠ” ì…ë ¥ì¹¸ì¸ ì…ˆì´ì—ìš”!\n",
        "\n",
        "í•˜ì§€ë§Œ ì €í¬ëŠ” ì¼ë°˜ì ìœ¼ë¡œ ë‹¨ì–´ë§Œ ê²€ìƒ‰í•˜ê³  ëë‚˜ê¸°ì—\n",
        "êµ¬ê¸€ ê²€ìƒ‰ í”„ë¡œê·¸ë¨ì´ ì–´ë–¤ ì˜µì…˜ì´ ìˆëŠ”ì§€ ì˜ ëª°ë¼ìš”!\n",
        "ì´ëŸ´ ë•Œ ëˆ„êµ¬ë‚˜ ì‰½ê²Œ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ”ê²Œ ë°”ë¡œ\n",
        "êµ¬ê¸€ ê³ ê¸‰ ê²€ìƒ‰(Google Advanced Search)ì´ì—ìš”!\n",
        "\n",
        "ì•„ë˜ ë§í¬ë¥¼ íƒ€ê³  ë“¤ì–´ê°€ì„œ í•œë²ˆ ì‚¬ìš©í•´ë³´ì„¸ìš”!\n",
        "ì›í•˜ëŠ” í•­ëª©ì„ ê¸°ì…í•˜ë©´ ì´ë¥¼ êµ¬ê¸€ ê²€ìƒ‰ì°½ì— ì…ë ¥í•  ìˆ˜ ìˆëŠ”\n",
        "ì í•©í•œ Queryë¡œ ë°”ê¾¸ì–´ì„œ ê²€ìƒ‰ì„ ëŒ€ì‹  í•´ì¤˜ìš”!\n",
        "```\n",
        "\n",
        "- [Google Advanced Search](https://www.google.com/advanced_search)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k0IQvtE8aUEY"
      },
      "source": [
        "#### ğŸ“– <font color='gold' ><b>[ ì½ê¸° ]</b></font> ê¹ƒí—™ ê³ ê¸‰ ê²€ìƒ‰ (Github Advanced Search)\n",
        "``` python\n",
        "ğŸ¦†\n",
        "Githubë„ ê³ ê¸‰ ê²€ìƒ‰ì´ ê°€ëŠ¥í•˜ë‹¤ëŠ” ì‚¬ì‹¤ì„ ì•„ì‹œë‚˜ìš”?\n",
        "êµ¬ê¸€ì²˜ëŸ¼ ì—¬ëŸ¬ ì˜µì…˜ì„ ì œê³µí•˜ê³  ìˆìœ¼ë‹ˆ í•œë²ˆ ì‚´í´ë´ìš”!\n",
        "```\n",
        "\n",
        "- [Github Advanced Search](https://github.com/search/advanced)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bb_DEzPpaRc9"
      },
      "source": [
        "#### ğŸ“– <font color='gold' ><b>[ ì½ê¸° ]</b></font> ëª¨ë¸ íë ˆì´ì…˜ ì‚¬ì´íŠ¸\n",
        "``` python\n",
        "ğŸ¦†\n",
        "íŠ¹ì • ëª¨ë¸ì„ ì°¾ëŠ” ê²ƒì´ ì•„ë‹ˆë¼ ì „ë°˜ì ì¸ ëª¨ë¸ì˜ íŠ¸ë Œë“œë¥¼ ì‚´í´ë³´ê³ ì í•˜ë©´\n",
        "íë ˆì´ì…˜ ì‚¬ì´íŠ¸ë¥¼ ë°©ë¬¸í•˜ëŠ” ê²ƒë„ í•˜ë‚˜ì˜ ë°©ë²•ì´ì—ìš”!\n",
        "```\n",
        "\n",
        "- [Browse State-of-the-Art - Papers With Code](https://paperswithcode.com/sota)\n",
        "- [labml.ai Annotated PyTorch Paper Implementations - labml.ai](https://nn.labml.ai/)\n",
        "- [awesome-deeplearning-resources - endymecy](https://endymecy.github.io/awesome-deeplearning-resources/awesome_projects.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aowwiHAz3I2c"
      },
      "source": [
        "### ğŸ›¸ Github ëª¨ë¸ ë¼ì´ì„¼ìŠ¤ ì²´í¬\n",
        "> Github ëª¨ë¸ì„ ì°¾ìœ¼ë©´ ë¨¼ì € ë¼ì´ì„¼ìŠ¤ë¥¼ í™•ì¸í•´ì•¼ í•©ë‹ˆë‹¤. ì›ì‘ìê°€ ì´ ëª¨ë¸ì„ ììœ ë¡­ê²Œ ì“¸ ìˆ˜ ìˆê²Œ í—ˆìš©í•´ì¤¬ëŠ”ì§€, ì•„ë‹ˆë©´ ì½”ë“œë¥¼ ê°€ì ¸ë‹¤ ì“°ëŠ”ë° ì œì•½ì„ ê±¸ì–´ë‘ì—ˆëŠ”ì§€ ì²´í¬í•´ì•¼ í›„ì— ìƒê¸¸ ë²•ì  ë¬¸ì œë¥¼ ë°©ì§€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. \n",
        "\n",
        "- ğŸ“– <font color='gold' ><b>[ ì½ê¸° ]</b></font> ì˜¤í”ˆì†ŒìŠ¤ ë¼ì´ì„¼ìŠ¤ ì¢…ë¥˜\n",
        "- ğŸ“– <font color='gold' ><b>[ ì½ê¸° ]</b></font> Github ëª¨ë¸ ë¼ì´ì„¼ìŠ¤ ì²´í¬\n",
        "- ğŸ“– <font color='gold' ><b>[ ì½ê¸° ]</b></font> ë¼ì´ì„¼ìŠ¤ê°€ í‘œì‹œë˜ì§€ ì•Šì€ ëª¨ë¸ì„ ì‚¬ìš©í•´ë„ ë ê¹Œ?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EGO21TZ0N_Iu"
      },
      "source": [
        "#### ğŸ“– <font color='gold' ><b>[ ì½ê¸° ]</b></font> ì˜¤í”ˆì†ŒìŠ¤ ë¼ì´ì„¼ìŠ¤ ì¢…ë¥˜\n",
        "\n",
        "``` python\n",
        "ğŸ¦†\n",
        "Githubì—ì„œ ì°¾ì€ ëª¨ë¸ì˜ ë¼ì´ì„¼ìŠ¤ë¥¼ í™•ì¸í•˜ê¸° ì „ì—\n",
        "ì˜¤í”ˆì†ŒìŠ¤ ë¼ì´ì„¼ìŠ¤ì— ë¨¼ì € ì–´ë–¤ ì¢…ë¥˜ë“¤ì´ ìˆëŠ”ì§€ ì•„ëŠ”ê²Œ ì¤‘ìš”í•´ìš”!\n",
        "\n",
        "ì•„ë˜ ì‚¬ì´íŠ¸ì— ì˜ ì •ë¦¬ë˜ì–´ ìˆìœ¼ë‹ˆê¹Œ í•¨ê»˜ë´ìš”!\n",
        "```\n",
        "\n",
        "- [Choosing the right license - Github Docs](https://docs.github.com/en/github/creating-cloning-and-archiving-repositories/creating-a-repository-on-github/licensing-a-repository#choosing-the-right-license)\n",
        "- [Choose an open source license - Choose AI License](https://choosealicense.com/)\n",
        "- [ì˜¤í”ˆì†ŒìŠ¤ë¥¼ ì‚¬ìš©í•˜ê³  ì¤€ë¹„í•˜ëŠ” ê°œë°œìë¥¼ ìœ„í•œ ê°€ì´ë“œ - if(kakao) dev 2018](https://tv.kakao.com/channel/3150758/cliplink/391717603)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q2IFscSgPqj0"
      },
      "source": [
        "#### ğŸ“– <font color='gold' ><b>[ ì½ê¸° ]</b></font> Github ëª¨ë¸ ë¼ì´ì„¼ìŠ¤ ì²´í¬\n",
        "\n",
        "``` python\n",
        "ğŸ¦†\n",
        "Hugging FaceëŠ” ìì—°ì–´ ì²˜ë¦¬ì—ì„œ ì •ë§ ìœ ëª…í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ì£ !\n",
        "transformers ëª¨ë¸ì˜ ë¼ì´ì„¼ìŠ¤ë¥¼ ê°™ì´ ì‚´í´ë³¼ê¹Œìš”?\n",
        "```\n",
        "\n",
        "- [transformers - Hugging Face Github](https://github.com/huggingface/transformers)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0oOO5qzH2vXq"
      },
      "source": [
        "![](https://github.com/IllgamhoDuck/PyTorch/blob/main/document_image/hugging%20face%20license.png?raw=true)\n",
        "![](https://github.com/IllgamhoDuck/PyTorch/blob/main/document_image/apache%20license%202.0.png?raw=true)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tApDeubq27rZ"
      },
      "source": [
        "``` python\n",
        "ğŸ¦†\n",
        "Apache License 2.0ì„ ë”°ë¥´ê³  ìˆë„¤ìš”!\n",
        "ìƒì—…ì ìœ¼ë¡œ ì´ìš©ì´ ê°€ëŠ¥í•œ ììœ ë¡œìš´ ë¼ì´ì„¼ìŠ¤ì—ìš”!\n",
        "í•˜ì§€ë§Œ ì†ŒìŠ¤ ì½”ë“œë¥¼ ê°€ì ¸ë‹¤ê°€ ì‚¬ìš©í•˜ë©´ licenseì™€ copyrightì„ ëª…ì‹œí•´ì¤˜ì•¼í•˜ê³ \n",
        "ê°€ì ¸ë‹¤ê°€ ì‚¬ìš©í•œ ì†ŒìŠ¤ì½”ë“œë¥¼ ìˆ˜ì •í–ˆìœ¼ë©´ ì´ê²ƒ ë˜í•œ ëª…ì‹œí•´ì¤˜ì•¼ í•´ìš”!\n",
        "\n",
        "ì œì•½ ì‚¬í•­ì€ ìˆì§€ë§Œ hugging faceë¥¼ ì´ìš©í•´ì„œ ìƒì—…ì  ì œí’ˆì„ ë§Œë“¤ì–´ë„\n",
        "ì½”ë“œë¥¼ ê³µê°œí•˜ì§€ ì•Šì•„ë„ ë˜ê¸° ë•Œë¬¸ì— ì•ˆì‹¬í•˜ê³  ì œí’ˆì„ ë§Œë“œëŠ”ë° ì´ìš©í•˜ì…”ë„ ë˜ìš”!\n",
        "\n",
        "ë§ˆì¹¨ ë¼ì´ì„¼ìŠ¤ ì´ì•¼ê¸°ê°€ ë‚˜ì˜¤ê³  ìˆì–´ì„œ ê·¸ëŸ°ë° ìœ„ì—ì„œì²˜ëŸ¼\n",
        "Githubì˜ ì œí’ˆë“¤ì˜ ìŠ¤í¬ë¦°ìƒ·ì„ ì°ëŠ” ê²ƒì€ ê³¼ì—° í•©ë²•ì¼ê¹Œìš”? ë¶ˆë²•ì¼ê¹Œìš”?\n",
        "\n",
        "ê¶ê¸ˆí•˜ì‹  ë¶„ì€ ì•„ë˜ screenshotê´€ë ¨ ë§í¬ë¥¼ ì°¾ì•„ë³´ì„¸ìš”!\n",
        "```\n",
        "\n",
        "**âœ¨ ìœ ìš©í•œ ìë£Œ âœ¨**\n",
        "- [Apache License 2.0 - OLIS](https://www.olis.or.kr/license/Detailselect.do?lId=1002&mapCode=010002)\n",
        "- [Commons:Screenshots - Wikimedia Commons](https://commons.wikimedia.org/wiki/Commons:Screenshots)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D1Jje0IwRejE"
      },
      "source": [
        "#### ğŸ“– <font color='gold' ><b>[ ì½ê¸° ]</b></font> ë¼ì´ì„¼ìŠ¤ê°€ í‘œì‹œë˜ì§€ ì•Šì€ ëª¨ë¸ì„ ì‚¬ìš©í•´ë„ ë ê¹Œ?\n",
        "\n",
        "``` python\n",
        "ğŸ¦†\n",
        "Githubì— ì˜¬ë¼ì˜¨ ë‹¤ì–‘í•œ ëª¨ë¸ì„ ë³´ë‹¤ë³´ë©´ ë¼ì´ì„¼ìŠ¤ í‘œì‹œê°€ ì—†ì„ ë•Œê°€ ìˆì–´ìš”!\n",
        "ì´ëŸ° ëª¨ë¸ì˜ ê²½ìš° ì‚¬ìš©í•´ë„ ë ê¹Œìš” ì•ˆë ê¹Œìš”?\n",
        "\n",
        "ì•„ë˜ ë¬¸ì„œë¥¼ ë³´ë©´ì„œ ê°™ì´ ì•Œì•„ë´ìš”!\n",
        "```\n",
        "\n",
        "- [No License - Choose AI License](https://choosealicense.com/no-permission/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C5EzHAPj3LW8"
      },
      "source": [
        "### ğŸ›¸ Github Repository íƒìƒ‰\n",
        "> Githubì€ Repositoryë¥¼ íƒìƒ‰í•  ìˆ˜ ìˆëŠ” ê¸°ëŠ¥ì„ ì œê³µí•´ì¤ë‹ˆë‹¤. ì´ë¥¼ í™œìš©í•˜ëŠ” ë°©ë²•ì„ ê°€ë³ê²Œ ì•Œì•„ë³´ëŠ” ì‹œê°„ì„ ê°€ì§‘ë‹ˆë‹¤.\n",
        "\n",
        "- ğŸ“– <font color='gold' ><b>[ ì½ê¸° ]</b></font> Repository ì†ì— ìˆ¨ì–´ ìˆëŠ” ëª¨ë¸ ì°¾ê¸°\n",
        "- ğŸ“– <font color='gold' ><b>[ ì½ê¸° ]</b></font> transformers.py ë‚´ë¶€ ëª©ì°¨ í™•ì¸"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rSyB0wutN_Oi"
      },
      "source": [
        "#### ğŸ“– <font color='gold' ><b>[ ì½ê¸° ]</b></font> Repository ì†ì— ìˆ¨ì–´ ìˆëŠ” ëª¨ë¸ ì°¾ê¸°\n",
        "\n",
        "``` python\n",
        "ğŸ¦†\n",
        "PyTorch ê³µì‹ Github ì½”ë“œ ë² ì´ìŠ¤ì—ì„œ Transformer ëª¨ë¸ ì½”ë“œë¥¼ ì°¾ìœ¼ë ¤ê³  í•˜ëŠ”ë°\n",
        "PyTorch ê³µì‹ Github ë©”ì¸ í˜ì´ì§€ì— ë“¤ì–´ì„œìë§ˆì ê·¸ ë°©ëŒ€í•œ ì–‘ì˜ ì½”ë“œì— ë²Œì¨ í˜„ê¸°ì¦ì´ ë‚˜ë„¤ìš”!\n",
        "\n",
        "ì˜†ì—ì„œ ë³´ë‹¤ ëª»í•œ ì¹œêµ¬ê°€ Githubì´ ì œê³µí•´ì£¼ëŠ” ê²€ìƒ‰ ê¸°ëŠ¥ì„ ì‚¬ìš©í•˜ë¼ê³  ë§í•´ì£¼ì—ˆì–´ìš”! \n",
        "```\n",
        "\n",
        "- [PyTorch - Github](https://github.com/pytorch/pytorch)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K4TqNcE3PZbi"
      },
      "source": [
        "``` python\n",
        "ğŸ¦†\n",
        "Github ê²€ìƒ‰í•˜ëŠ” ê³³ì„ ì°¾ì•˜ì–´ìš”!\n",
        "```\n",
        "\n",
        "![](https://github.com/IllgamhoDuck/PyTorch/blob/main/document_image/github%20-%20pytorch.png?raw=true)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "og22SSY0QHxY"
      },
      "source": [
        "``` python\n",
        "ğŸ¦†\n",
        "transformerë¥¼ ì…ë ¥í•˜ë‹ˆê¹Œ 3ê°€ì§€ ì¢…ë¥˜ì˜ ê²€ìƒ‰ì´ ë‚˜ì˜¤ë„¤ìš”!\n",
        "\n",
        "- In this repository\n",
        "- In this organization\n",
        "- All Github\n",
        "\n",
        "ì €í¬ê°€ ì›í•˜ëŠ” ê²ƒì€ Repository ë‚´ë¶€ ê²€ìƒ‰ì´ë‹ˆê¹Œ ë§¨ ìœ„ì— ê²ƒì„ ëˆŒë €ì–´ìš”!\n",
        "```\n",
        "\n",
        "![](https://github.com/IllgamhoDuck/PyTorch/blob/main/document_image/github%20-%20pytorch%20-%20search%20bar.png?raw=true)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "upJpvsqvQna2"
      },
      "source": [
        "``` python\n",
        "ğŸ¦†\n",
        "PyTorch ê³µì‹ ì½”ë“œì—ì„œ transformer ê²€ìƒ‰ ê²°ê³¼ê°€ ëœ¨ë„¤ìš”!\n",
        "í•˜ì§€ë§Œ ì œê°€ ì›í•˜ëŠ” ê²ƒì€ c++ ì½”ë“œë¡œ ì´ë£¨ì–´ì§„ transformer ëª¨ë¸ì´ ì•„ë‹ˆë¼\n",
        "pythonìœ¼ë¡œ ì´ë£¨ì–´ì§„ transformer ëª¨ë¸ì´ì—ìš”!\n",
        "\n",
        "ìŠ¤í¬ë¡¤ì„ ì¡°ê¸ˆ ë‚´ë ¤ë³¼ê¹Œìš”?\n",
        "```\n",
        "\n",
        "![](https://github.com/IllgamhoDuck/PyTorch/blob/main/document_image/github%20-%20pytorch%20-%20transformer.png?raw=true)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FnRVVIycQ8Cj"
      },
      "source": [
        "``` python\n",
        "ğŸ¦†\n",
        "transformer.py! ì°¾ì•˜ì–´ìš”! ì´ì œ í´ë¦­í•´ì„œ ë“¤ì–´ê°€ë©´ ë  ê²ƒ ê°™ì•„ìš”!\n",
        "\n",
        "ì´ë ‡ê²Œ í¸í•˜ë‹¤ë‹ˆ! ê²€ìƒ‰ì°½ì´ ì •ë§ ì¢‹ë„¤ìš”!\n",
        "```\n",
        "\n",
        "![](https://github.com/IllgamhoDuck/PyTorch/blob/main/document_image/github%20-%20pytorch%20-%20transformer%20found.png?raw=true)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E5k7RfnzRRo9"
      },
      "source": [
        "``` python\n",
        "ğŸ¦†\n",
        "class Transformer! ì œê°€ ì •í™•íˆ ì›í•˜ë˜ ëª¨ë¸ì´ì—ìš”!\n",
        "\n",
        "ê²½ë¡œë¥¼ ë³´ë‹ˆê¹Œ pytorch/torch/nn/modules/transformer.py ë„¤ìš”!\n",
        "ë§Œì•½ ì§ì ‘ ì°¾ìœ¼ë ¤ê³  í–ˆë‹¤ë©´ ê½¤ í—¤ë§¸ì„ ê²ƒ ê°™ì•„ìš”!\n",
        "```\n",
        "\n",
        "![](https://github.com/IllgamhoDuck/PyTorch/blob/main/document_image/transformers.png?raw=true)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pSIGoFyWRoJ2"
      },
      "source": [
        "#### ğŸ“– <font color='gold' ><b>[ ì½ê¸° ]</b></font> transformers.py ë‚´ë¶€ ëª©ì°¨ í™•ì¸\n",
        "\n",
        "``` python\n",
        "ğŸ¦†\n",
        "transformer.pyì— ì–´ë–¤ classì™€ functionì´ ìˆëŠ”ì§€ í™•ì¸ì„ í•˜ê³  ì‹¶ì„ ë•Œ\n",
        "ì¼ì¼ì´ ìŠ¤í¬ë¡¤ì„ ë‚´ë¦¬ë©´ì„œ í™•ì¸í•˜ê¸°ì—ëŠ” ë²ˆê±°ë¡­ê² ì£ ?\n",
        "\n",
        "transformers.py ë‚´ë¶€ì˜ ëª©ì°¨ëŠ” ì–´ë””ì—ì„œ í™•ì¸í• ê¹Œìš”?\n",
        "```\n",
        "\n",
        "- [transformer.py - Github](https://github.com/pytorch/pytorch/blob/35307b131df9d24bfa96103d6061cf14c797ee32/torch/nn/modules/transformer.py)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gq6zcLvVRpXB"
      },
      "source": [
        "``` python\n",
        "ğŸ¦†\n",
        "ë¹¨ê°„ìƒ‰ ë°•ìŠ¤ì˜ Jump toë¥¼ ì´ìš©í•˜ë©´ ì¢‹ì•„ìš”!\n",
        "```\n",
        "\n",
        "![](https://github.com/IllgamhoDuck/PyTorch/blob/main/document_image/transformer%20-%20jump%20to.png?raw=true)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZziNxuyzSNKE"
      },
      "source": [
        "``` python\n",
        "ğŸ¦†\n",
        "ê° classì™€ functionì´ ìˆœì„œëŒ€ë¡œ ë‚˜ì™€ìˆëŠ” ê²ƒì´ ë³´ì´ì‹œì£ ?\n",
        "ë³µì¡í•œ ì½”ë“œë¥¼ ìŠ¤í¬ë¡¤ê³¼ í•¨ê»˜ íƒí—˜í•˜ì§€ ì•Šë”ë¼ë„ ëª©ì°¨ë¥¼ ë³¼ ìˆ˜ ìˆì–´ìš”!\n",
        "```\n",
        "\n",
        "![](https://github.com/IllgamhoDuck/PyTorch/blob/main/document_image/transformers%20-%20insider%20search.png?raw=true)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u7iF0gyR3dZa"
      },
      "source": [
        "### ğŸ›¸ Github ëª¨ë¸ ì¸ìš©\n",
        "> Githubì—ì„œ ë ˆí¼ëŸ°ìŠ¤(Reference) ëª¨ë¸ì„ ì„±ê³µì ìœ¼ë¡œ ì°¾ì€ ì´í›„ pip install, ë³µì‚¬ ë¶™ì—¬ë„£ê¸°, í˜¹ì€ git clone ë“± ìì‹ ë§Œì˜ ë°©ë²•ìœ¼ë¡œ ëª¨ë¸ ì½”ë“œë¥¼ ê°€ì ¸ì™”ì„ ê²ƒì…ë‹ˆë‹¤. ì¼ë°˜ì ìœ¼ë¡œ ìš°ë¦¬ëŠ” ë§í¬ë¥¼ ë‚¨ê¸°ê±°ë‚˜ ê·¸ëƒ¥ ë„˜ê¸°ëŠ” ê²½ìš°ê°€ ìˆìŠµë‹ˆë‹¤. í•˜ì§€ë§Œ ì›ì¹™ì ìœ¼ë¡œ ì •í™•í•œ ì¸ìš©ì€ ì›ì‘ìì— ëŒ€í•œ ì˜ˆì˜ì´ê¸° ë•Œë¬¸ì— ì¸ìš©(cite)ì„ ì •í™•í•˜ê²Œ í•˜ëŠ” ë°©ë²•ì„ ê°€ë³ê²Œ ì•Œì•„ë³´ëŠ” ì‹œê°„ì„ ê°€ì§‘ë‹ˆë‹¤.\n",
        "\n",
        "- ğŸ“– <font color='gold' ><b>[ ì½ê¸° ]</b></font> Citationì´ ì œê³µë  ê²½ìš°\n",
        "- ğŸ“– <font color='gold' ><b>[ ì½ê¸° ]</b></font> Citationì´ ì œê³µë˜ì§€ ì•Šì„ ê²½ìš°"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HxAcbyy-axop"
      },
      "source": [
        "#### ğŸ“– <font color='gold' ><b>[ ì½ê¸° ]</b></font> Citationì´ ì œê³µë  ê²½ìš°\n",
        "\n",
        "``` python\n",
        "ğŸ¦†\n",
        "PyTorchë‚˜ Hugging Faceì™€ ê°™ì´ ìœ ëª…í•˜ê³  ê³µì‹ì ì¸\n",
        "Github í”„ë¡œì íŠ¸ë“¤ì€ ë³´í†µ Citationì„ ì œê³µí•´ì¤˜ìš”!\n",
        "\n",
        "í•˜ì§€ë§Œ Reference ëª¨ë¸ì´ ì†í•´ìˆëŠ”\n",
        "ê° Github í˜ì´ì§€ë³„ë¡œ Citationì„ ì œê³µí•˜ì§€ëŠ” ì•Šì•„ìš”!\n",
        "\n",
        "ê·¸ë˜ì„œ ì—¬ê¸°ì„œëŠ” Github ëª¨ë¸ ì¸ìš©ì„ Github ëª¨ë¸ì´ ì†í•´ìˆëŠ”\n",
        "Repository ì¸ìš©ìœ¼ë¡œ ëŒ€ì‹ í•˜ëŠ” ê²ƒì— ì£¼ì˜í•´ì£¼ì„¸ìš”!\n",
        "```\n",
        "```python\n",
        "ğŸ¦ ë¶€ì•µì´ì—ìš”! Github Repository Citation ì˜ˆì‹œì—ìš”!\n",
        "```\n",
        "- [PyTorch/CITATION - Github](https://github.com/pytorch/pytorch/blob/master/CITATION)\n",
        "- [Huggingface/Transformers/citation - Github](https://github.com/huggingface/transformers#citation)\n",
        "\n",
        "```python\n",
        "ğŸ¦ ëŒ€ë¶€ë¶„ì€ BibTex í˜•ì‹ì„ ë”°ë¥´ê¸° ë•Œë¬¸ì— ì•„ë˜ì—ì„œ ë³€í™˜í•´ì„œ ì‚¬ìš©í•˜ì„¸ìš”!\n",
        "```\n",
        "- [BibTeX Online Converter](https://bibtex.online/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PY5Rm509gNHe"
      },
      "source": [
        "#### ğŸ“– <font color='gold' ><b>[ ì½ê¸° ]</b></font> Citationì´ ì œê³µë˜ì§€ ì•Šì„ ê²½ìš°\n",
        "\n",
        "``` python\n",
        "ğŸ¦†\n",
        "ì§ì ‘ ì¸ìš©ë¬¸ì„ ë§Œë“¤ì–´ë‚´ëŠ” ê²ƒì€ ì–¸ì œë‚˜ ê¹Œë‹¤ë¡œìš´ ì¼ì´ì£ !\n",
        "ì¸ìš© ë°©ë²•ë„ ì œê°ê°ì´ê³  ê·¸ ë°©ë²•ì— ë§ì¶”ëŠ” ê²ƒë„ ë²ˆê±°ë¡œì›Œìš”!\n",
        "ê·¸ë˜ì„œ ì¼ë°˜ì ìœ¼ë¡œ ë‹¤ë“¤ ëŒ€ì¶© ì¸ìš©í•˜ê³  ë„˜ê¸°ëŠ” ê²½ìš°ê°€ ë§ì•„ìš”!\n",
        "\n",
        "í•˜ì§€ë§Œ ì ì–´ë„ ì—¬ê¸°ì„œëŠ” ì œëŒ€ë¡œ ì¸ìš©í•˜ëŠ” ë°©ë²•ì— ëŒ€í•´ì„œ ì•Œì•„ë´ìš”!\n",
        "```\n",
        "```python\n",
        "ğŸ¦ ë‹¤ì‹œ ë¶€ì•µì´ì—ìš”! Citationì„ ì§ì ‘ ì‘ì„±í•˜ë ¤ë©´ ì•„ë˜ ê¸€ì„ ì¶”ì²œë“œë ¤ìš”!\n",
        "```\n",
        "\n",
        "- [How to Cite a GitHub Repository - Wiki How](https://www.wikihow.com/Cite-a-GitHub-Repository)\n",
        "\n",
        "```python\n",
        "ğŸ¦ ìë™ ì™„ì„± Citationì„ ì›í•œë‹¤ë©´ ë‹¤ìŒ ì‚¬ì´íŠ¸ì—ì„œ í•˜ì‹œë©´ ë˜ìš”!\n",
        "```\n",
        "- [Free Harvard Citation Generator - Cite This For Me](https://www.citethisforme.com/citation-generator/harvard)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AjV4kPz449Qf"
      },
      "source": [
        "### ğŸ‰ğŸ‰ğŸ‰ Github ì™„ë£Œ! ğŸ‰ğŸ‰ğŸ‰\n",
        "\n",
        "```python\n",
        "ğŸ¦†\n",
        "ë§ˆì¹¨ë‚´ ëì— ë‹¤ë‹¤ë €êµ°ìš”! ì´ì œëŠ” í—¤ì–´ì§ˆ ì‹œê°„ì´ì—ìš”!\n",
        "í•¨ê»˜ ê³µë¶€í•œ ê²ƒì„ ìŠì§€ ëª»í• ê±°ì˜ˆìš”!\n",
        "\n",
        "ê·¸ëŸ¼ ë¶€ìŠ¤íŠ¸ìº í”„ì˜ ì—¬ì • ëë‚˜ë©´ ì§€êµ¬ì—ì„œ ë‹¤ì‹œ ë§Œë‚˜ìš”!\n",
        "ì €ëŠ” ì´ë§Œ ì§€êµ¬ë¡œ ëŒì•„ê°€ë³¼ê²Œìš”!\n",
        "```\n",
        "```python\n",
        "ğŸ¦ ì €ë„ ê°€ë³¼ê²Œìš”! ì•ˆë…•!\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ixzc0txuqmDb"
      },
      "source": [
        "## ğŸ‰ğŸŠğŸ‰ ì¶•í•˜ë“œë ¤ìš”! ëê¹Œì§€ í•´ë‚´ì…¨êµ°ìš”! ğŸ‰ğŸŠğŸ‰\n",
        "> ì´ë²ˆ ê³¼ì œì—ëŠ” custom ëª¨ë¸ì— ëŒ€í•œ ë‹¤ì–‘í•˜ë©´ì„œë„ ê²°ì½” ì ì§€ ì•Šì€ ë‚´ìš©ì´ ë‹´ê²¨ì ¸ ìˆì—ˆìŠµë‹ˆë‹¤! ì´ì œ ì—¬ëŸ¬ë¶„ì€ custom ëª¨ë¸ì„ ë§Œë“¤ê¸° ìœ„í•´ì„œ ë¬´ì—‡ì´ í•„ìš”í•œì§€ ì•Œê³  ë¶€ì¡±í•œ ê²ƒì´ ìˆë‹¤ë©´ ìŠ¤ìŠ¤ë¡œ ì°¾ì•„ë‚´ ì±„ì›Œë‚¼ ìˆ˜ ìˆìœ¼ë©° ìŠ¤ìŠ¤ë¡œ ì›í•˜ëŠ” ëª¨ë¸ì„ êµ¬ì¶•í•´ë‚˜ê°ˆ ìˆ˜ ìˆëŠ” ì§€ì‹ì„ ì–»ì—ˆìŠµë‹ˆë‹¤! ì—¬ê¸°ê¹Œì§€ ì˜¤ëŠ” ê³¼ì •ì´ ê²°ì½” ì‰½ì§€ë§Œì€ ì•Šì•˜ê² ì§€ë§Œ ë¶„ëª… ê°€ì¹˜ê°€ ìˆì—ˆê¸°ë¥¼ ë°”ëë‹ˆë‹¤. í–‰ìš´ì„ ë¹•ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "v_fiPQLq700o"
      },
      "source": [
        "#@title ë¶€ë•ì´ê°€ ì¶•í•˜ì˜ ì¶¤ì„ ì¶˜ëŒ€ìš”!\n",
        "from IPython.display import Image\n",
        "Image(url='https://post-phinf.pstatic.net/MjAxODEyMzFfMTAw/MDAxNTQ2MjE0OTg5NjAz.EHOabmOFRb9Sd4H1C8xJWAjDd-AalUHZ0mGRQc8nLJgg.QaKd2fe0gct3mQ-Ex-8qqSS1RVXjoC_-NLXo80sAQNsg.GIF/mug_obj_201812310909504083.gif?type=w1080')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "Eo7wLf2p7x_q"
      },
      "source": [
        "#@title ë¸Œë ˆì´í¬ëŒ„ìŠ¤!\n",
        "from IPython.display import Image\n",
        "Image(url='https://www.wetrend.co.kr/data/editor2/wit_board/2102/07/1612656261_3c92e94dc4e55df68f76b46053008df8')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "_9eeUgvl7M3O"
      },
      "source": [
        "#@title ì—¬ê¸°ì„œ ë©ˆì¶œ ìˆ˜ ì—†ì§€! ì¶¤ì¶° ì¹œêµ¬ë“¤!\n",
        "from IPython.display import Image\n",
        "Image(url='https://i.pinimg.com/originals/29/04/24/29042493fb118029b9014e4cb800c7ee.gif')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}